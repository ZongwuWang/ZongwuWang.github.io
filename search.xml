<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Ambit: In-Memory Accelerator for Bulk Bitwise Operations Using Commodity DRAM Technology</title>
      <link href="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/"/>
      <url>/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/</url>
      
        <content type="html"><![CDATA[<!-- 文章标题 --><!-- TOC --><ul><li><a href="#summary">Summary</a></li><li><a href="#research-objective">Research Objective</a></li><li><a href="#problem-statement">Problem Statement</a></li><li><a href="#methods">Method(s)</a><ul><li><a href="#detailed-design">Detailed Design</a><ul><li><a href="#ambit-and-or">Ambit-AND-OR</a></li><li><a href="#tra%E8%83%BD%E5%A4%9F%E5%B7%A5%E4%BD%9C%E9%9C%80%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98">TRA能够工作需要解决的问题</a></li><li><a href="#%E8%A7%A3%E5%86%B335%E7%9A%84ambit-and-or-flow">解决3~5的Ambit-AND-OR Flow</a></li><li><a href="#ambit-not">Ambit-NOT</a></li></ul></li><li><a href="#ambit-putting-it--all-together">Ambit: Putting it  all together</a><ul><li><a href="#row-address-grouping">Row address grouping</a></li><li><a href="#executing-bitwise-ops-the-aap-primitive">Executing Bitwise Ops: The AAP Primitive</a></li><li><a href="#accelerating-aap-with-a-split-row-decoder">Accelerating AAP with a Split Row Decoder</a></li><li><a href="#integrating-ambit-with-the-system">Integrating Ambit with the System</a></li></ul></li></ul></li><li><a href="#evaluation">Evaluation</a></li><li><a href="#conclusion">Conclusion</a><ul><li><a href="#circuit-level-spice-simulation">Circuit-level SPICE Simulation</a></li><li><a href="#analysis-of-throughput--energy">Analysis of Throughput &amp; Energy</a></li><li><a href="#effect-on-real-world-application">Effect on Real-World Application</a></li></ul></li><li><a href="#notes">Notes</a><ul><li><a href="#bulk-bitwise-operations%E7%9A%84%E5%8A%A0%E9%80%9F%E5%9C%BA%E6%99%AF%E5%8F%8A%E6%84%8F%E4%B9%89">Bulk bitwise operations的加速场景及意义</a></li><li><a href="#interleaved-memory-system-%E4%BA%A4%E9%94%99%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F">Interleaved Memory System (交错存储系统)</a></li></ul></li></ul><!-- /TOC --><p>HPCA-2020</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><!-- 写完笔记之后最后填，概述文章的内容，以后查阅笔记的时候先看这一段。 --><p>这篇文章介绍了一种存内计算的方法Ambit，可以在DRAM中实现整行的AND/OR/NOT逻辑操作，将源数据复制到预留的操作数行，不破坏原始数据，同时降低操作数译码电路的复杂度。</p><h2 id="Research-Objective"><a href="#Research-Objective" class="headerlink" title="Research Objective"></a>Research Objective</h2><!-- 作者的研究目标 --><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><!-- 问题陈述，要解决什么问题？ --><p>In existing architectures, the throughput of bulk bitwise operations is limited by the memory bandwidth available to the processing unit (e.g., CPU, GPU, FPGA, processing-in-memory).</p><h2 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a>Method(s)</h2><!-- 解决问题的方法/算法是什么？ --><p>Ambit利用DRAM技术的模拟操作完全在DRAM内部执行按位运算，从而充分利用了内部DRAM的全部带宽。<br>With modest changes to the DRAM design, Ambit can exploit:</p><ul><li>the maximum internal bandwidth available inside each DRAM array;</li><li>the memory-level parallelism across multiple DRAM arrays.</li></ul><h3 id="Detailed-Design"><a href="#Detailed-Design" class="headerlink" title="Detailed Design"></a>Detailed Design</h3><h4 id="Ambit-AND-OR"><a href="#Ambit-AND-OR" class="headerlink" title="Ambit-AND-OR"></a>Ambit-AND-OR</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-11-44-34.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="TRA"></p><p>TRA (triple-row activation) 同时将一个读出放大器与同一位线上的三个DRAM单元相连，假设这三个单元的电容相同，都为$C_c$，bitline的寄生电容为$C_b$，基于电荷共享原则，在电荷共享结束之后，bitline上的电压偏差为：<br>$$\delta = \frac{k\cdot C_c \cdot V_{DD} + C_b \cdot \frac{1}{2} \cdot V_{DD}}{3C_c + C_b} - \frac{1}{2}V_{DD} = \frac{(2k-3)C_c}{6C_c + 2C_b}V_{DD}$$<br>从上面的公式可以看出，如果$k = 2, 3$，则bitline deviation为正，如果$k = 0, 1$，则bitline deviation为负。<br>分别使用A, B, C表示三个cell的逻辑值，则最终的输出可以表示为$C(A+B) + \overline{C}(AB)$，由此我们可以得到：通过控制C的逻辑值，我们可以使用TRA实现逻辑AND和OR。</p><h4 id="TRA能够工作需要解决的问题"><a href="#TRA能够工作需要解决的问题" class="headerlink" title="TRA能够工作需要解决的问题"></a>TRA能够工作需要解决的问题</h4><ol><li>当同时激活三个单元时，位线上的偏差可能小于仅激活一个单元时的偏差。 这可能会延长感测放大的时间或更糟，感测放大器可能会检测到错误的值。</li><li>由于工艺的变化，所有电容相等的假设在实际设计中是不正确的。这会影响TRA的可靠性，从而影响其结果的正确性。</li><li>TRA会改写三个cell的原始数据。</li><li>电容可能会没有充电到满电荷，或者由于漏电会导致电荷随时间减少，如果漏电明显会影响运算结果。</li><li>同时激活DRAM子阵列中的三个任意行需要内存控制器和行解码器同时通信和解码三个行地址。这将在地址总线和行解码器上引入大量成本。</li></ol><h4 id="解决3-5的Ambit-AND-OR-Flow"><a href="#解决3-5的Ambit-AND-OR-Flow" class="headerlink" title="解决3~5的Ambit-AND-OR Flow"></a>解决3~5的Ambit-AND-OR Flow</h4><p>Ambit reserves a set of designed rows in each subarray thar are used to perform TRAs. These designated rows are chosen statically at design time.</p><ol><li>Copy data of row A to designated row T0</li><li>Copy data of row B to designated row T1</li><li>Initialize designated row T2 to 0</li><li>Activate designated rows T0, T1, and T2 simultaneously</li><li>Copy data of row T0 to row R</li></ol><h4 id="Ambit-NOT"><a href="#Ambit-NOT" class="headerlink" title="Ambit-NOT"></a>Ambit-NOT</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-46-47.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Ambit-NOT"></p><p>$\overline{\text{bitline}}$上的电压表示cell逻辑值的NOT逻辑，因此Ambit-NOT的方法是将$\overline{\text{bitline}}$上的数值连接到$bitline$，从而实现NOT逻辑，如上图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-52-29.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Bitwise NOT using a dual-contact cell"></p><ol><li>Activate the source row A;</li><li>Activate n-wordline of DCC (address B5);</li><li>Precharge the bank;</li><li>Copy data from d-wordline of DCC to row R (RowClone).</li></ol><h3 id="Ambit-Putting-it-all-together"><a href="#Ambit-Putting-it-all-together" class="headerlink" title="Ambit: Putting it  all together"></a>Ambit: Putting it  all together</h3><h4 id="Row-address-grouping"><a href="#Row-address-grouping" class="headerlink" title="Row address grouping"></a>Row address grouping</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-58-18.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Row address grouping"></p><p>Ambit将每个subarray中的行地址分为三类：</p><ul><li><strong>B</strong>itwise group</li><li><strong>C</strong>ontrol group</li><li><strong>D</strong>ata group</li></ul><p>Bitwise group的地址译码如下表所示：</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-16-07-51.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Mappping of B-group address"></p><h4 id="Executing-Bitwise-Ops-The-AAP-Primitive"><a href="#Executing-Bitwise-Ops-The-AAP-Primitive" class="headerlink" title="Executing Bitwise Ops: The AAP Primitive"></a>Executing Bitwise Ops: The AAP Primitive</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-16-29-14.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Command sequences for different bitwise operations"></p><p>从上图可以看出逻辑操作基本上可以使用AAP操作和AP操作来实现。</p><h4 id="Accelerating-AAP-with-a-Split-Row-Decoder"><a href="#Accelerating-AAP-with-a-Split-Row-Decoder" class="headerlink" title="Accelerating AAP with a Split Row Decoder"></a>Accelerating AAP with a Split Row Decoder</h4><h4 id="Integrating-Ambit-with-the-System"><a href="#Integrating-Ambit-with-the-System" class="headerlink" title="Integrating Ambit with the System"></a>Integrating Ambit with the System</h4><ol><li><p>ISA Support<br>$$bbop dst, src1, [src2], size$$</p></li><li><p>Ambit API/Driver Support</p><ul><li>an API that enables applications to specify bitvectors that are likely to be involved in bitwise operations;</li><li>a driver that is aware of the internal mapping of DRAM rows to subarrays and maps the bitvectors involved in bulk bitwise operations to the same DRAM array.</li></ul></li><li><p>Implementing the $bbop$ Instruction<br> 微架构需要检查：1)Ambit操作的源/目的地址是否行对齐；2)操作的长度是否是DRAM行长度的整数倍。如果检查通过，则CPU将操作发送到memory controller，否则CPU执行该操作。</p></li><li><p>Maintaining On-chip Cache Coherence</p><ul><li>flush any dirty cache lines from the source rows;</li><li>invalidate any cache lines from the source rows;<blockquote><p>Note: The above mechanism is already required by DMA. As Ambit operations are always row-wide, we can use structures like the Dirty-Block Index to speed up flushing dirty data.</p></blockquote></li></ul></li><li><p>Error Correction and Data Scrambling<br>暂时不深入这一块</p></li></ol><h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><!-- 作者如何评估自己的方法，有没有问题或者可以借鉴的地方 --><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-29-22.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><!-- 作者给了哪些strong conclusion, 又给了哪些weak conclusion? --><h3 id="Circuit-level-SPICE-Simulation"><a href="#Circuit-level-SPICE-Simulation" class="headerlink" title="Circuit-level SPICE Simulation"></a>Circuit-level SPICE Simulation</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-21-41.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Effect of process variation on TRA"></p><p><strong>Simulation tools:</strong><br>    HSPICE with the sense amplifier using 55nm DDR3 model parameters.<br><strong>Conclusion:</strong></p><ul><li>up to $\pm5%$ variation, there are zero errors in TRA.</li><li>even with $\pm10%$ and $\pm15%$ variation, the percentage of erroneous TRAs across 100,000 iterations each is just 0.29% and 6.01%.</li></ul><h3 id="Analysis-of-Throughput-amp-Energy"><a href="#Analysis-of-Throughput-amp-Energy" class="headerlink" title="Analysis of Throughput &amp; Energy"></a>Analysis of Throughput &amp; Energy</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-32-10.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Through of bbop"></p><p> Ambit (with 8 DRAM banks) outperform Skylake by 44.9%, GTX745 by 32.0x, and HMC 2.0 by 2.4X.</p><p> <img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-39-42.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Energy of bbop"></p><p><strong>Conclusion:</strong> Ambit reduces energy consumption by 25.1X-59.5X compared to copying data with the memory controller using the DDR3 interface.</p><h3 id="Effect-on-Real-World-Application"><a href="#Effect-on-Real-World-Application" class="headerlink" title="Effect on Real-World Application"></a>Effect on Real-World Application</h3><p><strong>Tools:</strong> GEM5<br><strong>Benchmark:</strong><br>    - a database bitmap index<br>    - BitWeaving, a mechanism to accelerate database column scan operations<br>    - a bitvector-based implementation of the widely-used set data structure</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-53-03.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Bitmap index performance"></p><p><strong>Conclusion:</strong> Ambit significantly reduces the query execution time compared to the baseline by 6X on average.</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-54-54.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Speedup offered by Ambit for BitWeaving"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-58-20.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Performance of set operations"></p><p><font color="blue" size="5">现有基于忆阻器的PIM能够加速的一大原因在于神经网络计算的高并行度，但是一旦并行度不高，这些慢的访存速度将强烈限制PIM的性能，因此在比cache访存速度慢的memory中实现非规则计算加速是不现实的，物理特性和容量升高都会导致访存变慢。但是有可能实现低功耗PIM。</font></p><h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><!-- 在这些框架外额外需要记录的笔记。 --><h3 id="Bulk-bitwise-operations的加速场景及意义"><a href="#Bulk-bitwise-operations的加速场景及意义" class="headerlink" title="Bulk bitwise operations的加速场景及意义"></a>Bulk bitwise operations的加速场景及意义</h3><p>In fact, many real-world databases support bitmap indice. A recent work, WideTable, designs an entire database around a technique called BitWeaving, which accelerates scans completely using bulk bitwise operations. Microsoft recently open-sourced a technology called BitFunnel that accelerates the document filtering portion of web search. BitFunnel relies on fast bulk bitwise AND operations. Bulk bitwise operations are also prevalent in DNA sequence alignment, encrayption algorithms, graph processing, and networking. Thus, accelerating bulk bitwise operations can significantly boost the performance of various applications.</p><h3 id="Interleaved-Memory-System-交错存储系统"><a href="#Interleaved-Memory-System-交错存储系统" class="headerlink" title="Interleaved Memory System (交错存储系统)"></a>Interleaved Memory System (交错存储系统)</h3><blockquote><p>参考链接：<a href="https://blog.csdn.net/wbcuc/article/details/8183369">https://blog.csdn.net/wbcuc/article/details/8183369</a></p></blockquote><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-47-52.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Non-interleaved Memory Organization"></p><p>非交错存储系统如上图所示，单个bank内地址连续，因此访问连续内存需要串行访问，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-51-32.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Non-interleaved Burst Access Timing"></p><p>不难看出上面这种方式的访问延时比较高，为了降低访存的延时，交错存储系统将地址连续的分布在bank之间，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-53-18.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Interleaved Memory Organization"></p><p>因此bank0和bank1的可以并行访问，从而将地址0和1并行读出，降低了访存的延时，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-55-01.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Intereaved Burst Access Timing"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Compute Caches</title>
      <link href="/2021/08/26/compute-caches/"/>
      <url>/2021/08/26/compute-caches/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>转-四种基本的编程命名规范</title>
      <link href="/2021/08/13/zhuan-si-chong-ji-ben-de-bian-cheng-ming-ming-gui-fan/"/>
      <url>/2021/08/13/zhuan-si-chong-ji-ben-de-bian-cheng-ming-ming-gui-fan/</url>
      
        <content type="html"><![CDATA[<h1 id="转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）"><a href="#转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）" class="headerlink" title="转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）"></a>转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）</h1><h2 id="匈牙利命名法"><a href="#匈牙利命名法" class="headerlink" title="匈牙利命名法"></a>匈牙利命名法</h2><p>匈牙利命名法是早期的规范，由微软的一个匈牙利人发明的，是IDE还十分智障的年代的产物。那个年代，当代码量很多的时候，想要确定一个变量的类型是很麻烦的，不像现在IDE都会给提示，所以才产生了这样一个命名规范，估计现在已经没啥人用了吧……一个十分系统却又琐碎的命名规范。</p><p>该命名规范，要求前缀字母用变量类型的缩写，其余部分用变量的英文或英文的缩写，单词第一个字母大写。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int iMyAge;        #  &quot;i&quot;: int</span><br><span class="line">char cMyName[10];  #  &quot;c&quot;: char</span><br><span class="line">float fManHeight;  #  &quot;f&quot;: float</span><br></pre></td></tr></table></figure><p>其他前缀类型还有：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">a      数组（Array）</span><br><span class="line">b      布尔值（Boolean）</span><br><span class="line">by     字节（Byte）</span><br><span class="line">c      有符号字符（Char）</span><br><span class="line">cb     无符号字符（Char Byte，并没有神马人用的）</span><br><span class="line">cr     颜色参考值（Color Ref）</span><br><span class="line">cx,cy  坐标差（长度 Short Int）</span><br><span class="line">dw     双字（Double Word）</span><br><span class="line">fn     函数（Function）</span><br><span class="line">h      Handle（句柄）</span><br><span class="line">i      整形（Int）</span><br><span class="line">l      长整型（Long Int）</span><br><span class="line">lp     长指针（Long Pointer）</span><br><span class="line">m_     类成员（Class Member）</span><br><span class="line">n      短整型（Short Int）</span><br><span class="line">np     近程指针（Near Pointer）</span><br><span class="line">p      指针（Pointer）</span><br><span class="line">s      字符串（String）</span><br><span class="line">sz     以 Null 做结尾的字符串型（String with Zero End）</span><br><span class="line">w      字（Word）</span><br></pre></td></tr></table></figure><p>还有其他更多的前缀是根据微软自己的MFC/句柄/控件/结构等东西定义的，就不过多描述了。</p><h2 id="驼峰式命名法"><a href="#驼峰式命名法" class="headerlink" title="驼峰式命名法"></a>驼峰式命名法</h2><p>驼峰式命名法，又叫小驼峰式命名法（所以自然就存在大驼峰命名法啦……)。</p><p>该命名规范，要求第一个单词首字母小写，后面其他单词首字母大写，简单粗暴易学易用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int myAge;</span><br><span class="line">char myName[10];</span><br><span class="line">float manHeight;</span><br></pre></td></tr></table></figure><h2 id="帕斯卡命名法"><a href="#帕斯卡命名法" class="headerlink" title="帕斯卡命名法"></a>帕斯卡命名法</h2><p>帕斯卡命名法，又叫大驼峰式命名法。</p><p>与小驼峰式命名法的最大区别在于，每个单词的第一个字母都要大写。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int MyAge;</span><br><span class="line">char MyName[10];</span><br><span class="line">float ManHeight;</span><br></pre></td></tr></table></figure><h2 id="下划线命名法"><a href="#下划线命名法" class="headerlink" title="下划线命名法"></a>下划线命名法</h2><p>下划线命名法并不如大小驼峰式命名法那么备受推崇，但是也是浓墨重彩的一笔。尤其在宏定义和常量中使用比较多，通过下划线来分割全部都是大写的单词。</p><p>该命名规范，也是很简单，要求单词与单词之间通过下划线连接即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int my_age;</span><br><span class="line">char my_name[10];</span><br><span class="line">float man_height;</span><br></pre></td></tr></table></figure><h2 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h2><p>随着技术的发展，命名规范也在不断的细化，一种命名规范早已无法系统的满足各方需求（匈牙利命名法除外，但是已经基本淘汰了），不同的语言不同 IDE 推崇的规范也有所不同，无法评判哪一种最好，但是可以肯定的是，集后三种命名规范大成者，一定是受众最广的。</p><p>例如，谷歌 C++ 编程规范，从项目的命名到文件的命名，再到类和变量以及宏定义的命名都做到了细致入微，充分的结合了下划线命名法与驼峰式命名法（早先推崇的小驼峰，不过今年好像改成大驼峰了），又加入了一些新的元素，十分的系统完善。</p><p>当然，命名规范并不代表着编程规范，仅仅是编程规范的一部分而已，除去命名规范，还有很多编程上的细节是必须关注的，例如，等号两边留空格还是等号对齐？空行神马时候神马地方留更加符合代码结构？空格神马时候神马地方留更加美观？花括号是否对齐？</p><p>诸如此类，还有很多，无法一下子全部掌握并应用，但是在编程经验增加的过程中，一定也要不断的留意，自己所在的公司部门使用的是神马样的规范，没错，并不提倡大家练就自己的规范，一定要去融入工作环境的需求。</p><p>每次去新的工作环境，第一个要看的文档不是别的，一定是编程规范，如果没有这个东西，那么就努力去推一个统一的规范，推不动的话，那可以换工作了，否则日后将会带来无尽的麻烦。</p><p>本文转载自：<a href="https://zhuanlan.zhihu.com/p/89909623">https://zhuanlan.zhihu.com/p/89909623</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2021/08/07/hello-world/"/>
      <url>/2021/08/07/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>A 28 nm Configurable Memory (TCAM/BCAM/SRAM) Using Push-Rule 6T Bit Cell Enabling Logic-in-Memory</title>
      <link href="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/"/>
      <url>/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/</url>
      
        <content type="html"><![CDATA[<p>今天在阅读“CAPE: A Content-Addressable Processing Engine”这篇论文时，论文中引用的一篇仅使用6T SRAM实现CAM的工作引起了我的兴趣。</p><p>由于可以对存储的所有entry进行并行数据搜索/匹配的优良特性，CAM是高关联性缓存、TLB和寄存器重命名电路中不可或缺的部分。LUT也是IP路由器表的主要功能，如Fig. 1所示，因此CAM是许多路由器芯片的主要组成部分。</p><!-- ![](./A-28-nm-Configurable-Memory-TCAM-BCAM-SRAM-Using-Push-Rule-6T-Bit-Cell-Enabling-Logic-in-Memory/202184-222208.jpg) --><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-222208.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>但是传统的CAM存在一个严重的问题就是资源开销很大，无法高密度集成，比如一个BCAM需要10个晶体管，一个TCAM需要16个晶体管，如Fig. 2所示。<br><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-222641.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>因此本文能够使用6T SRAM紧凑的单元实现CAM的方案就显得非常有意义。同时，该论文在保留SRAM存储功能的基础上还实现了TCAM以及一些基础的逻辑操作（AND和NOR）。该论文不仅提出了实现方案，还通过一些精巧的设计保证了该设计的高性能，而且分析的面面俱到，是一个相当优秀的工作。</p><p>在此也先简单总结一下该设计的最终性能：基于6T 28nm FDSOI SRAM工艺，实现了$64\times 64 (4kb)$ BCAM，在1V工作电压下，BCAM的工作频率为370 MHz，能效为$0.5\ fJ/search/bit$，两个64-bit words的逻辑操作的频率达到787 MHz。</p><p>接下来开始介绍该工作的细节，受限简单介绍一下传统CAM搜索的原理。如Fig. 3所示，存储单元中的比特与输入的比特进行XNOR操作，然后同一根match line上的所有同或结果进行线与逻辑，最终通过SA输出匹配结果。在很多查找应用中，可能需要匹配多个结果，如果只需要单个地址，也可以对结果进行优先编码。<font color="blue">这里对搜索的结果进行优先编码也可能对今后的研究有一些启示，很多时候想用到优先编码，但是还没有遇到合适的场合。</font></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-224025.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>接下来看这篇论文提出的6T BCAM设计，如Fig. 4所示。该设计使用标准SRAM中的位线 作为match lines，使用WL表示搜索序列按列进行搜索匹配。而传统的SRAM存储功能仍然保持，可以动态配置成BCAM/TCAM/Logic/SRAM storage。为此，需要对电路进行一些特殊设计，以兼容多种模式，这些在本文中也一一进行了详细的介绍，之后我也会对一些关键的考虑进行简单的介绍。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-224830.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>从Fig. 4中，我们可以看到为了兼容CAM的功能，作者在传统的6T SRAM基础上进行了些微的改动，那就是将WL变为两根，WLR和WLL，分别对与BL和BLB相连的晶体管进行门控（这在Fig. 5中可以看得更加清楚）。文中对这一设计的代价总结为:</p><blockquote><p>“This creates two indeppendent access transistors but incur no area penalty since the push-rule layers are kept intact (i.e., only DRC-compliant metallization changes are made).”</p></blockquote><p><font color="blue">在这里重点指出这一点的原因在于：之前我在和其他人讨论类似的设计的时候，我想通过一根WL改进设计，大家觉得增加这一根线会对面积开销产生很大的影响，这与这边作者的观点相左，暂时看不懂这里为什么面积不会有很大的影响，今后的研究中可能会借鉴这个观点。</font></p><p>废话说完，开始真正介绍三种工作模式：</p><p><strong>1. BCAM</strong></p><p>Fig. 5展示的是该设计实现BCAM搜索的过程，Search string从WLR/WLL输入，当输入为1时，WLR=1，WLL=0，表明BL对应的门控晶体管开启，BLB对应的门控晶体管截止。如果对应的SRAM cell存的值为1，则BL对应的门控晶体管D/S端都为高电平，结果是BL和BLB的最终电位都为高，而如果存储的值为0，则BL预充的高电平会通过SRAM cell放电，从而将BL上电位下拉到0，BLB上电位仍然保持高电平。当输入为0时，工作情况类似，只是BLB对应的门控晶体管开启。因此同一条BL对应的SRAM cell只要有任意一比特无法跟search string bit匹配，BL或BLB会被下拉到低电平，最终与门输出为0，否则输出为1，表示完全匹配。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-230549.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Note:</p><ul><li>基于SRAM的CAM相对于忆阻器的CAM还有一个有点就是搜索的字长可以做到特别长，因为SRAM的off state可以做到几乎不漏电。</li><li>针对SRAM的读操作和BCAM的操作，SA的工作机制是不同的，该设计提出了一种SA，可以在不增加面积的基础上，实现可重构的两种功能的SA，如Fig. 6所示。<br><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-05002.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></li><li>SRAM是逐行写，CAM是对所有列进行匹配，数据需要逐列写。这要是在我看来就是不可能的，这个方案就放弃了，但是作者可能巧妙地解决了这一问题，不仅是磕盐的态度，对于行和列都要写的方案在今后的设计中也可以参考，毕竟有时候经常需要行/列都进行操作，比如矩阵的转置等等，比如从一个bank中逐行读出，逐列写入另一个bank。之前陈怡然也有一篇工作涉及到行列操作的CAM，也可以一起总结一下。这个按列去写刚好受益于有两根WL，这跟BL是等价的。逐行写数据从BL输入，逐列写数据从WL输入。</li><li>该工作还考虑了同时开启多行对SRAM cell中数据的破坏进行了分析，并提出了解决方案。</li></ul><p><strong>2. TCAM</strong></p><p>TCAM的工作原理如Fig. 11所示，由于TCAM中存在三种状态”1”, “0”, “X”，所以需要使用两比特来实现，相邻的两列表示一比特，其中存储”00”表示“0”，存储“11”表示“1”，存储“01”表示“X”，当存储的值为“01”是，左列的BLB对应的SRAM cell输出为“1”，右列的BL对应的SRAM输出也为“1”，因此无论输入是“0”还是“1”，都不会将BL或BLB下拉到低电平。<font color="blue">在其他文章中，认为该设计在实现TCAM时，只需要将WLR和WLL都设置为GND，这样使用BCAM同样的电路就可以实现TCAM的功能。而在本文中，作者自己竟然用了两倍的面积来实现TCAM的功能。不仔细看还会以为本文作者犯了一个错误，其实并不是这样子的。这是如何定义TCAM的一个问题。如果对于输入的某些bit进行mask的话，这样输入的这些bit与所有搜索项目的对应bit都不会去比较，个人感觉这种是比较常用的，但是对于优先编码等应用场合，这种就不适用了，需要将对应的某一搜索项的某些bit进行mask，这样就需要用到本文中所提出的方案，也没有去查TCAM的具体定义，可能这中才是真正的TCAM（杨老师Nature Electronics论文中也是实现的这种方式），以后研究过程中可以用这个电路。</font></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-15121.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><strong>3. Logic Operations</strong></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-15755.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该设计实现“AND”逻辑如Fig. 15所示，逻辑操作与存储相同，是以行为单位进行的。要对某两行进行逻辑操作，将对应的WL输入设置为“1”（即WLR=VDD, WLL=GND)，其他行WLL=WLR=GND进行MASK。开启的两行中对应的2个SRAM cell中只要有一个cell存储的值为0，就会将BL下拉到低电平，即实现了“AND”操作。“NOR”操作方式与“AND”类似，TABLE I总结了这两种操作的配置。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20434.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该设计的整体架构如Fig. 16所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20452.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>最后，放置一些实验结果，以对该设计的性能有一个更加深入的了解。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20730.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20753.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20813.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20832.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20851.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 挖坑待填 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决gem5运行时缺少pydot的问题</title>
      <link href="/2021/08/03/jie-jue-gem5-yun-xing-shi-que-shao-pydot-de-wen-ti/"/>
      <url>/2021/08/03/jie-jue-gem5-yun-xing-shi-que-shao-pydot-de-wen-ti/</url>
      
        <content type="html"><![CDATA[<h1 id="解决gem5运行时缺少pydot的问题"><a href="#解决gem5运行时缺少pydot的问题" class="headerlink" title="解决gem5运行时缺少pydot的问题"></a>解决gem5运行时缺少pydot的问题</h1><p>在运行gem5时，会显示：</p><blockquote><p>warn: No dot file generated. Please install pydot to generate the dot file and pdf.</p></blockquote><p>作为一个高度强迫症患者，实在无法忍受每次运行出现这个刺眼的warning，而且在进行系统仿真的时候，产生的config.dot.svg和config.dot.pdf等文件还可以可视化整个系统的架构，为此记录一下我解决这个问题的方法。</p><p>在网上搜索博客，基本上都是如下的<a href="https://blog.csdn.net/mjl960108/article/details/79981794">解决方案</a>：</p><blockquote><p>sudo apt install python-pydot python-pydot-ng graphviz</p></blockquote><p>但是运行时会事与愿违：</p><blockquote><p>root@9187b8755600:~/gem5/m5out# apt install python-pydot python-pydot-ng graphviz<br>Reading package lists… Done<br>Building dependency tree<br>Reading state information… Done<br>E: Unable to locate package python-pydot<br>E: Unable to locate package python-pydot-ng</p></blockquote><p>找不到安装包，也有博客指出需要使用pip命令安装，但是ubuntu自带的python无法找到pip命令，而也最好不要使用conda的虚拟python环境，因为无法定位到虚拟环境中的scons命令，这个我至今也没有解决，而是直接安装docker环境，配置python2.7和python3.8，用于不同版本的gem5，非常方便。</p><p>为此解决系统python环境缺少pydot的方法如下：</p><ol><li>下载<a href="https://pypi.org/project/pydot/#files">pydot源</a><blockquote><p>wget <a href="https://files.pythonhosted.org/packages/13/6e/916cdf94f9b38ae0777b254c75c3bdddee49a54cc4014aac1460a7a172b3/pydot-1.4.2.tar.gz">https://files.pythonhosted.org/packages/13/6e/916cdf94f9b38ae0777b254c75c3bdddee49a54cc4014aac1460a7a172b3/pydot-1.4.2.tar.gz</a></p></blockquote></li><li>解压文件</li><li>安装pydot<blockquote><p>python setup.py install (for python2.7)<br>python3 setup.py install (for python3.8)</p></blockquote></li></ol><p>完美解决！！！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>(转)Types of Memory Interleaving</title>
      <link href="/2021/07/30/zhuan-types-of-memory-interleaving/"/>
      <url>/2021/07/30/zhuan-types-of-memory-interleaving/</url>
      
        <content type="html"><![CDATA[<h1 id="转-Types-of-Memory-Interleaving"><a href="#转-Types-of-Memory-Interleaving" class="headerlink" title="(转)Types of Memory Interleaving"></a>(转)Types of Memory Interleaving</h1><p><a href="https://www.geeksforgeeks.org/memory-interleaving/">Memory Interleaving</a> is an abstraction technique which divides memory into a number of modules such that successive words in the address space are placed in the different module.</p><p>Suppose a 64 MB memory made up of the 4 MB chips as shown in the below:</p><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/1406-4.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>We organize the memory into 4 MB banks, each having eight of the 4 MB chips. The memory thus has 16 banks, each of 4 MB.</p><p>64 MB memory = $2^{26}$, so 26 bits are used for addressing.<br>16 = $2^4$, so 4 bits of address select the bank, and 4 MB = $2^{22}$, so 22 bits of address to each chip.</p><p>In general, an N-bit address, with $N = L + M$, is broken into two parts:</p><ol><li>L-bit bank select, used to activate one of the $2^L$ banks of memory, and</li><li>M-bit address that is sent to each of the memory banks.</li></ol><p>When one of the memory banks is active, the other ($2^L – 1$) are inactive. All banks receive the M-bit address, but the inactive one do not respond to it.</p><p><strong>Classification of Memory Interleaving:</strong><br>Memory interleaving is classified into two types:</p><ol><li><strong>High Order Interleaving –</strong> In high-order interleaving, the most significant bits of the address select the memory chip. The least significant bits are sent as addresses to each chip. One problem is that consecutive addresses tend to be in the same chip. The maximum rate of data transfer is limited by the memory cycle time.</li></ol><p>It is also known as Memory Banking.</p><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/223-1.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ol start="2"><li><strong>Low Order Interleaving –</strong> In low-order interleaving, the least significant bits select the memory bank (module). In this, consecutive memory addresses are in different memory modules. This allows memory access at much faster rates than allowed by the cycle time.</li></ol><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/3164-1.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>注：转载于<a href="https://www.geeksforgeeks.org/types-of-memory-interleaving/">https://www.geeksforgeeks.org/types-of-memory-interleaving/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CACTI 7.0介绍</title>
      <link href="/2021/07/29/cacti-7-0-jie-shao/"/>
      <url>/2021/07/29/cacti-7-0-jie-shao/</url>
      
        <content type="html"><![CDATA[<h1 id="CACTI-7-0介绍"><a href="#CACTI-7-0介绍" class="headerlink" title="CACTI 7.0介绍"></a>CACTI 7.0介绍</h1><h2 id="1-CACTI发展"><a href="#1-CACTI发展" class="headerlink" title="1. CACTI发展"></a>1. CACTI发展</h2><p>CACTI是HP公司推出的一款开源开源工具，广泛应用于对cache/DRAM的延时，功耗，cycle time[^1]和面积的评估。</p><p>[^1]: <font color="gray">(暂时不知道如何翻译比较好，感觉前面的延时指的是各个部分的延时信息，这边的cycle time应该指的是访问周期)</font></p><p>CACTI最初由Dr. Jouppi和Dr. Wilton于1993年开发，此后经历了六次版本的迭代。</p><h2 id="2-CACTI支持的特性"><a href="#2-CACTI支持的特性" class="headerlink" title="2. CACTI支持的特性"></a>2. CACTI支持的特性</h2><ul><li>以下memory的功耗、延时、cycle time的建模<ul><li>direct mapped caches</li><li>set-associative caches</li><li>fully associative caches</li><li>Embedded DRAM memories</li><li>Commodity DRAM memories</li></ul></li><li>多端口UCA(uniform cache access)，多端口的NUCA(non-uniform cache access)的建模</li><li>工作温度对泄露功耗的影响</li><li>路由功耗模型</li><li>具有不同延迟、功耗和面积属性的互连模型，包括低摆幅线模型</li><li>用于执行功率、延迟、面积和带宽之间权衡分析的接口</li><li>该工具使用的所有工艺特定值均从 ITRS 获得，目前该工具支持 90nm、65nm、45nm 和 32nm 技术节点</li><li>用于计算DDR总线延迟和能量的芯片IO模型。用户可以模拟不同的负载（扇出）并评估对频率和能量的影响。该模型可用于研究LR-DIMM、R-DIMM等。</li><li>Version 7.0在6.5版本的基础之上还融合了CACTI 3D</li></ul><h2 id="3-CACTI的使用方法"><a href="#3-CACTI的使用方法" class="headerlink" title="3. CACTI的使用方法"></a>3. CACTI的使用方法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/HewlettPackard/cacti</span><br><span class="line"><span class="built_in">cd</span> cacti</span><br><span class="line"><span class="comment"># modify the xxx.cfg for self configuration</span></span><br><span class="line">make</span><br><span class="line">./cacti -infile xxx.cfg</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows使用sftp获取服务器运行记录</title>
      <link href="/2021/07/25/windows-shi-yong-sftp-huo-qu-fu-wu-qi-yun-xing-ji-lu/"/>
      <url>/2021/07/25/windows-shi-yong-sftp-huo-qu-fu-wu-qi-yun-xing-ji-lu/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>函数的副作用</title>
      <link href="/2021/07/25/han-shu-de-fu-zuo-yong/"/>
      <url>/2021/07/25/han-shu-de-fu-zuo-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="转-函数的副作用"><a href="#转-函数的副作用" class="headerlink" title="(转)函数的副作用"></a>(转)函数的副作用</h1><p><strong>函数的副作用</strong>指当调用函数时，除了返回函数值之外，还对主调用函数产生附加的影响。例如修改全局变量（函数外的变量）或修改参数。</p><p>函数副作用会给程序设计带来不必要的麻烦，给程序带来十分难以查找的错误，并且降低程序的可读性。严格的函数式语言要求函数必须无副作用。</p><p>函数的副作用相关的几个概念， Pure Function、 Impure Function、 Referential Transparent。</p><ul><li><p><strong>纯函数 (Pure Function)</strong><br>输入输出数据流全是显式（Explicit）的。 显式（Explicit）的意思是，函数与外界交换数据只有一个唯一渠道——参数和返回值。函数从函数外部接受的所有输入信息都通过参数传递到该函数内部。函数输出到函数外部的所有信息都通过返回值传递到该函数外部。</p></li><li><p><strong>非纯函数 (Impure Function)</strong></p><p>与之相反。 隐式（Implicit）的意思是，函数通过参数和返回值以外的渠道，和外界进行数据交换。比如读取/修改全局变量，都叫作以隐式的方式和外界进行数据交换。</p></li><li><p><strong>引用透明 (Referential Transparent)</strong></p><p>引用透明的概念与函数的副作用相关，且受其影响。 如果程序中两个相同值得表达式能在该程序的任何地方互相替换，而不影响程序的动作，那么该程序就具有引用透明性。它的优点是比非引用透明的语言的语义更容易理解，不那么晦涩。纯函数式语言没有变量，所以它们都具有引用透明性。</p></li></ul><p>以下示例说明了引用透明与函数副作用的结合</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result1 = (fun(a) + b) / (fun(a) - c);</span><br><span class="line">temp = func(a);</span><br><span class="line">result2 = (temp + b) / (temp - c);</span><br></pre></td></tr></table></figure><p>如果函数没有副作用，那么result1和result2将是等价的。然而如果fun有副作用，比如让b或c加1，那么result1和result2将不相等。因此，副作用违背了引用透明性。</p><p>在JavaScript中，引入了函数。但显然JS中的函数可以访问、修改全局变量（或定义在函数外的变量），如下</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">5</span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fun</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">a = <span class="number">10</span>;</span><br><span class="line">&#125;</span><br><span class="line">fun();<span class="comment">// a变成了10</span></span><br></pre></td></tr></table></figure><p>JS中要想保证函数无副作用这项特性，只能依靠编程人员的习惯，即</p><ol><li><p>函数入口使用参数运算，而不修改它</p></li><li><p>函数内不修改函数外的变量，如全局变量</p></li><li><p>运算结果通过函数返回给外部（出口）</p></li></ol><blockquote><p>转载自：<a href="https://www.cnblogs.com/snandy/archive/2011/08/14/2137898.html">https://www.cnblogs.com/snandy/archive/2011/08/14/2137898.html</a></p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>(转)多核处理器的九大关键技术</title>
      <link href="/2021/07/23/zhuan-duo-he-chu-li-qi-de-jiu-da-guan-jian-ji-zhu/"/>
      <url>/2021/07/23/zhuan-duo-he-chu-li-qi-de-jiu-da-guan-jian-ji-zhu/</url>
      
        <content type="html"><![CDATA[<h1 id="转-多核处理器的九大关键技术"><a href="#转-多核处理器的九大关键技术" class="headerlink" title="(转)多核处理器的九大关键技术"></a>(转)多核处理器的九大关键技术</h1><p>与单核处理器相比，多核处理器在体系结构、软件、功耗和安全性设计等方面面临着巨大的挑战，但也蕴含着巨大的潜能。</p><p>CMP和SMT一样，致力于发掘计算的粗粒度并行性。CMP可以看做是随着大规模集成电路技术的发展，在芯片容量足够大时，就可以将大规模并行处理机结构中的SMP（对称多处理机）或DSM（分布共享处理机）节点集成到同一芯片内，各个处理器并行执行不同的线程或进程。在基于SMP结构的单芯片多处理机中，处理器之间通过片外Cache或者是片外的共享存储器来进行通信。而基于DSM结构的单芯片多处理器中，处理器间通过连接分布式存储器的片内高速交叉开关网络进行通信。由于SMP和DSM已经是非常成熟的技术了，CMP结构设计比较容易，只是后端设计和芯片制造工艺的要求较高而已。正因为这样，CMP成为了最先被应用于商用CPU的“未来”高性能处理器结构。</p><p>虽然多核能利用集成度提高带来的诸多好处，让芯片的性能成倍地增加，但很明显的是原来系统级的一些问题便引入到了处理器内部。</p><ol><li><p>核结构研究: 同构还是异构</p><p>CMP的构成分成同构和异构两类，同构是指内部核的结构是相同的，而异构是指内部的核结构是不同的。为此，面对不同的应用研究核结构的实现对未来微处理器的性能至关重要。核本身的结构，关系到整个芯片的面积、功耗和性能。怎样继承和发展传统处理器的成果，直接影响多核的性能和实现周期。同时，根据Amdahl定理，程序的加速比决定于串行部分的性能，所以，从理论上来看似乎异构微处理器的结构具有更好的性能。</p><p>核所用的指令系统对系统的实现也是很重要的，采用多核之间采用相同的指令系统还是不同的指令系统，能否运行操作系统等，也将是研究的内容之一。</p></li><li><p>程序执行模型</p><p>多核处理器设计的首要问题是选择程序执行模型。程序执行模型的适用性决定多核处理器能否以最低的代价提供最高的性能。程序执行模型是编译器设计人员与系统实现人员之间的接口。编译器设计人员决定如何将一种高级语言程序按一种程序执行模型转换成一种目标机器语言程序; 系统实现人员则决定该程序执行模型在具体目标机器上的有效实现。当目标机器是多核体系结构时，产生的问题是: 多核体系结构如何支持重要的程序执行模型？是否有其他的程序执行模型更适于多核的体系结构？这些程序执行模型能多大程度上满足应用的需要并为用户所接受？</p></li><li><p>Cache设计: 多级Cache设计与一致性问题</p><p>处理器和主存间的速度差距对CMP来说是个突出的矛盾，因此必须使用多级Cache来缓解。目前有共享一级Cache的CMP、共享二级Cache的CMP以及共享主存的CMP。通常，CMP采用共享二级Cache的CMP结构，即每个处理器核心拥有私有的一级Cache，且所有处理器核心共享二级Cache。</p><p>Cache自身的体系结构设计也直接关系到系统整体性能。但是在CMP结构中，共享Cache或独有Cache孰优孰劣、需不需要在一块芯片上建立多级Cache，以及建立几级Cache等等，由于对整个芯片的尺寸、功耗、布局、性能以及运行效率等都有很大的影响，因而这些都是需要认真研究和探讨的问题。</p><p>另一方面，多级Cache又引发一致性问题。采用何种Cache一致性模型和机制都将对CMP整体性能产生重要影响。在传统多处理器系统结构中广泛采用的Cache一致性模型有: 顺序一致性模型、弱一致性模型、释放一致性模型等。与之相关的Cache一致性机制主要有总线的侦听协议和基于目录的目录协议。目前的CMP系统大多采用基于总线的侦听协议。</p></li><li><p>核间通信技术</p><p>CMP处理器的各CPU核心执行的程序之间有时需要进行数据共享与同步，因此其硬件结构必须支持核间通信。高效的通信机制是CMP处理器高性能的重要保障，目前比较主流的片上高效通信机制有两种，一种是基于总线共享的Cache结构，一种是基于片上的互连结构。</p><p>总线共享Cache结构是指每个CPU内核拥有共享的二级或三级Cache，用于保存比较常用的数据，并通过连接核心的总线进行通信。这种系统的优点是结构简单，通信速度高，缺点是基于总线的结构可扩展性较差。</p><p>基于片上互连的结构是指每个CPU核心具有独立的处理单元和Cache，各个CPU核心通过交叉开关或片上网络等方式连接在一起。各个CPU核心间通过消息通信。这种结构的优点是可扩展性好，数据带宽有保证; 缺点是硬件结构复杂，且软件改动较大。</p><p>也许这两者的竞争结果不是互相取代而是互相合作，例如在全局范围采用片上网络而局部采用总线方式，来达到性能与复杂性的平衡。</p></li><li><p>总线设计</p><p>传统微处理器中，Cache不命中或访存事件都会对CPU的执行效率产生负面影响，而总线接口单元（BIU）的工作效率会决定此影响的程度。当多个CPU核心同时要求访问内存或多个CPU核心内私有Cache同时出现Cache不命中事件时，BIU对这多个访问请求的仲裁机制以及对外存储访问的转换机制的效率决定了CMP系统的整体性能。因此寻找高效的多端口总线接口单元（BIU）结构，将多核心对主存的单字访问转为更为高效的猝发（burst）访问; 同时寻找对CMP处理器整体效率最佳的一次Burst访问字的数量模型以及高效多端口BIU访问的仲裁机制将是CMP处理器研究的重要内容。</p></li><li><p>操作系统设计: 任务调度、中断处理、同步互斥</p><p>对于多核CPU，优化操作系统任务调度算法是保证效率的关键。一般任务调度算法有全局队列调度和局部队列调度。前者是指操作系统维护一个全局的任务等待队列，当系统中有一个CPU核心空闲时，操作系统就从全局任务等待队列中选取就绪任务开始在此核心上执行。这种方法的优点是CPU核心利用率较高。后者是指操作系统为每个CPU内核维护一个局部的任务等待队列，当系统中有一个CPU内核空闲时，便从该核心的任务等待队列中选取恰当的任务执行，这种方法的优点是任务基本上无需在多个CPU核心间切换，有利于提高CPU核心局部Cache命中率。目前多数多核CPU操作系统采用的是基于全局队列的任务调度算法。</p><p>多核的中断处理和单核有很大不同。多核的各处理器之间需要通过中断方式进行通信，所以多个处理器之间的本地中断控制器和负责仲裁各核之间中断分配的全局中断控制器也需要封装在芯片内部。</p><p>另外,多核CPU是一个多任务系统。由于不同任务会竞争共享资源，因此需要系统提供同步与互斥机制。而传统的用于单核的解决机制并不能满足多核，需要利用硬件提供的“读－修改－写”的原子操作或其他同步互斥机制来保证。</p></li><li><p>低功耗设计</p><p>半导体工艺的迅速发展使微处理器的集成度越来越高，同时处理器表面温度也变得越来越高并呈指数级增长，每三年处理器的功耗密度就能翻一番。目前，低功耗和热优化设计已经成为微处理器研究中的核心问题。CMP的多核心结构决定了其相关的功耗研究是一个至关重要的课题。</p><p>低功耗设计是一个多层次问题，需要同时在操作系统级、算法级、结构级、电路级等多个层次上进行研究。每个层次的低功耗设计方法实现的效果不同——抽象层次越高，功耗和温度降低的效果越明显。</p></li><li><p>存储器墙</p><p>为了使芯片内核充分地工作，最起码的要求是芯片能提供与芯片性能相匹配的存储器带宽，虽然内部Cache的容量能解决一些问题，但随着性能的进一步提高，必须有其他一些手段来提高存储器接口的带宽，如增加单个管脚带宽的DDR、DDR2、QDR、XDR等。同样，系统也必须有能提供高带宽的存储器。所以，芯片对封装的要求也越来越高，虽然封装的管脚数每年以20%的数目提升，但还不能完全解决问题，而且还带来了成本提高的问题，为此，怎样提供一个高带宽，低延迟的接口带宽，是必须解决的一个重要问题。</p></li><li><p>可靠性及安全性设计</p><p> 随着技术革新的发展，处理器的应用渗透到现代社会的各个层面，但是在安全性方面却存在着很大的隐患。一方面，处理器结构自身的可靠性低下，由于超微细化与时钟设计的高速化、低电源电压化，设计上的安全系数越来越难以保证，故障的发生率逐渐走高。另一方面，来自第三方的恶意攻击越来越多，手段越来越先进，已成为具有普遍性的社会问题。现在，可靠性与安全性的提高在计算机体系结构研究领域备受注目。</p></li></ol><p>转载于:<a href="http://blog.itpub.net/312079/viewspace-245322/">http://blog.itpub.net/312079/viewspace-245322/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux Tools Mannual</title>
      <link href="/2021/07/22/linux-tools-mannual/"/>
      <url>/2021/07/22/linux-tools-mannual/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux-常用工具使用命令速查表"><a href="#Linux-常用工具使用命令速查表" class="headerlink" title="Linux 常用工具使用命令速查表"></a>Linux 常用工具使用命令速查表</h1><h2 id="tmux"><a href="#tmux" class="headerlink" title="tmux"></a>tmux</h2><h3 id="tmu常用操作指令及快捷键"><a href="#tmu常用操作指令及快捷键" class="headerlink" title="tmu常用操作指令及快捷键"></a>tmu常用操作指令及快捷键</h3><ol><li>查看有所有tmux会话<br>指令：tmux ls<br>快捷键：Ctrl+b s</li><li>新建tmux窗口<br>指令：tmux new -s <session-name></session-name></li><li>重命名会话<br>指令：tmux rename-session -t <old-name> <new-name><br>快捷键：Ctrl+b $</new-name></old-name></li><li>分离会话<br>指令：tmux detach/exit(关闭窗口，杀死会话)<br>快捷键：Ctrl+b d</li><li>平铺当前窗口<br>快捷键：Ctrl+b z(再次Ctrl+b d恢复)</li><li>杀死会话<br>指令：tmux kill-session -t <session-name></session-name></li><li>切换会话<br>指令：tmux switch -t <session-name></session-name></li><li>划分上下两个窗格<br>指令：tmux split<br>快捷键：Ctrl+b “</li><li>划分左右两个窗格<br>指令：tmux split -h<br>快捷键：Ctrl+b %</li><li>光标切换到上方窗格<br>指令：tmux select-pane -U<br>快捷键：Ctrl+b 方向键上</li><li>光标切换到下方窗格<br>指令：tmux select-pane -D<br>快捷键：Ctrl+b 方向键下</li><li>光标切换到左边窗格<br>指令：tmux select-pane -L<br>快捷键：Ctrl+b 方向键左</li><li>光标钱换到右边窗格<br>指令：tmux select-pane -R<br>快捷键：Ctrl+b 方向键右</li></ol><p><a href="https://zhuanlan.zhihu.com/p/90464490">https://zhuanlan.zhihu.com/p/90464490</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
