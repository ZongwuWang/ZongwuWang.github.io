<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>A 65-nm 0.6-fJ/Bit/Search Ternary Content Addressable Memory Using an Adaptive Match-Line Discharge</title>
      <link href="/2021/09/09/a-65-nm-0-6-fj-bit-search-ternary-content-addressable-memory-using-an-adaptive-match-line-discharge/"/>
      <url>/2021/09/09/a-65-nm-0-6-fj-bit-search-ternary-content-addressable-memory-using-an-adaptive-match-line-discharge/</url>
      
        <content type="html"><![CDATA[<h1 id="A-65-nm-0-6-fJ-Bit-Search-Ternary-Content-Addressable-Memory-Using-an-Adaptive-Match-Line-Discharge"><a href="#A-65-nm-0-6-fJ-Bit-Search-Ternary-Content-Addressable-Memory-Using-an-Adaptive-Match-Line-Discharge" class="headerlink" title="A 65-nm 0.6-fJ/Bit/Search Ternary Content Addressable Memory Using an Adaptive Match-Line Discharge"></a>A 65-nm 0.6-fJ/Bit/Search Ternary Content Addressable Memory Using an Adaptive Match-Line Discharge</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>用于完全并行搜索操作的匹配线 (ML) 和搜索线 (SL) 的大量切换是以巨大的动态功耗为代价的。此外，随着内存容量和时钟速度的增加，CAM 设计变得更加难以满足功耗和性能预算。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/09/a-65-nm-0-6-fj-bit-search-ternary-content-addressable-memory-using-an-adaptive-match-line-discharge/202199-160318.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>如图1所示，传统的CAM设计存在三点挑战：</p><ol><li>多有访问条目每个周期都会改变具有大寄生电容布线的电压，这会导致巨大的功耗并产生大量的热量；</li><li>由失配数量的差异，entry之间具有不同的感知延迟，导致搜索性能下降；</li><li>由于所有访问entry的搜索操作的行数(ML和SL)多，因此阵列密度低。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Memory sizing of a scalable SRAM in-memory computing tile based architecture</title>
      <link href="/2021/09/09/memory-sizing-of-a-scalable-sram-in-memory-computing-tile-based-architecture/"/>
      <url>/2021/09/09/memory-sizing-of-a-scalable-sram-in-memory-computing-tile-based-architecture/</url>
      
        <content type="html"><![CDATA[<h1 id="Memory-sizing-of-a-scalable-SRAM-in-memory-computing-tile-based-architecture"><a href="#Memory-sizing-of-a-scalable-SRAM-in-memory-computing-tile-based-architecture" class="headerlink" title="Memory sizing of a scalable SRAM in-memory computing tile based architecture"></a>Memory sizing of a scalable SRAM in-memory computing tile based architecture</h1><h2 id="Motivation-and-Key-Ideas-of-This-Work"><a href="#Motivation-and-Key-Ideas-of-This-Work" class="headerlink" title="Motivation and Key Ideas of This Work"></a>Motivation and Key Ideas of This Work</h2><p>本文作者根据给定的缓存大小研究了一组应用程序，结果表明单个缓存实例不足以包含大型数据集，并且需要多个具有线互连的缓存实例。</p><p>本文提出了一种根据支持IMC的应用程序集来评估以数据为中心的架构的互连成本的方法，目的是创建一个连线模型。与完整的布局布线设计流程相比，该模型的新颖性为存储器设计人员提供了更精确的尺寸和更快的估计。</p><p><strong>Achievements:</strong> 通过将缓存拆分为多个子块，与单个大型 IMC 内存实例相比，我们可以实现更低的能量（高达 78% 的增益）和更快（高达 49% 的增益）的 IMC 块。</p><h2 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/09/memory-sizing-of-a-scalable-sram-in-memory-computing-tile-based-architecture/202199-150754.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>这边相关的工作就不过多介绍了，都是一些比较经典的相关论文。但是这边的图1比较有意思。可以看出作者将数据中心计算的解决方案分为了四类，分别是：IMC，IMC++，NMC和PE，分别对应着不同的加速粒度/复杂度。</p><h2 id="IMC的应用探索"><a href="#IMC的应用探索" class="headerlink" title="IMC的应用探索"></a>IMC的应用探索</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/09/memory-sizing-of-a-scalable-sram-in-memory-computing-tile-based-architecture/202199-154524.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>本文选取的应用以及操作占比如表1所示。这边结果的提取方式比较有意义，应用的是基于LLVM的一个框架<a href="#refer-anchor-1"><sup>1</sup></a><sup>,</sup><a href="#refer-anchor-2"><sup>2</sup></a>，有空可以学习一下。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id="refer-anchor-1"></div>- [1]     M. Kooli, H. Charles, C. Touzet, B. Giraud, and J. Noël, "Software Platform Dedicated for In-Memory Computing Circuit Evaluation," in 2017 International Symposium on Rapid System Prototyping (RSP), 19-20 Oct. 2017 2017, pp. 43-49. <div id="refer-anchor-2"></div>- [2]     M. Kooli, H. Charles, C. Touzet, B. Giraud, and J. Noel, "Smart instruction codes for in-memory computing architectures compatible with standard SRAM interfaces," in 2018 Design, Automation & Test in Europe Conference & Exhibition (DATE), 19-23 March 2018 2018, pp. 1634-1639, doi: 10.23919/DATE.2018.8342276. ]]></content>
      
      
      
        <tags>
            
            <tag> 未完待续 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FReaC Cache: Folded-logic Reconfigurable Computing in the Last Level Cache</title>
      <link href="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/"/>
      <url>/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/</url>
      
        <content type="html"><![CDATA[<h1 id="FReaC-Cache-Folded-logic-Reconfigurable-Computing-in-the-Last-Level-Cache"><a href="#FReaC-Cache-Folded-logic-Reconfigurable-Computing-in-the-Last-Level-Cache" class="headerlink" title="FReaC Cache: Folded-logic Reconfigurable Computing in the Last Level Cache"></a>FReaC Cache: Folded-logic Reconfigurable Computing in the Last Level Cache</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>不断提出的加速器工作会面临一些问题：在哪里放置这些加速器？如何向它们提供数据？</p><p>本文中举了两个例子：</p><ol><li>PCIe连接的加速器以有限的带宽访问系统内存中的数据，例如PCIe 3.0 x16中的带宽为16GB/s，但是PCIe系统驱动程序会在每个加速器事务中产生数万条指令，从而导致更长的延迟和带宽损失。因此，每次DMA传输的成本在1μs到160μs之间。此外，连接PCIe的卡会消耗额外的功率，最近的一项研究指出，连接PCIe的FPGA在空闲时消耗12W。</li><li>片上和片下memory性能存在很大差距，从片下DRAM中取数需要56ns，消耗28-45pJ/bit (40nm)的能量。相比之下，从片上32K-word的SRAM阵列中读取16 bits只需要消耗11pJ。</li></ol><p>在边缘计算场景中，工作集的大小可能足够小，以至于来回穿梭数据所花费的时间和精力使得许多应用不希望使用off-chip和off-die加速器。</p><p>为了应对这些挑战，我们寻求在能效、成本和性能之间提供一个中间地带，以对现有系统、处理器和内存架构进行有限更改的方式。</p><p>因此本文提出了RReaC架构，该架构利用现有的LLC来构建加速器，大概思路是使用LLC的SRAM构建查找表，从而可以实现基于查找表的可重构加速器。此外，该论文还使用了logic folding技术，但是这也是以时间换空间的方法。</p><p>该论文的目标是卸载小而重要的内核，这些内核将从定制的加速器逻辑以及FReaC Cache的高吞吐量和高带宽中受益。</p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><h3 id="LLC设计"><a href="#LLC设计" class="headerlink" title="LLC设计"></a>LLC设计</h3><p>该段介绍的LLC设计参考自原文中参考文献[36]，并且从[36][38][39][40]可以看出Intel LLC从UCA到NUCA的发展，有空可以总结一下。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202198-213747.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图1说明了20路组相联的2.5MB缓存切片组织，每个切片(slice)有多个数据阵列(data array, DA)组成，以平铺方式组织在四个象限中。每一路由来自每个象限的单个数据阵列组成，即每路由四个数据阵列以及一个Tag/State和CV(valid)/LRU数组。Control box单元位于缓存的中间，负责所有控制操作、一致性和互连接口。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202198-213802.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>每个 32KB 数据阵列由两个 16KB 子阵列组成，每个子阵列都有一个 32 位端口。图 2 展示了子阵列（SA）的微架构。子阵列由32个bit-slice组成，每个slice为子阵列输出贡献1 bit，并由两个块组成。</p><p>从图2中我们可以得到以下计算公式：</p><p>$$16KB = 32\ bit\ slices = 32 \times 2\ Chunks\ = 32 \times 2 \times 4\ sets = 32 \times 2 \times 4 \times 512\ bits$$</p><p>在本文中，系统LLC的总容量为1.25MB，因此每个SA为8KB。</p><p>考虑到这种架构，我们提出了四个观察结果：</p><ol><li>SA的组织，使得在缓存数据数组中引入任何新逻辑都非常昂贵。</li><li>子阵列以lock-step方式按way运行，并行访问它们的单元。</li><li>由于缓存线在多路数据阵列之间不交错，因此可以独立访问、修改甚至关闭各个路。</li><li>虽然高速缓存访问可能需要几个周期，但单个数据阵列操作只有1到2个周期，而位线感测是1个周期长。数据数组以某种方式共享数据总线，从而串行化缓存线读取和写入。</li></ol><h3 id="可重构架构"><a href="#可重构架构" class="headerlink" title="可重构架构"></a>可重构架构</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202198-220410.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>现场可编程门阵列 (FPGA) 实际上是可重构计算的同义词，可以通过多种方式实现。通常，FPGA 由一系列逻辑块组成，即可配置逻辑块 (CLB)，以岛状布局组织，具有可编程布线结构，例如开关盒 (SB) 和连接盒 (CB)，提供每个模块之间的互连。如图3所示。CLB由几个基本逻辑元件 (BLE) 组成，每个基本逻辑元件包括一个查找表 (LUT) 和一个触发器。现代 FPGA 还包括特殊 IO（输入/输出）、DSP 和内存块。FPGA LUT 由多路复用器树或复用树和 SRAM 配置存储器组成，SRAM 配置存储器存储 LUT 实现的布尔函数的配置位。因此，K 输入 LUT 或 K-LUT 将需要 2<sup>K</sup> SRAM 单元来存储其功能。图3(c) 展示了一个 3-LUT。连接 CLB 的全局布线结构，例如开关盒和互连线，是 FPGA 中延迟的主要来源，并且可以占据近 80% 的面积。</p><h3 id="逻辑折叠-Logic-Folding"><a href="#逻辑折叠-Logic-Folding" class="headerlink" title="逻辑折叠(Logic Folding)"></a>逻辑折叠(Logic Folding)</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202198-220829.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>逻辑折叠利用动态重新配置，通过随时间折叠电路并跨时间共享可用逻辑资源，即时间流水线，允许使用有限的逻辑资源实现大型电路。因此，可以在较小的区域内实现相对较大的电路，尽管延迟较长。在图 4(a)中，图中的每个节点都是组合电路中的查找表 (LUT)。通过将图划分为四个级别，我们现在可以将每个级别实现为时间流水线的状态，从而只需要三个 LUT 而不是十个，但将延迟增加到四个时间步长。在每个时间步长，必须重新配置三个 LUT 以实现下一级别的操作。因此，如果我们可以重新配置每个周期，则可以在 4 个周期内实现该电路。 级别之间的相关性由锁存输出处理。</p><h2 id="FReaC-Cache"><a href="#FReaC-Cache" class="headerlink" title="FReaC Cache"></a>FReaC Cache</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202199-10654.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>FReC Cache 建立在两个关键思想之上：</p><ol><li>通过将 LLC 的 SRAM 用于 LUT 配置存储器，并通过最小化复杂的全局布线，可以实现密集的可重配置逻辑。</li><li>逻辑折叠允许我们用延迟（时钟周期）来减少每个周期的资源需求，以便映射电路。 高频抵消了折叠过程中产生的延迟损失。</li></ol><p>图 5 对单个LLC切片的FReaC Cache端到端操作进行了六个步骤的高层次概述。</p><ol><li>为了利用FReac Cache作为加速器，必须选择LLC的一部分作为加速器运行。</li><li>由于整个路都用于形成计算逻辑，因此必须刷新所选路中的脏行。</li><li>选定的方式被锁定为计算模式。请注意，为了刷新和锁定缓存方式，我们通过在现有的缓存控制框架中引入我们自己的计算集群控制器(CC Ctrl)。主机仅通过本机加载和存储(LD/ST)指令与CC Ctrl单元交互。</li><li>为计算模式准备SRAM way后，我们写入(加载)加速器配置比特。</li><li>如果需要，主机可以在开始计算之前填充暂存器并配置任何偏移量。</li><li>最后，主机通过LD/ST向CC Ctrl单元发出运行命令，并等待操作完成。一旦加速器完成，就可以通过重复步骤4和5对一组新的加速器进行编程或将新数据提供给现有的一组加速器。</li></ol><h3 id="Dense-Compute-Sub-Arrays"><a href="#Dense-Compute-Sub-Arrays" class="headerlink" title="Dense Compute Sub-Arrays"></a>Dense Compute Sub-Arrays</h3><p>从图3(c)可以看出LUT由SRAM配置比特位和mux-tree组成，LLC的sub-array能够通过每一次访问读取固定比特的数据，因此sub-array的每一行可以存储一个或多个LUT的配置信息，通过逐行读取sub-array的值，可以实现不同的LUTs。因此每次访问可以实现不同的逻辑操作。也就是说，子阵列的每一行都可以在逻辑折叠中实现一个时间流水线阶段。</p><p>为了实现这一点，子阵列通过存储器锁存器与多路复用树配对，如图4(b)所示。缓存锁存器与复用树一起形成了一个单一的查找表。请注意，复用树的输入是LUT输入。在读取新行时，LUT被重新配置以执行新操作。由于子阵列比较小，每次访问都可以在一个周期内进行。</p><p>因此，我们可以在每个周期动态重新配置 LUT。 由于单个 LUT 可能不足以实现布尔电路，因此可以将 LUT 的输出存储在状态锁存器中，以便在稍后的时间步长反馈到另一个 LUT 的输入中。 至关重要的是，复用树、锁存器和其他额外逻辑位于子阵列的外部，不会干扰现有的存储器设计。</p><p>从图4(b)可以看出，由于每一行存储32 bits，因此可以配置一个5输入LUT，或2个4输入LUT，或4个3输入LUT。</p><h3 id="微计算集群"><a href="#微计算集群" class="headerlink" title="微计算集群"></a>微计算集群</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202199-11806.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>单个计算子阵列可能需要大量折叠周期才能实现逻辑折叠电路。因此，我们建议通过将每两个相邻数据阵列分组，将计算子阵列组织成微计算集群(MCC)。即四个子阵列，组成一个微计算集群，如图6(b)所示。在微计算集群内，每个子阵列借助锁存器和放置在子阵列外部的多路复用树，在每个周期激活一个或多个LUT。为了让每个计算子阵列实现的LUT一起运行，我们还在集群中添加了一个操作数交叉开关，类似于FPGA的CLB中的那种。接下来，我们提供一小部分寄存器来存储来自折叠电路的中间状态并在原始设计中实现时序逻辑。最后，由于使用LUT实现乘法等算术运算的成本很高，因此我们还添加了专用的整数乘法累加(MAC)单元。引入的附加逻辑结构放置在子阵列之外，并在两个数据阵列之间间隔开。因此，我们不会影响记忆的区域或时间。</p><h4 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h4><p>现在可以通过从每个子阵列加载新配置，逐个周期地实现电路的每一级，在微计算集群内实现逻辑折叠电路。为了简化这一点，我们将每个级别的配置位存储在子阵列中的顺序地址中，并重用现有的地址总线来遍历地址。步数（折叠级别）由逻辑折叠计划决定。调度由我们添加到缓存控制箱的微型计算集群控制器 (CC Ctrl) 单元执行和管理。接下来，在每个时间步长，操作数可以缓存在寄存器或 LUT 中或从总线中提取。操作数交叉开关促进了这种移动，它必须为每个时间步长配置，由调度决定。因此，交叉开关也需要配置位，这些配置位存储在路的标记/状态数组中，在路用于计算时不使用。因此，我们不需要额外的配置内存。</p><h4 id="物理设计注意事项"><a href="#物理设计注意事项" class="headerlink" title="物理设计注意事项"></a>物理设计注意事项</h4><h3 id="可重构计算切片的操作"><a href="#可重构计算切片的操作" class="headerlink" title="可重构计算切片的操作"></a>可重构计算切片的操作</h3><p>图 6a说明了具有微计算集群的LLC切片。出于说明目的，我们展示了8个CC tiles，其中显示了五个tiles及其所有逻辑组件——两个数据阵列和集群逻辑 (CL)。集群逻辑包括锁存器、复用树、MAC 单元、寄存器和交叉开关，如图 6b所示。请注意，由于微计算集群是通过两路方式使用DA构建的，因此一次完全消耗两路Cache，因此在它们的位置形成四个计算集群(MCC)切片。<font color="red">为了获得最大的灵活性，我们将集群逻辑添加到所有DA对中。这允许我们按需使用整个缓存切片或仅使用切片的一小部分，有效地对切片进行动态分区和重新配置，以启用计算逻辑。(怎么理解？)</font>我们还在切片的控制盒中引入了一个计算集群控制器（CC Ctrl）单元，以协助锁定和刷新方式，以及集群的控制和协调。 CC Ctrl 利用缓存控制器的现有功能和机制来完成其任务。来自内核的传入请求由 LLC 控制器提供服务，即使缓存的一部分用于计算，CC Ctrl 单元也不会干扰。如果整个 LLC 都用于计算，那么核心请求将被视为未命中，并转发到内存。</p><h4 id="主机接口"><a href="#主机接口" class="headerlink" title="主机接口"></a>主机接口</h4><p>FReC Cache不需要自定义指令。主机通过加载和存储(LD/ST)操作与加速器和CC Ctrl单元交互。每个切片的地址范围是为FReaC缓存操作保留的，以便CC Ctrl单元的控制寄存器暴露给主机内核。主机通过写入CC Ctrl单元中的控制寄存器来设置LLC切片以进行计算。此设置包括选择、刷新和锁定计算方式（图5中的步骤1、2和3）。为了配置加速器，主机将微计算集群配置数据写入CC Ctrl Unit中的指定地址，然后将配置数据写入集群子阵列（步骤4）。然后，主机可以填充暂存缓冲区（稍后讨论），并通过写入另一个地址范围来设置加速器地址偏移量（步骤5）。同样，CC Ctrl单元负责将数据转发到相应的子阵列中。最后，还分配了一个运行寄存器（步骤6）。这些控制和数据寄存器对于缓存片是唯一的，并且每个片必须执行一次设置和配置。地址空间和控制寄存器可以通过有限的操作系统支持暴露给用户代码。在内核驱动程序的帮助下，可以为物理地址范围分配虚拟地址（ioremap()操作），然后通过字符设备驱动程序暴露给用户空间，用户程序可以通过mmap()操作访问该驱动程序.</p><h4 id="设置和配置"><a href="#设置和配置" class="headerlink" title="设置和配置"></a>设置和配置</h4><p>图5中的步骤1、2和3概述了如何为计算设置LLC切片。首先，必须选择和刷新方式，然后锁定计算模式。启用此功能的机制已在现代LLC中可用，并由CC Ctrl单元利用。缓存中的路是相互独立的，因此可以指示缓存控制逻辑忽略一组路。LLC已经包含睡眠逻辑以节省功率，以及熔断位以在良率低或制造缺陷的情况下关闭。现有的LLC还可以专门为单个内核分配缓存方式，从而修改其他内核看到的有效LLC。但是，在将路配置为计算之前，必须清除脏缓存行中的路。清除路径的开销取决于几个因素，包括：包含策略、缓存层次结构、内存带宽以及有多少行是脏的。在最坏的情况下，如果必须刷新LLC中的所有行，则刷新速度会受到片外存储器带宽的限制。对于10MB的LLC，这可能是数百微秒的数量级。一旦通道被刷新并锁定到计算模式，它们就不会参与缓存。其余方式继续作为LLC的一部分运作。然后，主机可以通过切片中的CC Ctrl单元将配置位（图5中的步骤4）写入微计算集群。一旦加载了加速器的配置位，除非配置被驱逐或覆盖，否则不需要再次获取它们。</p><h3 id="加速器操作"><a href="#加速器操作" class="headerlink" title="加速器操作"></a>加速器操作</h3><h3 id="Large-Micro-Compute-Clusters-and-Multi-Cores"><a href="#Large-Micro-Compute-Clusters-and-Multi-Cores" class="headerlink" title="Large Micro Compute Clusters and Multi-Cores"></a>Large Micro Compute Clusters and Multi-Cores</h3><p>FReaC Cache是一种分块架构，其中每个微计算集群(CC)可以通过将加速器电路映射到其上来操作自己的独立计算单元（加速器分块），如图5所示。为此，加速器电路被折叠和调度，每个时间步都被映射到LUT、MAC和触发器（第四节）。在每个时间步上，集群最多可以访问四个5-LUT或八个4-LUT、一个MAC和一个总线操作。微计算集群以某种方式共享地址总线，从而以锁步方式运行。为了进一步简化设计，并尽可能多地重用结构，我们将所有簇的地址线连接起来。由于所有集群都运行相同的加速器并具有相同的调度，因此所有加速器块都以锁步方式运行。如前所述，CC Ctrl单元负责逐步执行调度并在地址总线上广播集群的下一个地址。</p><h4 id="操作数移动"><a href="#操作数移动" class="headerlink" title="操作数移动"></a>操作数移动</h4><p>为了提供对外部操作数的访问，我们建议使用数据总线之一作为操作数数据路径（图6b）。集群首先将操作数的地址放在总线上，总线将地址传送到CC Ctrl单元。CC Ctrl单元处理地址，在需要时应用任何偏移量，并将其移交给要服务的缓存控制器。如果缓存切片在本地命中，则操作数将通过相同的数据总线转发回集群。写入请求遵循类似的过程。由于集群以锁步方式运行，因此可能一次接收多个请求，并且集群将停止直到所有请求都得到服务。与CPU内核不同，集群等待写回完成。在读取和写入两种情况下，缓存负责合并请求（如果有能力的话）。由于数据数组共享一条总线，请求和响应可能需要跨多个周期进行序列化。</p><h4 id="FReC-缓存暂存器"><a href="#FReC-缓存暂存器" class="headerlink" title="FReC 缓存暂存器"></a>FReC 缓存暂存器</h4><p>为了充分利用FReaC Cache的功能，我们引入了对暂存器的支持。通过锁定缓存中的路径，我们允许 CC Ctrl以为暂存器保留的方式将加速器加载和存储路由到子阵列。使用现有的缓存线映射，每次可以从每路加载总共32个字节。然而，由于子阵列之间的共享数据总线和缓存控制盒中的窄数据路径，字的传递是串行化的。我们使用处理器内核来填充暂存器，从而使内核能够将数据直接初始化到暂存器中。这样做，我们避免了从上层缓存中刷新数据的需要，以及将数据复制到暂存器的开销（图5中的步骤5）。FReaC Cache不需要暂存器，但大多数加速器使用本地暂存器来提高性能和功耗。此外，暂存器有助于解决LLC无法访问TLB的问题，这会增加开销。如果没有暂存器或访问TLB，FReaC Cache将需要：(1) 工作集从上层缓存中清除，(2) 加速器运行时内核不接触数据，(3) 内核提供物理地址，(4) 数据是连续的，页面被固定在主机内存中。</p><h3 id="大型微计算集群和多核"><a href="#大型微计算集群和多核" class="headerlink" title="大型微计算集群和多核"></a>大型微计算集群和多核</h3><h4 id="启用更大的计算集群"><a href="#启用更大的计算集群" class="headerlink" title="启用更大的计算集群"></a>启用更大的计算集群</h4><p>通过将加速器限制为单个微计算集群，我们将它们限制为每个周期4到8个LUT（假设有5输入或4输入LUT）。对于控制或逻辑繁重的应用程序，可能具有基于LUT的大型电路，这可能会导致大量折叠步骤并损害性能。因此，我们建议添加轻量级FPGA风格的开关盒，其中每个开关盒执行静态路由，段连接相邻的微计算集群。我们现在可以将4、8、16或最多32个计算集群分组以形成一个大型加速器tile，每个周期有更多可用的LUT。图6c显示了最终切片概览，并说明了一个示例，其中使用四个MCC形成加速器tile，并使用两种方式形成暂存器。<br>由于计算集群的密度、每个集群的LUT数量有限以及集群之间的距离较短，因此支持这种全局路由结构并不像传统FPGA那样昂贵。此外，单个缓存切片比FPGA小得多，这使得在单个时钟周期内将位从一端路由到另一端成为可能。</p><h4 id="多核系统中的-FReC-缓存"><a href="#多核系统中的-FReC-缓存" class="headerlink" title="多核系统中的 FReC 缓存"></a>多核系统中的 FReC 缓存</h4><p>在FReC Cache中，每个切片中实现的加速器彼此独立运行。加速器之间的通信是通过全局地址空间执行的，就像在GPU等其他数据并行架构中一样。在大型计算需求的情况下，问题可以分解为较小的独立问题，由每个切片的加速器处理。因此，FReaC Cache非常适合解决数据并行问题。请注意，互连计算集群的交换基础设施也仅限于单个切片。因此，加速器块的大小受LLC切片的大小和关联性限制。在某些情况下，整体性能取决于关联性、LLC切片的数量和MAC单元的总数。</p><h2 id="映射加速器"><a href="#映射加速器" class="headerlink" title="映射加速器"></a>映射加速器</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-110042.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>FReaC Cache是一个灵活的架构，一部分LLC slice可以用于计算，其余的部分则可以用于缓存数据，如图7(a)所示。<br>图7(b)则描述了映射的流程，具体可以参考文中列出的文献。</p><h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><p>我们的评估使用了gem5模拟器。我们在gem5中实现了一个周期精确的时序模型，通过考虑以下因素来模拟FReaC Cache的性能：每个基准加速器的综合电路的折叠时间表、将操作数从暂存器移动到集群时缓存总线上的争用、集群IO带宽以及将操作数加载到加速器tile。对于每个基准加速器，我们执行RTL模拟以生成所用内存访问的跟踪，以及它运行的确切周期数。我们模拟的系统是一个8核ARM微架构，类似于Exynos-5 SoC中的A15s，在表I中进行了描述。我们使用McPat和Cacti 6.5来生成尺寸、功率，以及存储器阵列的延迟（表II）。对于我们的模拟，我们考虑从子阵列读取一个字的延迟和功率，而不是从L3获取整个缓存行的延迟。因此，我们看到从子阵列读取单个字的延迟允许我们每个周期执行一次读取，从而允许我们在每个周期重新配置我们的子阵列。类似地，将数据以一种方式从子阵列移动到另一种方式需要沿高速缓存控制盒内的共享数据总线移动并且也是串行化的。我们通过McPat估计LLC的总泄漏功率为1.125W。<br>对于我们的评估，我们选择了MachSuite中的基准测试和一些手写的基准，它们非常适合FReaC Cache的预期用例，并代表计算、内存和逻辑(LUT)绑定应用程序。我们排除了n体分子动力学（KNN、GRID）和DNN训练（反向传播）等基准，因为我们在本文中针对边缘处理。==FReaC Cache 能够加速小型但重要的内核，这些内核将从 FReaC Cache 的低延迟、高吞吐量和高带宽数据访问中受益。== 因此，我们专注于内核，而不是大型多相应用程序。由于原始基准数据集非常小，我们以批处理方式将问题扩大了256倍。工作以数据并行的方式在所有可用的加速器tile/CPU 线程之间平均分配。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-110833.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h3 id="时间和面积开销"><a href="#时间和面积开销" class="headerlink" title="时间和面积开销"></a>时间和面积开销</h3><p>为了评估FReaC Cache中涉及的开销，我们使用Cacti、McPat、DSENT和RTL综合以及一个45nm库缩放到32nm。FreaC Cache添加了以下组件以形成微计算集群(MCC)：Mux Trees、Operand XBars、Intermediate Registers和MACs。MCC的组织和功能远没有处理器复杂，我们特别考虑以尽量减少对缓存时序的影响：(1) 通过添加缓冲区，我们避免加载现有总线。(2) 我们不修改内存阵列本身。(3) 大多数关键组件布线繁重，但集中在一个集群中，现代工艺节点具有高布线密度。(4) 正如我们将要证明的，新元件的面积可以忽略不计，因此它们的添加不会显着影响关键的导线路径。<br>我们对我们的面积和延迟建模采取保守的方法，并考虑最坏的情况。由于我们在短段中添加了新的布线，我们可以通过Cacti和DSENT合理地估计这些，如[55]中所示。特别是，Cacti 6+被开发用于识别大型缓存中的线路延迟。首先，我们考虑微计算集群。添加了四个组件：操作数xbar、复用树、中间寄存器和MAC单元。我们使用RTL模型来估计32位MAC单元和256个中间值保持触发器的成本分别为1011μm2和1086μm2。接下来，我们使用DSENT估计32X1 Mux树的成本为45μm2，操作数交叉开关为1239μm2。因此，每个簇增加的总面积为0.0034 mm2。如果我们在切片中启用32个集群，使用 16 路，总开销为0.109 mm2，仅占表II中描述的LLC切片总面积的3.5%。这将启用每个切片32个独立加速器切片的基本FReaC缓存模式。<br>然而，启用更大的集群有潜在的好处。为此，我们考虑了图3所示的FPGA式孤岛路由。为此，我们在四个微计算集群的组之间放置了一个开关盒，以及一个额外的开关盒来跨越标签阵列和控制盒，以启用X-Y路由。因此，我们总共有28个(7X4)开关盒，放置在16路缓存中，在8X4微计算集群块之间创建互连结构。请注意，FPGA路由结构和互连可以设计为放置在缓冲区和逻辑之上。因此，一旦我们确定了逻辑块的面积，我们就可以确定导线和互连的长度。然后，我们使用DSent和CACTI扫描模型的频率，直到在最坏的情况下不违反时序，因此为大型计算集群确定为3GHz，为小型计算集群确定为4GHz。可能的最长路径是切片对角的两个交换机之间的曼哈顿距离。我们发现这是2.864 毫米，基于高速缓存切片和子阵列的几何形状，必须在交换机之间的10条链路上完成，并且必须满足0.3 ns的延迟才能在一个周期内完成。我们考虑32位链路，并计算全局路由和链路的总面积为3469 μm2。最后，开关盒也需要配置，我们为每四个微计算集群添加一个宽输出8KB内存。这增加了0.35 mm2的总开销。请注意，这仅在我们需要以3GHz运行非常大的加速器块时才需要。因此，我们总共向切片添加了0.48 mm2或15.3%的开销。这是一个保守的估计，因为我们选择了短链接和更多的开关盒，因此为交换机增加了更多的配置内存。</p><p><strong>Summary: 运行3GHz大型计算集群时，面积开销为0.48 mm<sup>2</sup>，占LLC总面积的15.3%。</strong></p><h3 id="加速器设计空间"><a href="#加速器设计空间" class="headerlink" title="加速器设计空间"></a>加速器设计空间</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-131237.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><!-- 图8显示的时计算集群tile数对折叠周期的影响，MCC数越多，每次折叠步骤可以实现的逻辑越多，完成操作所需的折叠周期越少。因此，存在一个加速器延迟和网络吞吐率的平衡，以最大化性能和能效。 --><p>我们首先探索映射到FReC Cache的加速器的设计空间。我们使用Xilinx Vivado HLS综合了基准测试。首先，我们探讨了对用于实现加速器tile的计算集群tile数量的影响。每个加速器可用的MCC越多，每个折叠步骤可以分配的资源就越多，因此折叠周期就越少。我们展示了图8中每个基准在不同tile尺寸下的折叠周期数。虽然为每个加速器tile分配更多MCC减少了折叠次数，但每个切片的并发加速器tile数量存在权衡。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-135631.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>因此，加速器块的延迟和净吞吐量之间存在权衡。这种权衡还需要考虑工作集邻近度的影响。为了最大限度地提高性能和效率，工作集必须在缓存中可用。因此，并发加速器tile的数量也受到每个加速器tile的工作集 ==(数据量？)== 的限制。为了说明这一点，我们考虑了被分配到计算和缓存的LLC的不同比率。我们从16个Cache way用于计算和4个Cache way用于缓存开始，创建32个MCC和一个256KB缓存器，然后扫描到2个Cache way用于计算和18个Cache way用于缓存，创建4个MCC和一个1.1MB缓存器。图9显示了可以放入单个切片的最大加速器切片数量，切片大小为1（每个切片1 MCC）。具有较小工作集的加速器，例如AES和点积引擎，能够用加速器填充所有32个MCC块。然而，GEMM、KMP、Sorting 和 Stencil 等计算内核和存储绑定内核都通过将更多的LLC分配给缓存来达到最大的切片数量（以及吞吐量）。请注意，这是加速器工作集和可用切片数量的函数。总体而言，我们观察到由32个MCC和256KB缓存以及16个具有768KB暂存器的MCC组成的组织允许在单个切片中实例化大多数加速器块。</p><h3 id="FReC-缓存性能和效率"><a href="#FReC-缓存性能和效率" class="headerlink" title="FReC 缓存性能和效率"></a>FReC 缓存性能和效率</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152647.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152659.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>我们将FreaC Cache与其基础系统的8个ARM内核、一个大型PCIe连接的FPGA(Xilinx ZCU102 FPGA) 和一个独立的Ultra 96​​ SoC FPGA系统进行了比较。我们使用OpenMP以数据并行的方式跨所有可用的物理内核并行化基线基准测试。我们通过McPat使用32nm低功耗库对ARM内核的功率进行建模。为了评估FPGA，我们综合了启用所有优化指令的基准电路。接下来，我们尝试实例化基准IP的256个副本，以反映最大的数据并行性。如果所有副本都不适合，那么我们对工作负载进行批处理，并相应地缩放延迟。我们包括160 μs的DMA延迟和配置开销，还包括通过PCIe3.0 x16为ZCU102传输数据到FPGA的成本，以及在Ultra 96​​ (U96)中通过AXI总线传输的成本。然后，我们使用Xilinx功率估计器(XPE)来估计功率，并将电路板空闲和泄漏功率计为12W的ZCU102。FReaC Cache上的基准测试延迟由我们的Gem5模拟器提供。为了提供最佳性能并与我们的FPGA比较保持一致，我们将数据移入暂存器缓冲区。我们测量内核在FReaC Cache加速器中操作的延迟，以及将数据集传输到暂存缓冲区的延迟。在将数据加载到缓冲区时，我们并行加载LLC切片，从而充分利用LLC的带宽。内核延迟还包括写入配置数据的时间。我们通过考虑来自计算集群和暂存器的读取次数来估计FReaC Cache的能力。我们还假设开关盒之间的链路在100%负载下运行，每条链路消耗约9 mW，并添加泄漏功率。我们展示了与A15主机的单个线程相关的所有数据。<br>为了更好地理解FReaC Cache，我们首先检查单个缓存切片和加速器切片大小的影响。我们考虑一个具有32MCC-256KB分区的切片，因此消耗了切片的所有20路。然后，我们扫描加速器tile大小，为每个加速器分配1、8和16个MCC，并测量内核在单个主机内核(A15)上的执行速度。我们还使用每个切片的最大加速器数量来限制我们的探索，如图9所示。在图10中，除了AES，我们看到增加切片大小可以提高性能。然而，我们看到tile大小为16时性能有所下降，因为16个或更多MCC的tile需要降低时钟速度。正如我们在图8和图9中看到的，AES具有非常高的折叠开销，但可以在单个切片中容纳多个副本。因此，它更适合每个切片有多个切片，每个切片的MCC很少。正如我们之前提到的，将LLC分配到内存与计算之间存在权衡。我们在图11中更仔细地检查了这一点。我们展示了单个切片中两个不同的计算到内存分区在所有加速器切片大小中可能的最佳性能。再一次，我们发现AES比缓冲存储器更喜欢更多的计算集群，以及其他计算内核，如点积引擎、全连接层和GEMM。但是请注意，这里我们仅限于单个切片。最佳的计算到内存权衡也是切片总数的函数，我们观察到，随着参与加速的切片数量的增加，16MCC-768KB拆分被证明更有用。<br>接下来，我们将在我们的评估系统中考虑FReaC Cache的端到端性能。在实践中，消耗整个LLC可能是不可行的，因此我们保留了两种方式，每个切片128KB作为缓存。这留下了10%或1MB的LLC，同时将剩余的18路分配给计算和暂存器。我们考虑每个切片16MCC-640KB计算暂存器拆分，并扫描所有可能的加速器切片大小和缓存切片。为简洁起见，我们报告了给定切片数量的最佳性能（加速），并报告了相应的每瓦性能（每瓦吞吐量）和功率。我们在图12中以对数刻度呈现我们的数据。加速是通过应用程序的端到端延迟来衡量的，我们使用单个A15线程作为基准。端到端延迟包括初始化阵列、将它们移动到暂存器缓冲区以及返回核心的成本。为了进行比较，我们包括完全并行的八线程A15实现，以及ZCU102和Ultra96 (U96) FPGA。对于FGPA，我们还包括将数据移动到其缓冲区的成本。<br>正如我们所见，随着缓存切片数量的增加，FReaC Cache的端到端性能也随之提高。在各项基准测试中，FReaC Cache的性能比ARM内核低一小部分。平均而言，当使用所有八个切片时，FReaC Cache分别比单线程和多线程实现快8.2倍和3倍。此外，FReaC Cache的效率（Perf/Watt）平均比多核CPU高6.1倍。事实证明，FReaC Cache尤其适用于内存受限和计算内核，例如卷积、点积、向量加/乘、全连接层和GEMM，与单线程实现相比，速度提高了14.5倍。由于折叠，诸如AES和排序(SRT)之类的逻辑繁重的应用程序会受到更高的惩罚。因此，虽然它们比单个CPU线程快，但多线程实现超过它们，但功率几乎是其两倍。然而，在大多数基准测试中，大型ZCU102 FPGA的性能优于FReaC Cache、A15和U96。这是以功耗大幅增加为代价的，我们注意到ZCU102芯片比LLC以及整个A15芯片大得多。以边缘为中心的低功耗Ultra 96​​在计算和内存敏感基准测试中均被FReaC Cache击败。事实证明，FReaC Cache也比两种FPGA解决方案更节能。因此，FReaC Cache在各种基准测试和领域证明了自己的高性能、灵活和高效。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152729.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152741.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152752.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152810.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>最后，将数据移入和移出加速器可能会花费时间和精力。在NMA和PIM的情况下，这可能还需要核心和主机操作系统中的其他机制。为了降低将数据复制到缓冲区和从缓冲区复制数据的成本、提高性能并避免将页面固定到物理地址，FReaC Cache使用内核将数据直接初始化到暂存器缓冲区中。这有效地消除了复制操作，但这样做仍然需要时间。在我们对图12的评估中，我们考虑了应用程序的端到端延迟，包括初始化和复制数据的成本。在图13中，我们在对数尺度上展示了端到端加速与仅内核加速的对比。作为参考，我们还提供了多线程实现。我们观察到，根据基准测试，复制和初始化的开销可以忽略不计到60%。因此，在某些情况下，我们的端到端加速比峰值内核加速的一小部分。这部分是由于工作集的大小，甚至CPU也会因此而降低端到端性能。FReaC Cache的性能仍然优于CPU甚至FPGA。请注意，尽管LLC具有巨大的带宽并直接在缓冲区中初始化数据，但我们仍会受到内存初始化延迟的影响。然而，像ZCU102和U96这样的片外加速器需要在更慢的通道上进行完整复制，初始化完成后，会增加更多的开销。因此，FReaC Cache提供经济高效、节能且灵活的加速，以及通往用户工作集的高带宽和低延迟路径，这使FReaC Cache处于非常独特的位置。</p><h2 id="DISCUSSION"><a href="#DISCUSSION" class="headerlink" title="DISCUSSION"></a>DISCUSSION</h2><p>在本节中，我们将进行讨论以阐明 FReaC Cache 的动机、定位和潜在限制。</p><h3 id="可移植性"><a href="#可移植性" class="headerlink" title="可移植性"></a>可移植性</h3><p>在这项工作中，我们通过将FreaC Cache合并到现有架构中来说明FreaC Cache的思想和原则。虽然我们使用Huang等人提供的Intel Xeon LLC的详细描述作为示例FReac Cache设计的基础，FReaC Cache不限于英特尔LLC架构，也不依赖于任何特殊的英特尔企业功能。相反，在这项工作中，我们的重点是用于边缘计算的处理器。改变底层缓存切片架构可能会影响每个周期的有效LUT数量、微计算集群的大小、集群数量和跨路分组的集群数量等。 例如，如果一个缓存路由两倍作为许多子阵列，我们可以拥有两倍多的微计算集群，或相同数量的集群，每个周期可用的 LUT 数量增加一倍。为了一致性，我们使用了 Huang 等人描述的架构贯穿本文。总内存容量仅限制暂存器大小和我们可以存储的配置数量，但不限制性能。</p><h3 id="基于-FPGA-的架构"><a href="#基于-FPGA-的架构" class="headerlink" title="基于 FPGA 的架构"></a>基于 FPGA 的架构</h3><p>FReC Cache不是一种新的FPGA架构。相反，它是一种适用于边缘场景的极具成本效益和能效的解决方案，在这些场景中，小吞吐量或内存带宽密集型内核可以偶尔卸载。我们的重点不是重新设计可重新配置的计算逻辑，而是专注于重新配置LLC并将其转换为可以利用近内存计算的定制加速器的最佳方式。它不是为处理通用可重配置计算或提供一般FPGA设备通常针对的胶合逻辑而设计的。虽然我们确实使用LUT，就像FPGA，但我们的设计和组织与FPGA有很大不同，我们没有考虑通用FPGA的许多特性，包括嵌入式BRAM、丰富的基于FF的控制逻辑、高I/O能力、多-clock域等。因此，FReaC Cache不是每个应用程序的完美解决方案。如果应用程序易于理解且任务关键，则FPGA可能是更好的选择。例如，具有大型复杂控制电路的电路将更适合FPGA，在这种情况下，对数千个LUT的即时访问更为关键。但是，FReaC Cache比FPGA具有显着的面积优势，因为：（1）LLC子阵列占据了大部分面积，并且附加逻辑具有面积分数开销，以及（2）80%的FPGA面积用于布线结构及其配置位，FReaC缓存避免了这个问题。此外，FPGA的配置带宽有限，仅为400MB/s。FReaC缓存配置受LLC-DRAM带宽和LLC内部带宽（10到100GB/s）的限制。</p><h3 id="替代的-Near-和-In-Cache计算方法"><a href="#替代的-Near-和-In-Cache计算方法" class="headerlink" title="替代的 Near 和 In-Cache计算方法"></a>替代的 Near 和 In-Cache计算方法</h3><p>我们首先考虑Compute Caches，其中作者提出利用位线计算来实现向量计算。由于计算的性质，这种方法受到子阵列间距的限制，因此作者仅限于一组简单的位运算——AND、OR、XOR、复制和比较——它们对以下情况有效作者针对的数据操作域，例如字符串匹配、位图索引等。至关重要的是，这种方法需要对缓存和子阵列进行大量重新设计，并添加新的ISA指令，这会增加大量的设计和验证成本。此外，operands must be placed for sufficient locality in order to perform in-situ processing。 Compute Cache 中计算、ISA、基准测试和模拟基础设施的深奥性质使得很难与FReaC Cache进行一对一的比较。但是，我们注意到FReaC Cache的侵入性要小得多。所有新逻辑都放置在子阵列之外，重新使用现有总线，并且不使用自定义ISA。因此，我们最大限度地减少了对LLC和内核的面积、时序、能量和设计的影响。最重要的是，我们不限于位级操作或受限的应用领域。虽然FReaC Cache是通用的，但它最适合主机需要加速内存绑定计算内核的情况。Compute Cache在数据操作工作负载上提供了1.9倍的平均加速，而FReaC Cache在不同的工作负载上展示了3倍的平均加速。<br>接下来，我们考虑近缓存计算，例如BSSync，它将计算放置在缓存附近，而不是在数组内部。我们考虑在LLC中放置轻量级嵌入式内核(EC)，例如ARM A7，而不是在LLC中放置ALU并添加新的ISA指令。与FReaC Cache一样，它提供了类似的通用功能，独立于主机内核运行，加速器内核和主机内核之间的通信仍然可以通过LD/ST完成。每个A7内核的面积约为0.49 mm2，与FReaC Cache的per-slice开销类似。因此，我们考虑两种情况：（1）iso-area，每个切片放置一个EC，以及（2）每个切片放置两个EC。这些分别在LLC中提供总共八个和十六个内核。为了公平比较，我们分配了LLC的16 way作为暂存器供内核使用。正如我们在图14中看到的，基于FReaC Cache的加速器的定制电路和有效的内存带宽利用率使其显着优于iso-area 8 EC解决方案的平均4倍，以及16 EC设置的平均2倍。因此，与这种近缓存解决方案相比，FReaC Cache的面积和计算效率要高得多。请注意，图14中的加速是相对于单个A15线程显示的，该图包括所有八个A15内核的性能。</p><h3 id="干扰主机性能"><a href="#干扰主机性能" class="headerlink" title="干扰主机性能"></a>干扰主机性能</h3><p>由于LLC的一部分专用于计算，因此在CPU和FReaC Cache中的加速器性能之间存在潜在的权衡。解决方案取决于应用程序，以及CPU和加速器是否协同工作。然而，这个问题类似于在芯片多处理器和多租户云场景中看到的缓存干扰和性能隔离问题。特别是，先前的工作表明，在这种混合工作负载和多应用场景中，对LLC进行分区是一种有效的解决方案。将LLC的一部分专用于进程的加速器会对其他正在运行的进程的性能产生影响，这与将LLC的分区专用于该进程的效果类似。更好地理解为计算分配多少缓存需要详细研究以明确定义多租户级别和并发进程之间的交互，而先前关于缓存QoS和干扰的工作为此提供了良好的基础。<br>作为一阶分析，我们考虑两组应用程序：{AES、NW、STN2和STN3}和{CONV、FC、KMP和SRT}。每个组都包含混合了计算和内存绑定内核的应用程序，以及逻辑/分支繁重的特征。然后我们考虑两种情况 - 保留1MB和4MB的LLC用于缓存，而其余部分用于加速组中的应用程序之一。其余三个应用程序分别分配了两个CPU线程。图15展示了我们的分析，所有数据都标准化为单线程基线，如前几张图所示。由于四个应用程序中的三个应用程序在CPU复合体上运行，因此每个应用程序总共将运行3次。因此，我们考虑每个LLC容量的三个运行时间的平均值。我们的研究揭示了两个关键点：首先，我们注意到基准测试对LLC的总容量不敏感。这主要是因为内核的L1和L2缓存能够保存每个线程的工作集。我们的基准测试以批处理和数据并行的方式运行。因此，虽然总应用程序工作集可以高达32MB，这大于LLC容量，但每线程工作集（批处理的一个元素）不会超过128KB。其次，我们看到为加速分配更多LLC资源可以提高加速器的性能。这是预期的行为。但是，我们注意到这在很大程度上与可以分配多少方式作为暂存空间有关，以便加速器发挥作用。因此，我们观察到，对于我们给定的一组基准测试，将最多90%的LLC(9MB)分配给计算/暂存器以加速一个应用程序不会损害其余三个应用程序的性能，因为剩余的1MB足以支持L1和L2缓存中的每线程工作集。在这里，我们看到基于FReaC Cache的加速器可以提供1.8倍到9倍的CPU运行速度。请注意，虽然在图12、13和14中我们考虑了每个应用程序最多八个主机CPU的线程，但这里每个应用程序仅限于两个线程，而加速器利用LLC的所有八个切片。<br>因此，在这种情况下，将计算或内存受限的应用程序卸载到LLC将提供最佳的整体性能，并且对CPU内核的影响有限。如果一个或多个应用程序对LLC容量敏感，那么用户将需要缩减用于计算的LLC分配和/或考虑将LLC分区和分配给特定应用程序。正如我们的结果所示，FReaC Cache仍然能够以60%的LLC(6MB)提供加速。减少分配给计算的LLC数量将按比例减少加速度。因此，在可能的情况下，FReaC Cache将多余的LLC容量转换为计算，从而提供节能、定制且廉价的加速。</p><h2 id="CONCLUSION"><a href="#CONCLUSION" class="headerlink" title="CONCLUSION"></a>CONCLUSION</h2><p>在这项工作中，我们提出了一种新颖的架构，FReaC Cache，它利用了LLC的现有子阵列，并且在不改变子阵列的情况下，能够创建密集的可重构计算集群。FReaC Cache可以以3.5%到15.3%的最小面积开销实现，并且当消耗90%的LLC时，与边缘级多核处理器相比，平均加速提高了3倍，Perf/W平均提高了6.1倍加速。我们还展示了FReaC Cache相对于现代FPGA的竞争优势，在现代FPGA中，FReaC Cache的面积和功率效率更高。最后，我们承认使用LLC进行计算会降低缓存性能，但某些应用程序不会用完整个LLC。通过转换LLC进行计算，我们实现了两个目标：（1）避免浪费LLC容量，以及（2）近数据计算。因此，FReaC Cache为边缘设备的加速提供了一种经济高效的解决方案。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Recryptor: A Reconfigurable Cryptographic Cortex-M0 Processor With In-Memory and Near-Memory Computing for IoT Security</title>
      <link href="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/"/>
      <url>/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/</url>
      
        <content type="html"><![CDATA[<h1 id="Recryptor-A-Reconfigurable-Cryptographic-Cortex-M0-Processor-With-In-Memory-and-Near-Memory-Computing-for-IoT-Security"><a href="#Recryptor-A-Reconfigurable-Cryptographic-Cortex-M0-Processor-With-In-Memory-and-Near-Memory-Computing-for-IoT-Security" class="headerlink" title="Recryptor: A Reconfigurable Cryptographic Cortex-M0 Processor With In-Memory and Near-Memory Computing for IoT Security"></a>Recryptor: A Reconfigurable Cryptographic Cortex-M0 Processor With In-Memory and Near-Memory Computing for IoT Security</h1><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>这篇论文并没有提出新的SRAM计算电路，属于是将10T SRAM计算电路在架构级进行了应用，加速加密算法。这篇论文给我们的一个启发是：我们并不一定受限于传统SRAM的push rule结构，担心影响其他操作的性能。这篇论文就是3/4的SRAM属于传统Cache应用，1/4的SRAM用于存算一体，这其实和谢源老师的Prime架构思路类似，比Prime有优势的地方在于存/算模式切换没有开销。</p><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>加密函数通常需要高带宽计算(64-512 bits)，但是嵌入式处理器的数据通路只有32-bit宽度。<br>现有架构，无论是CPU还是ASIC，加密算法的运行效率不高。</p><h2 id="Target-of-This-Work"><a href="#Target-of-This-Work" class="headerlink" title="Target of This Work"></a>Target of This Work</h2><p>本文提出了 Recryptor，这是一种可重构的加密处理器，可通过增强商业通用处理器的现有Cache以增强计算能力。它支持使用10晶体管位单元的Cache中位线计算，以支持高达512位宽的不同按位运算。定制设计的移位器、旋转器和S-box模块位于内存附近，提供高吞吐量的近内存计算能力。</p><h2 id="架构介绍"><a href="#架构介绍" class="headerlink" title="架构介绍"></a>架构介绍</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-160115.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Recryptor 包含一个标准 ARM Cortex-M0 微控制器和 32-kB 存储器、一个用于访问片外数据的低功耗串行总线和一个仲裁器作为其内部总线，以及可选的有限状态机 (FSM)，如图 1 所示。32-kB存储器由四个8-kB Banks组成。三个是使用标准存储器编译器实现的，而第四个是定制设计的crypto-SRAM Bank(CSB)。</p><h2 id="RECRYPTOR’S-IN-MEMORY-COMPUTING"><a href="#RECRYPTOR’S-IN-MEMORY-COMPUTING" class="headerlink" title="RECRYPTOR’S IN-MEMORY COMPUTING"></a>RECRYPTOR’S IN-MEMORY COMPUTING</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-160127.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>CSB不仅能够当作常规的存储器进行32-bit的读写，而且支持大带宽存内/近存计算。如图2所示，CSB的存储单元使用的10T SRAM结构，读写路径分离，能够同时激活多行而不会对存储的值产生干扰。通过偏斜的两个SA分别实现OR/NAND/XOR/NOT/COPY操作(NOT/COPY是如何实现的？)。运算结果可以通过移位器进行得到移位之后的结果，并将结果锁存到Write FF中等待Write Buffer写回。此外，Write FF里的结果还可以通过64-bit Rotator或SBOX进行近存计算。最后，还有一路DIN用于支持标准memory的写操作。</p><h3 id="Bank分块的配置"><a href="#Bank分块的配置" class="headerlink" title="Bank分块的配置"></a>Bank分块的配置</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-163634.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>如图4所示，8-kB CSB分为16个slices，每个slice包含128个32-bit words。进行标准memory读写时，只激活一个slice。进行存内计算时，可以通过控制同时激活多个slices，即图4(b)中的Sub-Bank，以支持不同宽度的存内计算。</p><h2 id="RECRYPTOR’S-NEAR-MEMORY-COMPUTING"><a href="#RECRYPTOR’S-NEAR-MEMORY-COMPUTING" class="headerlink" title="RECRYPTOR’S NEAR-MEMORY COMPUTING"></a>RECRYPTOR’S NEAR-MEMORY COMPUTING</h2><h3 id="Shifter"><a href="#Shifter" class="headerlink" title="Shifter"></a>Shifter</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-165714.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Recryptor支持的近存shifter操作如表1所示。图5显示了一个简单的Shifter的草图及其wiring intensive版图设计。</p><h3 id="Rotator"><a href="#Rotator" class="headerlink" title="Rotator"></a>Rotator</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-170619.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Rotator是用于任意64位旋转的自定义两级设计，如图6所示，第一级可移动0-7 bits，第二级移动8x bits，从而可以实现0-63 bits的任意移位。</p><h3 id="SBOX"><a href="#SBOX" class="headerlink" title="SBOX"></a>SBOX</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-171214.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>S-box是用于字节替换的分组密码中的常用组件。它是一个非线性函数，对伽罗华域执行乘法反演，然后是仿射变换。该算法在转换为复合域GF(2<sup>4</sup>)<sup>2</sup>时更有效。电路实现如图7所示。</p><h2 id="可编程性和优化的算法实现"><a href="#可编程性和优化的算法实现" class="headerlink" title="可编程性和优化的算法实现"></a>可编程性和优化的算法实现</h2><p>该段对FFMR，AES，Keccak-f算法进行了优化，并介绍了图2中提及的可选的密码有限状态机，暂时跳过。</p><h2 id="RECRYPTOR-测试芯片设计和实验结果"><a href="#RECRYPTOR-测试芯片设计和实验结果" class="headerlink" title="RECRYPTOR 测试芯片设计和实验结果"></a>RECRYPTOR 测试芯片设计和实验结果</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-171647.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Baseline和Recryptor都是基于ARM Cortex-M0处理器，测试芯片的工艺节点为40nm，如图9所示。</p><p>我们可以看出Recryptor与baseline相比，存在36%的面积开销，如果使用push rule设计，面积开销降低至18%。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-172057.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图10显示的时10T SRAM的最高工作频率。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-172109.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图11显示的时不同温度下正常CSB读操作的最低工作电压。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-172122.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图12可以看出Recryptor与baseline的性能相当接近。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-172135.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图13可以看出Recryptor的功率超过base 30%，但是这一开销可以被速度优势弥补。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-173009.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图14显示了CSB仿真的能耗分布。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-173031.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>表4显示了Recryptor与其他处理器的性能对比：</p><ul><li>对于FFMR，Recryptor支持163-409 bits的字长，速度提升大于11倍，能效提升大于6.7倍。</li><li>对于Keccak，没有任何的协处理器实现的工作，因此选用了参考文献[12]中的ASIC实现进行对比。速度提升超过8倍，能效提升超过4.8倍。</li><li>对于AES，速度和能效提升9倍。(这边参考文献[18]中的工作速度会快很多，一部分时频率优势，另一部分可能是处理器的微架构优势，这需要看原文才能知道。)</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-173119.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图15进一步与ASIC和加密协处理器进行了对比，可以看出：在面积、吞吐量、能源和可编程性方面，Recryptor 作为比较架构之间的中间解决方案。</p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p>暂时跳过</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>i-SRAM: Interleaved Wordlines for Vector Boolean Operations Using SRAMs</title>
      <link href="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/"/>
      <url>/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/</url>
      
        <content type="html"><![CDATA[<h1 id="i-SRAM-Interleaved-Wordlines-for-Vector-Boolean-Operations-Using-SRAMs"><a href="#i-SRAM-Interleaved-Wordlines-for-Vector-Boolean-Operations-Using-SRAMs" class="headerlink" title="i-SRAM: Interleaved Wordlines for Vector Boolean Operations Using SRAMs"></a>i-SRAM: Interleaved Wordlines for Vector Boolean Operations Using SRAMs</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>之前基于SRAM的存内计算的工作需要对正常的 SRAM 读取操作进行修改，从而导致读取稳定性下降或感测裕度降低。</p><p>该论文所提出工作的一个关键亮点是，所提出的读取操作与正常的内存读取操作完全相同，因此不会导致读取鲁棒性或检测裕度的任何损失。</p><h2 id="INTERLEAVED-WLS-FOR-6T-SRAM-i-SRAM-6T"><a href="#INTERLEAVED-WLS-FOR-6T-SRAM-i-SRAM-6T" class="headerlink" title="INTERLEAVED WLS FOR 6T-SRAM: i-SRAM-6T"></a>INTERLEAVED WLS FOR 6T-SRAM: i-SRAM-6T</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202197-221316.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>交错WL技术如图1(a)所示，每一行由两根WL(O-WL和E-WL)控制，分别控制odd bit和even bit。计算电路如图1(b)所示，相邻的奇偶BL对应的SA测量结果输入到同一个计算电路中进行计算，这样任意连个奇偶word进行逻辑计算不需要同时打开多行，消除了传统6T SRAM的读取不稳定性。同时，与某些单端的SA相比，该工作与传统SA一样，采用差分的SA，能够提供更高的感测性能。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202197-231528.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>计算单元如图2所示，采用传统的CMOS逻辑实现NAND/NOR/XOR等操作。</p><p>针对这一方案，有两个关注点：</p><ol><li>该方案能且只能在任意的奇偶两个set之间进行逻辑操作，这在某些应用中非常适合，如CNN中Activation和Weight的VMM操作。</li><li>该方案没有对传统的6T SRAM的bit-cell电路和驱动电压进行任何更改。</li></ol><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202197-232338.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该方案的开销：由于采用双倍的WL，面积开销增加11%，此外还需要增加一层金属布线层。版图如图3所示。</p><h2 id="INTERLEAVED-WLS-FOR-8T-CELL-i-SRAM-8T"><a href="#INTERLEAVED-WLS-FOR-8T-CELL-i-SRAM-8T" class="headerlink" title="INTERLEAVED WLS FOR 8T CELL: i-SRAM-8T"></a>INTERLEAVED WLS FOR 8T CELL: i-SRAM-8T</h2><p>虽然交叉WL结构消除了同时激活多行带来的问题，但是8T SRAM相较于6T SRAM的优势在于读写路径解耦，非常适合进行低电压设计。在该论文中采用的是0.8V电压供电，而在65nm工艺下，标准供电电压为1.2V。8T SRAM相比于传统的6T SRAM，面积增加30%。cell结构及版图如图4所示，计算电路如图5所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-13643.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-13709.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="系统设置和评估框架"><a href="#系统设置和评估框架" class="headerlink" title="系统设置和评估框架"></a>系统设置和评估框架</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-14233.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>仿真采用的是一个简单的冯诺依曼架构，主机位Nios-II处理器，多个SRAM banks通过总线连接到主机，系统架构如图8(a)所示，针对iSRAM的指令扩展如图8(b)所示。系统仿真相关参数如表2所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-15427.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h3 id="BNN-加速"><a href="#BNN-加速" class="headerlink" title="BNN 加速"></a>BNN 加速</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-14251.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>BNN的加速方式如图7所示</p><h3 id="AES-加速"><a href="#AES-加速" class="headerlink" title="AES 加速"></a>AES 加速</h3><p>AES 加密算法严重依赖于使用逐位布尔运算（例如 XOR）的替换和置换操作。整个 AES 运行时高达 67% 的操作可以映射到上述 iSRAM-XOR 指令。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="CNN加速结果"><a href="#CNN加速结果" class="headerlink" title="CNN加速结果"></a>CNN加速结果</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-21155.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ul><li>与baseline(CPU)相比，i-SRAM-6T和8T能效提升分别位2.16x和2.4x；</li><li>i-SRAM-8T的能效最优，这是由于其供电电压低；</li><li>i-SRAM速度提升8.1x。</li></ul><h3 id="AES加速结果"><a href="#AES加速结果" class="headerlink" title="AES加速结果"></a>AES加速结果</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-21207.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-21221.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ul><li>i-SRAM-6T和i-SRAM-8T能效提升分别为3.6x和3.5x；</li><li>运行时间提速3x；</li><li>从64KB memory中读取64-bit数据能耗为19.36pJ，对两个64-bit数据进行计算能耗为25.83pJ。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>X-SRAM: Enabling In-Memory Boolean Computations in CMOS Static Random Access Memories</title>
      <link href="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/"/>
      <url>/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/</url>
      
        <content type="html"><![CDATA[<h1 id="X-SRAM-Enabling-In-Memory-Boolean-Computations-in-CMOS-Static-Random-Access-Memories"><a href="#X-SRAM-Enabling-In-Memory-Boolean-Computations-in-CMOS-Static-Random-Access-Memories" class="headerlink" title="X-SRAM: Enabling In-Memory Boolean Computations in CMOS Static Random Access Memories"></a>X-SRAM: Enabling In-Memory Boolean Computations in CMOS Static Random Access Memories</h1><!-- TOC --><ul><li><a href="#x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories">X-SRAM: Enabling In-Memory Boolean Computations in CMOS Static Random Access Memories</a><ul><li><a href="#motivation">Motivation</a></li><li><a href="#x-sram%E6%94%AF%E6%8C%81%E7%9A%84%E6%93%8D%E4%BD%9C">X-SRAM支持的操作</a><ul><li><a href="#nor">NOR</a></li><li><a href="#nand%E6%93%8D%E4%BD%9C">NAND操作</a></li><li><a href="#%E5%88%86%E5%8E%8B%E5%AE%9E%E7%8E%B0imp%E5%92%8Cxor%E9%80%BB%E8%BE%91%E6%93%8D%E4%BD%9C">分压实现IMP和XOR逻辑操作</a></li><li><a href="#read-compute-store%E6%93%8D%E4%BD%9C">Read-Compute-Store操作</a></li><li><a href="#8supsup-%E6%99%B6%E4%BD%93%E7%AE%A1%E5%B7%AE%E5%88%86%E8%AF%BBsram">8<sup>+</sup> 晶体管差分读SRAM</a></li></ul></li><li><a href="#%E8%AF%84%E4%BC%B0%E7%BB%93%E6%9E%9C">评估结果</a></li></ul></li></ul><!-- /TOC --><!-- ## 总结<font color=red size=4>这是一篇没有价值的工作，虽然能够实现所说的操作，但是开销大，操作复杂，而且稳定性差。</font><font color=blue>不要往下看，浪费时间！！！不要往下看，浪费时间！！！不要往下看，浪费时间！！！</font> --><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>之前的基于SRAM的存内计算方案需要锁存计算结果，并需要额外的周期写回结果。</p><h2 id="X-SRAM支持的操作"><a href="#X-SRAM支持的操作" class="headerlink" title="X-SRAM支持的操作"></a>X-SRAM支持的操作</h2><h3 id="NOR"><a href="#NOR" class="headerlink" title="NOR"></a>NOR</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-133447.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>8T SRAM的单元结构如图3(a)所示，在传统6T SRAM上增加了M1和M2形成单独的read通路。</p><p>NOR操作如图3(b)所示，首先预充RBL，然后通过RWL开启M2。如果Q为1(图3(a)中Q和QB的位置需要互换一下才正确)，则M1也开启，RBL通过M2和M1放电，否则，RBL保持高电平。NOR操作的波形如图3(c)所示。</p><h3 id="NAND操作"><a href="#NAND操作" class="headerlink" title="NAND操作"></a>NAND操作</h3><p>NAND逻辑的实现是利用的单行漏电和多行漏电，RBL电压下降的速度不同来实现的。需要合适的RWL脉冲宽度控制，使得两行同时漏电（Case 11）可以将RBL拉低到反相器阈值以下，而单行打开（Case 01/10）在这段时间里无法将RBL拉低到反相器阈值以下，如图3(d)所示。这种脉宽调制的方法我是不太看好的，控制难度太高，速度和精度都无法做到很高，虽然本文中作者做了一些monte carlo的仿真(图4和图5)，但是与实际情况相差较大。还不如增加两个晶体管做成差分的读取通路，还可以实现XOR逻辑，面积可能并不会比这种大，因为M1/M2的管子不再受放电速度限制可以做到最小尺寸，整体来说这个方案面积开销会比较大。NAND的工作波形如图3(d)所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-153145.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-153200.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h3 id="分压实现IMP和XOR逻辑操作"><a href="#分压实现IMP和XOR逻辑操作" class="headerlink" title="分压实现IMP和XOR逻辑操作"></a>分压实现IMP和XOR逻辑操作</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-154913.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>IMP和XOR逻辑如图6(a)所示。cell 1对应的SL1驱动到VDD，cell 2对应的SL2接到GND。计算时将RWL1和RWL2打开，从而M1-&gt;M2-&gt;M3-&gt;M4实现了从VDD到GND的通路，由于M2和M3开启，RDBL处的电压可以看作M1和M4的分压。Case 00，M1和M4都关断，RDBL保持预充电压，Case 11，M1和M4都开启，RDBL是两者沟道电阻的分压，仍然接近预充电压。Case 01，M4将RDBL下拉到GND。Case 10，M1将RDBL上拉到VDD。通过控制反相器的PU/PD的驱动能力，可以使得INV2在RDBL电压远低于$V_{pre}$，接近0V时输出才翻转到1；INV1在RDBL电压远高于$V_{pre}$，接近VDD时，输出才翻转到0。因此，INV2输出高电平表明数据为(0,1)，INV3输出高电平时，数据为(1,0)。此时INV1实现了”A IMP B”蕴含逻辑，通过对INV2和INV3的输出做或操作，可以得到XOR逻辑。<font color="red">此处的反相器与执行NOR/NAND时的反相器不同，而且不能使用最小尺寸。</font></p><h3 id="Read-Compute-Store操作"><a href="#Read-Compute-Store操作" class="headerlink" title="Read-Compute-Store操作"></a>Read-Compute-Store操作</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-191805.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>RCS可以在一个周期内进行计算，并将计算结果写到目的地址，不需要锁存计算结果。读取/写入路径解耦使得同一个周期完成计算和存储可能。从图8(a)种可以看到：首先激活RWL1和RWL2进行计算，计算结果通过多路选择器控制Write Driver写入WWL3对应行种。</p><p><font color="blue">这个操作还比较有优势，在一个周期内完成Load/Commpute/Store，这跟无线项目的想法一致。此外，这一功能还能实现memory copy操作。但是存在两点挑战：（1）这个电路还是比较复杂，能不能在<a href="https://zongwuwang.github.io/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/">4+2T SRAM</a>方案或者Local Bitline方案上进行改进；（2）如何将数据对齐仍相当有挑战。</font></p><h3 id="8-晶体管差分读SRAM"><a href="#8-晶体管差分读SRAM" class="headerlink" title="8+ 晶体管差分读SRAM"></a>8<sup>+</sup> 晶体管差分读SRAM</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-200806.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>这个就是我在之前提到的使用差分读通路，如图9(a)所示，使用9T实现。图9(b)显示的是9T SRAM实现NOR和NAND的波形，这与6T SRAM一摸一样。</p><p>为了感测bit-wise NAND和NOR操作的结果，图9(c)也展示了通过偏斜某一晶体管实现的非对称SA结构。偏斜晶体管可以通过多种途径实现，如晶体管尺寸，阈值电压和体偏电压等。如图9(c)所示，如果晶体管$M_{BL}$的尺寸大于$M_{BLB}$，其载流能力增加。对于“01”和“10”的情形，RBL和RBLB同时放电。但是由于$M_{BL}$的载流能力大于$M_{BLB}$，因此$SA_{out}$节点放过点更快，交叉耦合的反相器对最终会使得$SA_{out}$稳定在“0”。对于“11”的情形，RBL放电，RBLB保持为VDD，SA放大RBL和RBLB之间的电压差，最终导致$SA_{out}$稳定在“1”。对于“00”的情形，与“11”情形相反，最终$SA_{out}=1$。综上，$SA_{out}$实现了AND操作，$SA_{outb}$输出NAND操作结果。<br>同理，我们也可以设计$M_{BLB}$的尺寸大于$M_{BL}$，最终SA实现OR/NOR操作。<br>两个SA并行工作，实现AND/NAND/OR/NOR/XOR操作。</p><p>Monte Carlo仿真结果：</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-203034.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>工艺角仿真结果：</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-203048.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="评估结果"><a href="#评估结果" class="headerlink" title="评估结果"></a>评估结果</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-203523.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>表1展示了SRAM支持的各种操作的延迟和能耗，并且分析了各类操作的优缺点。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-204520.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图13显示了整个仿真的系统架构，采用的是Intel Nios-II处理器和Avalon总线，X-SRAM作为总线连接的协处理器，一共处理两条包含三个地址的指令。<br>仿真所用的Benchmark为AES加解密，其中可用于RCS-XOR和RCS-Copy加速的部分占整体运行时间的92%。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-204547.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>实验结果如图14所示，在128b和256b 密钥的ECB模式下，访存分别减少74.7%和74.6%。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin</title>
      <link href="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/"/>
      <url>/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/</url>
      
        <content type="html"><![CDATA[<h1 id="A-4-2T-SRAM-for-Searching-and-In-Memory-Computing-With-0-3-V-VDDmin"><a href="#A-4-2T-SRAM-for-Searching-and-In-Memory-Computing-With-0-3-V-VDDmin" class="headerlink" title="A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin"></a>A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin</h1><!-- TOC --><ul><li><a href="#a-4--2t-sram-for-searching-and-in-memory-computing-with-03-v-vddmin">A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin</a><ul><li><a href="#%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D">背景介绍</a></li><li><a href="#%E7%8E%B0%E6%9C%89%E5%B7%A5%E4%BD%9C%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98">现有工作存在的问题</a></li><li><a href="#%E6%9C%AC%E6%96%87%E7%9A%84%E7%9B%AE%E6%A0%87">本文的目标</a></li><li><a href="#%E6%9C%AC%E6%96%87%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82">本文工作细节</a><ul><li><a href="#4--2t-sram-cell-%E7%BB%93%E6%9E%84">4 + 2T SRAM Cell 结构</a></li><li><a href="#sram%E6%94%AF%E6%8C%81%E7%9A%84%E6%93%8D%E4%BD%9C%E6%A8%A1%E5%BC%8F">SRAM支持的操作模式</a></li></ul></li><li><a href="#%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C">测试结果</a></li><li><a href="#%E6%80%BB%E7%BB%93">总结</a></li></ul></li></ul><!-- /TOC --><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-14056.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>传统的冯诺依曼 (CVN) 架构在memory bank和计算元素之间持续传输数据，会产生大量的能源和延迟成本，这些成本可能会影响系统功率和性能，如图1所示。为了最小化能耗和延迟，最近提出了IMC(In-Memory Computing)。IMC同时激活多行，直接在BL上进行逻辑操作。IMC不仅减少了数据移动以及操作的延迟，而且受益于memory bank的高带宽，有可能实现高并行计算。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-14602.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>如图2所示，基于6T SRAM的IMC相比于传统冯诺依曼（CVN）显示出比较大的能效和速度优势。</p><h2 id="现有工作存在的问题"><a href="#现有工作存在的问题" class="headerlink" title="现有工作存在的问题"></a>现有工作存在的问题</h2><p>但是SRAM-based IMC仍存在一下问题：</p><ul><li>当多行同时激活时，传统的6T SRAM的读取噪声容限会降低。因此需要WL欠驱动来改善噪声容限，这会大幅度降低读取速度。此外，由于读取噪声容限下降，$VDD_{min}$被限制在大约0.7V。因此整体功耗很高。（memory access和leakage仍然主导IMC的系统能耗，如图2b所示。）</li><li>8T SRAM通过隔离SRAM的读取路径和编程路径，能够有效的提高读取的噪声容限，但是面积开销会增加30%。同时由于只有一根BL用于读取，8T SRAM只能实现AND逻辑。</li><li>10T SRAM能够克服8T SRAM的不足，但是会带来更大的面积开销。</li></ul><h2 id="本文的目标"><a href="#本文的目标" class="headerlink" title="本文的目标"></a>本文的目标</h2><p>因此，本文的目标是：<font color="blue">提出4 + 2T SRAM单元的方案，能够实现比传统6T SRAM更好的读取噪声容限，同时带来较小的面积开销，以及以较小的能耗支持更多的计算。</font></p><h2 id="本文工作细节"><a href="#本文工作细节" class="headerlink" title="本文工作细节"></a>本文工作细节</h2><h3 id="4-2T-SRAM-Cell-结构"><a href="#4-2T-SRAM-Cell-结构" class="headerlink" title="4 + 2T SRAM Cell 结构"></a>4 + 2T SRAM Cell 结构</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-15742.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该论文提出的4 + 2T SRAM结构如图3(a)所示。该SRAM中PU是使用DNW制作的深耗尽PMOS，能够通过体偏效应控制PMOS的阈值电压，从而不需要PG，只需要四个管子即可进行SRAM的编程。同时，读取BL也通过栅控晶体管与SRAM cell进行隔离，cell的电位能够通过栅控晶体管控制BL的放电与否，但是BL上的电压无法反向传播改写SRAM的值，因此可以同时打开多行SRAM进行计算。此外，互补的RBL和RBLB可以实现更多的逻辑操作。</p><h3 id="SRAM支持的操作模式"><a href="#SRAM支持的操作模式" class="headerlink" title="SRAM支持的操作模式"></a>SRAM支持的操作模式</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-21449.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>4 + 2T SRAM支持的所有操作以及各端口电压配置如表1所示。</p><ol><li><p>Write</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-21738.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图5展示了对2x2 SRAM阵列进行写操作。在Standby模式下，WBL和WBLB都处于高电平$VDD_H$，其中$VDD_H$高于$VDD$。对SRAM单元进行写操作时，以写”0”为例，先将WBL拉低至GND，此时节点n1从$VDD$降低至$V_{thp}$。然后拉低WWL，以降低PU的阈值电压，n1对应的PU导通，将n1拉低到0，同时n2对应的PU开启，PD关断，n2被上拉到1，WBL/WBLB上的输入会被写入SRAM单元中。</p></li><li><p>Read</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-24145.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>正常读操作如图9(a)所示，读操作时，某一行对应的RWL/RWLB被拉低到GND以激活读操作，SRAM cell保存的值决定两个栅控晶体管的开关，从而导致RBL或RBLB连通到RWL或RWLB放电，通过两个差分SA可以检测出RBL和RBLB上的电压。这边存在两点考虑：(1) 使用差分SA代替单端反相器，以提高感测速度；(2) 如果未选择行保存的值为1，则会导致RWL向RBL漏电，RBL无法下拉到GND，因此使用差分交叉耦合SA，能够检测RBL上很小的电压下降。</p></li><li><p>In-Memory-Logic operations</p><p>如图9(b)所示，该电路支持AND, NOR和XOR逻辑操作，所有的逻辑操作都在一个周期内完成。</p></li><li><p>BCAM</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-24717.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>BCAM操作如图11(a)所示，此时RBL和RBLB复用为SL和SLB，作为搜索的输入。RWL复用为ML。如果搜索的属于与该行保存的数据完全匹配，则不存在任何的ML不存在任何的放电通路。否则，SL或SLB将ML拉低，行方向的SA用于BCAM的检测。<br>该方案于传统的6T SRAM-based BCAM的优势在于：(1) 搜索仍是按行进行，因此保存的数据不需要转置（按列保存）；(2) 多行同时激活，数据不会被改写。图12展示的是一个BCAM搜索的例子。<br><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-25515.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p></li><li><p>TCAM</p><p>TCAM操作原理如图11(b)所示，操作于BCAM类似，区别在于使用2个cell保存三种状态。图13展示的是一个TCAM搜索的例子。<br><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-25525.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p></li></ol><h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95055.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95240.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95317.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图16显示了测量单元的write margin，绿色区域表明超过5$\sigma$的write margin，其中标注的balanced green region至少存在200mV margin。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95331.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图17显示：</p><ul><li>0.8V VDD下，写频率达到600MHz；</li><li>最小供电电压为VDD/VDDH=0.25/0.30V；</li><li>最优的写能效为4.02 fJ/bit，对应VDD=0.35V.</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95920.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图18是在1-bit mismatch下测量，结果表明：</p><ul><li>BCAM操作的$VDD_{min}=0.35V$，此时对应最优的BCAM搜索能效0.13 fJ/bit。</li><li>TCAM和TCAM实现的频率相同，在VDD=0.8V时达到225MHz。</li><li>TCAM的搜索能耗是BCAM的2倍。</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-100412.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图19表明：</p><ul><li>read $VDD_{min}=0.25V$;</li><li>logic operation $VDD_{min}=0.35V$（emploing single-port sensing and half-strength SA）;</li><li>最优读能效为3.96 fJ/bit，对应VDD=0.35V；</li><li>最优逻辑操作能效为6.57 fJ/bit，对应VDD=0.35V；</li><li>最高读频率350 MHz;</li><li>最高逻辑操作频率270 MHz。</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-100427.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>与近存计算相比，总延迟降低35%，总能耗降低25%。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-103838.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>实现最低的访问能耗和比较好的$VDD_{min}$</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-103854.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>我们以最小的面积开销实现了可比的$VDD_{min}$和最低的读取能量。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-103908.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>4 + 2T SRAM方案：</p><ul><li>相比于8T SRAM方案，面积节省15%。</li><li>差分解耦读取路径可实现可靠的多字同时激活以执行布尔逻辑功能。</li><li>与近内存计算相比，IMC 分别节省了 35% 和 25% 的延迟和能源。</li><li>BCAM 在 0.35 V 下达到 0.13 fJ/search/bit。</li><li>工艺角仿真实现0.3V读/写$VDD_{min}$。</li><li>该工作需要额外的电压供电。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Survey of SRAM-based Processing-in-Memory Techniques and Applications</title>
      <link href="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/"/>
      <url>/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/</url>
      
        <content type="html"><![CDATA[<h1 id="A-Survey-of-SRAM-based-Processing-in-Memory-Techniques-and-Applications"><a href="#A-Survey-of-SRAM-based-Processing-in-Memory-Techniques-and-Applications" class="headerlink" title="A Survey of SRAM-based Processing-in-Memory Techniques and Applications"></a>A Survey of SRAM-based Processing-in-Memory Techniques and Applications</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>随着冯诺依曼计算架构越来越受到数据移动开销的限制，研究人员开始探索内存处理(PIM)技术来抵消数据移动开销。由于SRAM的广泛使用，用于SRAM的PIM技术有望加速广泛的计算系统和应用程序。在本文中，我们对使用SRAM存储器进行内存处理的技术进行了调查。我们回顾了使用SRAM-PIM来实现布尔运算、搜索和算术运算，以及用于机器学习（尤其是神经网络）和自动机计算的加速器。本文旨在通过向算法和硬件架构领域的研究人员介绍基于SRAM的PIM技术的最新发展来加速协同设计工作。</p><h2 id="索引词"><a href="#索引词" class="headerlink" title="索引词"></a>索引词</h2><p>Review, deep neural networks, SRAM, cache, computing in memory, neural network, automata computing</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>数据传输产生的能量比算术运算高一百多倍。因此，传统的“冯诺依曼式”以计算为中心的处理器受到数据移动开销的严重限制。“内存处理”（PIM）是一种避免数据移动惩罚的有前途的方法。由于SRAM是一种商业成熟的技术，并且已经可用于各种规模和形状的计算系统，因此SRAM-PIM方法可以对计算行业的格局产生革命性的影响。</p><p>要了解SRAM-PIM的潜力，以具有多级缓存的CPU为例。在缓存子系统中，数据移动以两种方式发生。首先，数据传输发生在缓存级别之间。例如，数据从LLC移至L1，然后移至寄存器，最后移至功能单元。启用PIM的LLC可以避免这些开销。此外，共享LLC可以降低两个内核之间共享数据的开销，因为可以避免通过共享LLC在不同内核的私有L1缓存之间传输块。其次，由于H树互连上的数据传输和控制结构，缓存内部会产生延迟。在4GHz频率下，SRAM访问和LLC访问延迟分别为1个周期和30个周期。由于PIM方案仅访问SRAM阵列，因此它们产生的延迟可以忽略不计。</p><p>SRAM-PIM可以极大地有益于数据密集型应用，例如神经网络和模式匹配。例如，神经网络训练在大型数据集上运行，推理涉及对不同层的权重的计算。完全在SRAM中执行布尔运算和算术运算可以提高它们的效率。类似地，基因组学和自然语言处理中的许多模式匹配应用程序执行有限自动机式处理。在模式匹配应用中使用SRAM-PIM时，自动机状态转换完全发生在存储器内部。这避免了在基于CPU的处理中产生的分支错误预测和不规则内存访问的开销。此外，使用具有高扇入和扇出的互连可以将输入序列与许多候选序列相匹配。因此，SRAM-PIM可以提供大量的并行性。同样，在内存中执行搜索和比较操作可以提升压缩、编码和搜索引擎的性能。基于PIM的逻辑操作可以加速加密、图形索引和数据库应用程序。</p><p>然而，SRAM-PIM的使用也带来了许多挑战。在6T SRAM中，PIM的使用会导致严重的可靠性问题，例如读取干扰和读取噪声容限下降。虽然使用8T或10T单元减轻了这些限制，但它们也会导致更高的面积开销。此外，为大规模DNN设计加速器会带来诸如大列电流等挑战，这会导致供电问题和传感故障。最后，模拟域操作需要消耗大量面积和能量的ADC/DAC。显然，实现SRAM-PIM的全部潜力需要新颖和智能的技术。</p><p>在本文中，我们对基于SRAM的PIM技术进行了调研。图1显示了该论文的概述。第2节提供了动机和分类。第3节介绍了基于SRAM-PIM的逻辑、搜索和算术运算的实现。第4节展示了使用SRAM-PIM来加速神经网络应用。第5节展示了它在加速机器学习、自动机处理和偏微分方程求解方面的用途。第6节总结了论文，并简要提及了未来的研究挑战。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-112116.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>本文中经常使用以下缩写词：位线（BL）、位线条（BLB）、二元/-卷积/深度神经网络（BNN/CNN/DNN）、反向传播（BWP）、二元/三元内容可寻址存储器 (BCAM/TCAM)、缓存自动化 (CA)、卷积 (CONV)、数模转换器 (DAC)、双端口互锁存储单元 (DPDICE)、确定性下推自动机 (DPDA)、特征图 (fmap)、完全连接（FC）、指令集架构（ISA）、反相器（INV）、最近邻（kNN）、末级缓存（LLC）、查找表（LUT）、本地位线（LBL）、乘法和累加（MAC）、单片 3 维 (M3D)、矩阵向量乘法 (MVM)、非确定性有限自动机 (NFA)、感测放大器 (SA)、单指令多线程/数据 (SIMT/SIMD)、源代码行 (SL)、“连续-近似寄存器-模数转换器”（SAR-ADC）、支持向量机（SVM）、硅通孔（TSV）、“超大指令字”（VLIW）、字线(WL)、写 WL (WWL)、xnor 和累加 (XAC)</p><h2 id="动机和概述"><a href="#动机和概述" class="headerlink" title="动机和概述"></a>动机和概述</h2><p>在本节中，我们首先讨论实现基于SRAM的PIM（第2.1节）的挑战。为了正确看待事情，我们将SRAM-PIM方法与DRAM和RRAM中的PIM方法进行比较（第2.2节）。然后，我们提供了基于几个类别的研究工作分类（第2.3节）。</p><h3 id="基于SRAM的PIM的挑战"><a href="#基于SRAM的PIM的挑战" class="headerlink" title="基于SRAM的PIM的挑战"></a>基于SRAM的PIM的挑战</h3><ul><li><strong>SRAM密度低:</strong> SRAM具有低密度和高泄漏能量。因此，SRAM-PIM更适合小规模数据集。</li><li><strong>6T SRAM的局限性:</strong> 使用6T SRAM更适合设计最后一级缓存，因为它们已针对该区域进行了优化。在6T SRAM中，激活多行会降低读取噪声容限。它可以创建短路路径，可以随机翻转单元状态。此外，在BL放电后，由于6T SRAM的读写路径是共享的，因此激活下一个WL会导致伪写操作。<br>为避免数据损坏，可以调整WL电压。这严重限制了操作频率，例如Jeloka等人在1V下使用800 MHz频率，Wang等人在1.1V时使用475 MHz频率。此外，由于工作裕度小，Vdd不能低于0.7V。这导致高动态和泄漏能量消耗。为了提高噪声容限，需要进行WL欠驱动，这会增加读取延迟。作为避免6T SRAM数据损坏问题的另一种解决方案，可以使用脉宽调制WL。该解决方案避免了同时激活两个WL，但将外围电路的面积增加了2倍以上。<font color="blue">这边可以加上BLADE的local bitline</font></li><li><strong>8T/10T SRAM的局限性：</strong> 为了克服6T SRAM的限制，可以使用8T或10Tbitcell。8T SRAM将读和写路径解耦，这允许独立优化它们的读/写操作。这提高了裕度并允许降低最小Vdd，这降低了功耗。然而，与6T SRAM相比，8T SRAM会导致30%的面积损失。此外，由于8T SRAM使用单个读取BL，因此它仅计算AND运算。需要特殊的架构来支持其他逻辑功能。10T SRAM克服了这个问题，但会导致更高的面积损失。</li><li><strong>模拟域的限制：</strong> 模拟域操作更容易受到工艺变化、噪声、非线性I-V特性和老化的影响。此外，使用ADC/DAC会降低信号精度并造成能量/面积损失。</li><li><strong>映射大型DNN的挑战：</strong> 大规模DNN具有数千个量级的权重矩阵。然而，由于以下原因，无法在SRAM中实现如此大的矩阵：(1) 多个WL的激活需要高列电流。这会导致大量的瞬时功率，从而产生热和功率传输问题。(2) 工艺变化会使SA产生偏移。随着列电流的上升，感测失败的可能性更高。(3) 长导线具有高阻容(RC)延迟。这些挑战可以通过对SRAM阵列进行分区来缓解，该阵列将大矩阵拆分为多个较小的矩阵。但是，如果使用二元神经元累积来自不同子阵列的部分和，则此方法可能会影响分类精度。</li></ul><h3 id="在不同内存中处理内存中-近内存方法"><a href="#在不同内存中处理内存中-近内存方法" class="headerlink" title="在不同内存中处理内存中/近内存方法"></a>在不同内存中处理内存中/近内存方法</h3><p>比较不同内存技术中的 PIM 方法是很有见地的。</p><ul><li><strong>DRAM:</strong> 基于DRAM的内存处理提出了至关重要的挑战。(1) 由于DRAM读取是破坏性的，PIM计算破坏了原始数据。为了避免数据丢失，需要复制到别处，这会导致很大的开销。(2) 感测DRAM电容的余量小，导致模拟计算错误。修改单元设计的技术会导致大量的面积损失。(3) 技术差异阻碍了PIM所需的外围逻辑与DRAM的轻松集成。(4) DRAM中使用的数据/地址加扰技术对将其用于PIM操作提出了挑战。基于DRAM的近数据计算技术利用芯片堆叠将逻辑芯片与DRAM芯片集成在一起。然而，这会在制造和操作期间产生问题。</li><li><strong>RRAM:</strong> RRAM的优点是单元面积小。然而，RRAM设备具有非常低的耐用性和较大的写入延迟/能量。因此，频繁的重量更新可能会导致达到耐力极限。此外，基于RRAM的PIM在支持浮点计算方面面临着严峻的挑战。这是因为RRAM单元和ADC的分辨率有限。这需要使用多个单元格来表示浮点值。此外，指数归一化需要多次操作，由于RRAM的高延迟和低写耐久性，这尤其昂贵。事实上，范伯格等人使用128个RRAM单元来存储双精度 (64b) 数，其中64个单元仅用于执行归一化和对齐。相比之下，SRAM-PIM技术完全在SRAM阵列内部执行数字浮点计算。此外，在BWP阶段，使用转置权重矩阵执行CONV。为此，执行逐列读取操作，这会降低吞吐量和能源效率。</li></ul><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p>表 1 根据架构和实验参数对作品进行分类。如表 1 所示，大多数工作仅进行了电路或架构级评估。只有少数作品对从电路到系统的整个堆栈进行了评估。<br>表 2 根据它们的优化策略对作品进行分类。<br>表3根据实验平台和参数对作品进行分类。<br>表 4 根据实验结果对作品进行分类，例如它们的吞吐量和能效值。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114508.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114532.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114715.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114730.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114746.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="基于-SRAM-PIM-的搜索、逻辑和算术运算"><a href="#基于-SRAM-PIM-的搜索、逻辑和算术运算" class="headerlink" title="基于 SRAM-PIM 的搜索、逻辑和算术运算"></a>基于 SRAM-PIM 的搜索、逻辑和算术运算</h2><p>在本节中，我们将讨论基于SRAM-PIM的搜索操作（第3.1节）、逻辑运算（第3.2节）和算术运算（第3.3节）的实现。表5显示了由各种技术执行的基本操作。在BNN中，CONV操作被简单地计算为按位XNOR和population-count操作。因此，基于SRAM-PIM的XNOR实现可以加速BNN。<br>XOR运算可以使用NOR和AND运算来实现，如下所示： A XOR B = (A AND B) OR (A AND B)。大于/小于操作是通过减去操作数并读取MSB来执行的。大多数作品通过使用移位加法来执行乘法。对于有符号数的乘法，乘积的符号位是通过计算操作数的符号位的异或来获得的。</p><h3 id="搜索操作"><a href="#搜索操作" class="headerlink" title="搜索操作"></a>搜索操作</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-161130.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>通常，BCAM使用10T SRAM，TCAM使用16T SRAM。然而，非推规则CAM位单元比推规则6T SRAM大得多，这使得CAM区域非常大。杰洛卡等人提出了一种使用推式6T SRAM位单元设计的CAM电路。它们以列方式存储单词，如图 2(a)所示。它们的电路设计如图 2(b)所示。WL分为WL-right和WL-left，它们创建了两个独立的存取晶体管。搜索查询及其互补分别应用于WL-right和WL-left。如果匹配，BL和BLB都保持在Vdd。在不匹配的情况下，它们中的一个或两个放电。使用两个单端SA分别读取它们。它们之间的AND运算显示列中的匹配项。该过程对所有列并行完成。总体而言，他们的技术将搜索数据与存取晶体管中存储的数据执行XNOR，然后在BL SA上执行AND运算。</p><p>TCAM需要为每个单词使用两列，这将其容量减少了一半。在TCAM中，0和1分别对应组合“00”和“11”，而X对应组合“01”。屏蔽位(X)不会拉低BL或BLB，因为它在两个位置都存储了1。因此，它匹配搜索查询的0和1。要写入CAM，可以在内存模式下以行方式写入数据的转置。但是，这只执行批量写入，不允许写入特定元素。为了允许逐列写入操作，他们提出了一种写入策略，该策略在BCAM的两个周期和TCAM的三个周期内完成。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-161206.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>SRAM可以在三种模式下运行：内存、BCAM或TCAM。在传统存储模式中，字按行存储，地址应用于WL，正在读取的数据在BL上可用。他们提出的存储器可以对以行方式存储的多个字执行AND和NOR运算。例如，要实现与运算，就使用了BCAM模式。在这里，通过向WL-left和WL-right都提供0来屏蔽搜索字符串的输入位（在图 3中显示为M）。使用它，可以激活多行的WL。在图 3中，搜索查询是(1,M,1,M)，它为第1行和第3行启用WL-right。如果第1行或第3行中的任何位为0，则预充电的BL被下拉。此外，所有WL左晶体管都被停用，所有BLB保持高电平。这计算第1行和第3行的按位与。</p><p>为了执行NOR操作，只有WL左存取晶体管被激活，并且在搜索查询中应用0。“01”模式激活A行的WL-left和B行的WL-right。这读取BLB SA上的A和BL SA上的B。这些的AND运算提供了输出。他们的CAM实现了比传统CAM设计高四倍的密度。然而，在CAM模式下，他们的技术以比内存模式低的速度运行。此外，实现可重构功能所需的额外外设会导致较小的面积开销。</p><p>位线计算方法基于以下观察：在同时激活多个（例如，高达64个）WL时，共享BL提供存储在这两个激活行中的数据之间的NOR和AND运算的结果。为了防止由于多行访问而导致数据退化，降低WL电压以偏置SRAM阵列上的写入。通过进一步降低WL电压，可以增强鲁棒性，但也会增加延迟。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-161222.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>董等人提出了一种基于“深耗尽沟道”技术的4+2T SRAM单元。它可以执行逻辑操作并充当BCAM/TCAM。单元设计如图 4(a)所示。它具有解耦读写路径。该单元有6个晶体管，其中4个晶体管形成交叉耦合反相器对。这些逆变器具有不同的Vdd端子，用作WBL/WBLB。另外两个晶体管用作允许差分读取的存取晶体管。他们的单元有两个“栅极连接的差分读取端口”。这将存储节点与RWL和RBL/RBLB隔离。这提高了“读取噪声容限”并提高了激活多个字时的电路可靠性。该单元将n阱用作WWL，从而无需写存取晶体管。</p><p>他们使用差分RBL和RBLB来实现PIM操作。PIM操作的工作原理如图 4(b)所示。对于PIM，最初，RBLB和RBL都预充电到Vdd。此后，同时启用两对WL。如果A或B等于1，则RBL放电，因此，RBL计算(A NOR B)。如果A和B都等于1，则RBLB变高，因此，RBLB计算(A AND B)。他们用两个微小的差分SA评估RBLB和RBL。在通过来自Vdd的小电压降低RBL/RBLB时，SA在潜行电流消失之前将RBL/RBLB上的电压与参考电压(Vref)进行比较。由于SA的不同操作，AND/NAND和OR/NOR是同时计算的。两个SA结果之间的NOR门计算A XOR B。</p><p>对于CAM功能，RBL/RBLB提供搜索数据SL/SLB。此外，两个存取晶体管的RWL被分成ML/MLB。对于BCAM，一行的MLB和ML短接为一个ML。如果一行中的整个输入与存储的数据相同，ML保持高电平，否则它会被释放。每个ML都包含一个行级SA，其一端连接到Vref以评估结果。TCAM需要两个单元格。这里，ML[0]和MLB[1]相连，将单元A和B组合为一个TCAM单元。当AB单元格的值分别为00/11/01时，它表示1/0/X。他们的“4+2T单元”具有比6T SRAM更好的噪声容限和比8T SRAM更小的面积。此外，BCAM可以在0.3V的最小Vdd下运行。他们设计的局限性在于它依赖于一个不常见的4T位单元，该位单元面临不稳定和读取干扰问题。此外，它具有较差的性能/电压缩放（0.6V 时为 100Mhz）。</p><h3 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h3><h4 id="使用-2D-SRAM-对两个操作数的操作"><a href="#使用-2D-SRAM-对两个操作数的操作" class="headerlink" title="使用 2D SRAM 对两个操作数的操作"></a>使用 2D SRAM 对两个操作数的操作</h4><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-162315.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>阿加等人通过修改Jeloka等人提出的位线计算电路，提出了一种in-SRAM计算技术。他们添加了一个解码器来缓存子数组，这会激活两个WL，每个操作数一个。差分SA被重新配置以获得两个单端SA。它们用于分别感测绑定到位单元的两个BL。它们通过对BL和BLB进行NOR运算来扩展用于实现XOR运算的电路。为了比较两个字，他们使用有线NOR组合按位异或结果。搜索是通过与存储在子数组中的缓存块重复比较来执行的。为了将一个WL复制到另一个WL，SA的输出被反馈到BL。由于最后一个读取值要在下一个周期写入，因此“读写操作”合并以有效复制数据，如图5（a）所示。为了清零缓存块，在写操作之前，输入数据锁存器被复位。为了实现“无进位乘法”，首先将两个子阵列行进行“与”运算。然后，使用“XOR减少树”减少结果位。</p><p>PIM操作需要“操作数局部性”，即操作数必须映射到共享相同BL的子数组。他们将“块分区”定义为共享相同BL的子阵列中缓存块的集合。块分区中保存的任何两个缓存块之间都可以进行就地计算。考虑图 5(b)，它显示了一个带有四个子阵列的组。这里，子阵列中的每一行都有两个缓存块，因此每个子阵列都有两个块分区。就地计算可以发生在映射到相同“块分区”的块之间，例如，集合S1和S3中的块。如图 5(b)所示，他们的技术将集合的所有方式映射到相同的“块分区”，无论缓存块的存储方式如何，它都保留了操作数的局部性。此外，如图 5(c)所示，一些设置索引位（称为OLbits）用于决定块的存储体和分区。如果两个操作数的这些位相同，则将它们映射到同一分区。将集合的所有方式映射到同一分区的局限性在于它禁止并行标记数据访问。这种优化一般用在L1缓存中，以牺牲能量开销为代价来提高速度。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Chronos: Efcient Speculative Parallelism for Accelerators</title>
      <link href="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/"/>
      <url>/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/</url>
      
        <content type="html"><![CDATA[<p>ASPLOS-2020<br>Author: Maleen Abeydeera, Daniel Sanchez<br>Affiliations: MIT</p><!-- TOC --><ul><li><a href="#motivation">Motivation</a></li><li><a href="#target">Target</a></li><li><a href="#introduction">Introduction</a><ul><li><a href="#%E5%85%88%E5%89%8D%E5%8A%A0%E9%80%9F%E5%99%A8%E4%B8%AD%E7%9A%84%E5%B9%B6%E8%A1%8C%E7%B1%BB%E5%9E%8B">先前加速器中的并行类型</a></li><li><a href="#%E5%85%88%E5%89%8D%E7%9A%84%E6%8E%A8%E6%B5%8B%E6%9E%B6%E6%9E%84%E4%BE%9D%E8%B5%96%E4%BA%8E%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7">先前的推测架构依赖于缓存一致性</a></li><li><a href="#%E6%8A%95%E6%9C%BA%E6%89%A7%E8%A1%8C%E7%9A%84%E5%8E%9F%E5%9B%A0">投机执行的原因</a></li></ul></li><li><a href="#slot%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B">SLOT执行模型</a><ul><li><a href="#slot">SLOT</a></li><li><a href="#%E5%B0%86%E5%A4%9A%E5%AF%B9%E8%B1%A1%E8%AE%A1%E7%AE%97%E6%98%A0%E5%B0%84%E5%88%B0slot">将多对象计算映射到SLOT</a></li><li><a href="#discussion">Discussion</a></li></ul></li><li><a href="#chronos%E7%B3%BB%E7%BB%9F">Chronos系统</a><ul><li><a href="#%E8%AE%BE%E8%AE%A1%E8%A6%81%E6%B1%82%E5%92%8C%E6%8A%80%E6%9C%AF">设计要求和技术</a></li><li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%89%E5%BA%8F%E6%8E%A8%E6%B5%8B">分布式有序推测</a></li><li><a href="#%E4%BB%BB%E5%8A%A1%E5%8D%95%E5%85%83%E8%AE%BE%E8%AE%A1">任务单元设计</a><ul><li><a href="#%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97">任务队列</a></li><li><a href="#%E6%8F%90%E4%BA%A4%E9%98%9F%E5%88%97">提交队列</a></li></ul></li></ul></li></ul><!-- /TOC --><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>先前的加速器专注于易于利用并行性的领域，例如深度学习，并依赖于传统的并行化技术，如数据并行或数据流执行。</p><h2 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h2><p>在本文中，作者专注于为需要推测执行来提取并行性的应用程序构建加速器。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>例如，考虑离散事件模拟(des)，它在模拟数字电路、网络系统和物理过程方面具有广泛的适用性。离散事件模拟由动态创建的任务组成，这些任务可以在同一个模拟对象上运行，并且必须以正确的模拟时间顺序运行。非推测地运行这些任务需要过多的同步并限制并行性。推测性地运行任务更有利可图。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/2021831-215733.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>如Listing 1所示，每个des任务在特定时间处理一个门输入切换。如果此输入切换导致门的输出切换，则任务会在适当的时间将所有连接到该输出的输入的事件排入队列。顺序实现以模拟时间顺序一次处理一个任务，并在优先级队列中维护要处理的任务集。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/2021831-220352.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>以数字电路模拟为例，如Figure 1所示。Figure 1(a) 显示了具有输入波形和传播延迟的电路，Figure 1(b) 显示了在该电路上执行 des 的任务图。任务之间的箭头表示父子依赖关系（例如，任务O1创建任务A4和X6）。x轴显示任务顺序，y轴中任务的位置代表它操作的门。</p><p>在这个des中，我们可以发现一个很重要的现象：只有在同一门上操作的任务才具有数据依赖性；其他（例如，O1 和 N2）可能会在不违反正确性的情况下运行失序。但是任务和依赖项是未知的，因此乱序运行任务并不简单。虽然在des中，每个任务对单个对象（一个门）进行操作，并且这个对象是预先知道的。但这不足以确定哪些任务可以安全运行，因为一个任务可能与另一个在程序顺序中较早出现但尚不存在的任务相关。假设首先执行任务O1，产生任务X6。此时X6是系统中最早对XOR门进行操作的任务。但是执行X6会产生不正确的结果，因为X6必须遵循较早的依赖数据的任务X3，该任务尚不存在（因为N2尚未运行）。</p><h3 id="先前加速器中的并行类型"><a href="#先前加速器中的并行类型" class="headerlink" title="先前加速器中的并行类型"></a>先前加速器中的并行类型</h3><p>本文通过两个因素对并行类型进行分类：（1）任务是预先知道的还是动态创建的？（2）如果任务对共享数据进行操作，它们应该如何同步以应对算法的数据依赖性并产生正确的结果？<br>按此标准可以分为四类：</p><ul><li><strong>Static parallelism:</strong> 如果预先知道任务及其数据依赖性，则调度可以静态完成，不需要或需要非常简单的运行时机制。在对常规数据结构（例如密集矩阵）进行操作时会出现静态并行性。大多数先前的加速器都专注于静态并行性，如通过构建深度流水线和数据并行硬件，例如DaDianNao和Google的TPU。</li><li><strong>Dynamic parallelism with independent tasks:</strong> 某些算法，例如对树或图形进行操作的算法，必须动态创建任务，因为它们需要做更多的工作。在最简单的情况下，任务对不相交的数据进行操作，并且共享数据访问不需要同步。他们采用了由ESL和Cilk开创的fork-join模型。ParallelXL和TAPAS加速器针对这种动态并行性。它们的关键组成部分是对任务创建和负载平衡的硬件支持。</li><li><strong>Non-speculative synchronization of dependent tasks:</strong> 先前的工作已经展示了加速器，其中任务对共享数据进行操作，但大多数同步是通过停止而不是推测来实现的。</li><li><strong>Speculative synchronization of dependent tasks:</strong> 最后，Ma等人在FPGA上为图形分析应用程序构建加速器。它们支持原子任务，每个任务可以访问多个地址，冲突检测是使用全局共享的地址跟踪结构实现的，类似于一致性目录。因此，这种方法类似于基于一致性的冲突检测，并受到额外开销的影响。</li></ul><h3 id="先前的推测架构依赖于缓存一致性"><a href="#先前的推测架构依赖于缓存一致性" class="headerlink" title="先前的推测架构依赖于缓存一致性"></a>先前的推测架构依赖于缓存一致性</h3><p>先前的推测架构很难应用于加速器，因为它们都依赖于一致的缓存层次结构来执行推测执行，通过一致性协议检测任务之间的冲突。它需要实现一致的缓存和推测跟踪结构，虽然对于通用内核来说开销很小，但对于小型专用内核来说太昂贵了。(虽然依赖一致性对于多核来说是合理的，但对于加速器来说却是昂贵的。 一般的加速器和特别是可重新配置的硬件没有支持基于失效的冲突检测的一致缓存层次结构。实现一致性会增加复杂性、延迟和重要的片上 SRAM 以实现跟踪共享者的目录。除了一致性之外，对具有任意读写集的任务执行冲突检测会增加额外的开销，例如，每个核心价值几千字节的 Bloom 过滤器，这对于专门的处理核心来说太繁重了。)</p><h3 id="投机执行的原因"><a href="#投机执行的原因" class="headerlink" title="投机执行的原因"></a>投机执行的原因</h3><p>通常，当任务具有未知的读写集或任务间顺序约束时，需要进行推测。<br>为了应对这一挑战，在本文中，我们提出了一个硬件系统，该系统在不使用一致性的情况下实现推测执行。 相反，该系统遵循以数据为中心的方法，其中共享数据映射到整个系统； 工作被分成小任务，每个任务最多访问一个共享对象； 并且任务总是被发送到它们的数据被映射的地方运行。 为了强制跨任务组或其他顺序约束的原子性，任务通过时间戳排序（这些是完全与物理时间分离的程序指定的逻辑时间戳）。</p><p>通过SLOT (Spatially Located Ordered Tasks) 执行模型将这些语义形式化。在 SLOT 中，所有工作都通过使用时间戳排序的任务进行。一个任务可以创建在它们之后排序的子任务，并且父任务直接将输入值传递给子任务。==每个任务必须对单个读写对象进行操作，该对象必须在创建任务时声明（除此限制外，任务可以访问任意数量的只读数据）==</p><p>而本文提出的架构就是针对SLOT执行模型的实现，这可以在没有缓存一致性协议的情况下实现完全分布式操作。</p><h2 id="SLOT执行模型"><a href="#SLOT执行模型" class="headerlink" title="SLOT执行模型"></a>SLOT执行模型</h2><p>SLOT 限制每个任务访问单个读写对象，这在创建任务时必须知道。</p><h3 id="SLOT"><a href="#SLOT" class="headerlink" title="SLOT"></a>SLOT</h3><p>SLOT 应用程序由有序的、动态创建的任务组成。 每个任务都可以用软件或硬件来实现。 我们独立于实现来描述执行模型，并使用软件 API 对其进行说明。</p><p>每个任务在创建时都有两个属性：时间戳和对象ID。时间戳指定顺序约束：系统保证任务似乎按时间戳顺序执行。 具有相同时间戳的任务可以以任何顺序运行，但都是原子的（即它们不交错）。<br>对象id是指定任务之间数据依赖性的整数：当且仅当两个任务具有相同的对象id时，它们才被视为数据相关。对象ID限制每个任务最多访问共享内存中的一个读写对象。请注意，此限制仅适用于读写数据。一个任务可以访问任意数量的只读数据。<br>SLOT任务可以通过指定子任务的类型、时间戳、对象ID和它可能需要的任何输入数据值，在发现更多工作时创建子任务。每个子任务可能有任何大于或等于其父任务的时间戳。</p><p>在SLOT中，父子关系是单向的：父任务可以创建值并将值传递给它的子任务，但父任务在子任务之前被排序，因此在子任务执行之前完成。子任务不能返回值或与其父母通信。这与像Cilk这样的fork-join执行模型不同，在这种模型中，父母等待他们的孩子完成。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-10208.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ul><li><strong>API:</strong> Listing 2通过显示des任务的实现来说明SLOT软件API。在软件中，每个任务都由一个函数实现。该实现与Listing 1中的顺序实现几乎相同：每个任务模拟特定门的输入切换。这段代码通过调用slot::enqueue创建新任务，而不是将任务排入优先级队列，它指定了子任务的类型（它的函数指针，因为它是一个软件任务）、时间戳、对象ID和任何附加参数（门在这种情况下输入）。</li><li><strong>SLOT enables coherence-free conﬂict detection:</strong> 通过限制每个任务最多访问一个读写对象，SLOT的实现可以在没有复杂跟踪结构的情况下执行分布式冲突检测。如果实现将对象id映射到核心或区块，并将每个任务发送到其对象id映射的位置，那么查找冲突就成为本地操作。<br>例如，如果Fig. 1在四核系统上运行，NAND、OR、XOR和AND门可以映射到内核1-4。然后，如果任务X3在X6已经运行后到达核心3，核心3可以通过将X3的对象ID与仍然推测的任务的对象ID进行比较，在本地确定X3的冲突（相同门和更高时间戳的任务，在本例中为{X6}）。</li></ul><h3 id="将多对象计算映射到SLOT"><a href="#将多对象计算映射到SLOT" class="headerlink" title="将多对象计算映射到SLOT"></a>将多对象计算映射到SLOT</h3><p>多对象事务也可以表示为SLOT任务，方法是将每个事务分解为多个单对象任务，每个任务访问一个对象，并为每个事务提供不相交的时间戳范围。这样，事务中的任务不会与其他事务中的任务重叠。</p><p>例如，考虑一个银行应用程序，其中交易在帐户之间转移资金。每笔交易都必须自动减少源帐户的余额并增加目标帐户的余额。每个帐户都应该是不同的对象，但由于账户余额是读写数据，单个任务不能访问两个账户。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-11826.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Fig. 3显示了任务顺序如何使这成为可能。我们使用两个SLOT任务实现每笔交易，每个任务操作一个帐户：第一个减少源的余额并创建第二个任务来增加目的地的余额。每个事务都有一个不相交的时间戳范围，因此来自不同事务的任务不会交错。</p><p>这种技术推广到读写操作的任意组合。例如，我们的maxflow实现（第5节）使用它在图顶点的邻域上执行复杂的原子操作。</p><p>虽然将每个事务分解为许多小任务可能会给软件运行时增加大量开销，但小任务是加速器的自然匹配，因为硬件执行任务管理，小任务需要简单的处理元素。</p><h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><ul><li><strong>SLOT细粒度任务的好处:</strong> SLOT与先前工作相比的主要优势是实现无相干冲突检测。此外，先前的工作表明，即使在支持具有任意读/写集的任务的系统中，这种划分通常也是可取的，主要有以下三个原因：</li></ul><ol><li>增加并行性：将长串行事务分解为短任务允许这些任务并行运行。</li><li>减少中止的影响：在误推测时，只有冲突的任务被中止，而不是整个事务。</li><li>增加数据重用：不是在事务运行的系统中共享数据，而是将任务发送到靠近它们的数据运行，避免缓存行乒乓。由于每个任务消息比缓存行小得多，这减少了流量；并且任务是异步发送和执行的，因此它们的延迟比同步内存访问更容易隐藏。</li></ol><ul><li><strong>SLOT的局限:</strong> 虽然将程序分成短的单对象任务通常是有益的，但在一种情况下，基于一致性的冲突检测会优于SLOT：如果应用程序由很少修改的读写数据主导，这些数据具有大量重用，则基于一致性的冲突检测将允许在整个系统中缓存这些数据，在本地的零星写入之间进行读取，而SLOT需要在单独的任务中隔离对这些数据的每次访问，并将它们发送到一个地方。<br>我们在目标应用程序中没有发现这种行为，因此我们没有针对这种情况优化SLOT。SLOT的一个简单扩展可以通过让任务写入其对象ID未涵盖的地址来解决此问题。然后，系统可以将很少修改的数据视为只读数据，并允许将它们私下缓存。在写入时（这种情况很少见），一个简单的实现可以刷新所有缓存并中止所有未来任务；更复杂的实现可能会执行更精确的刷新和冲突检测。我们将对这些实施选择的详细研究留给未来的工作。</li></ul><h2 id="Chronos系统"><a href="#Chronos系统" class="headerlink" title="Chronos系统"></a>Chronos系统</h2><p>Chronos是一个架构框架，可以轻松地为具有有序并行性的应用程序设计加速器。<br>Chronos通过提供有效实现SLOT执行模型的架构模板来实现这一点。然后加速器可以通过定义他们自己的任务处理引擎或配置Chronos的非核心组件来专门化这个模板。通过这种划分，创建Chronos加速器就像指定处理引擎一样简单；该框架负责处理有序任务管理和推测执行的复杂性。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-13713.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Fig. 4显示了Chronos的组织架构。Chronos是一种平铺设计，具有完全分布式的任务管理和推测机制。每个tile都有多个执行任务的处理元素(PE)、一个本地（非一致性）缓存和一个用于排队、分派和提交有序任务的任务单元。</p><p><font color="blue">即使我们无法使用这个架构来完全处理无线项目的通用程序，但是这个架构解决了一类任务，可以放置适量的PE来处理带有这种特性的部分代码。</font></p><h3 id="设计要求和技术"><a href="#设计要求和技术" class="headerlink" title="设计要求和技术"></a>设计要求和技术</h3><ul><li><strong>高吞吐量任务管理:</strong> 短任务对系统提出了高吞吐量要求。例如，如果每个任务需要20个周期来执行，那么具有200个PE的Chronos系统每个周期必须创建、分派、冲突检查和提交10个任务以保持PE忙碌。这迫使设计没有集中组件：所有任务管理和推测机制必须完全分布式。Chronos的平铺设计实现了这一点。此外，每个tile的任务单元也需要保持高吞吐量。</li><li><strong>大投机窗口:</strong> 为了防止顺序限制并行性，系统必须能够在最早的未完成任务之前进行推测。更具体地说，由于顺序限制，任务在提交之前可能会在很长一段时间内处于推测状态——远远超过它们执行所需的时间。因此，系统应该能够跟踪比运行任务更多的推测任务。例如，正如我们将在Sec.6中看到的那样，有些应用程序每个运行任务需要大约10个推测任务</li></ul><p>这些要求强制完全分布式、深度无序执行。</p><h3 id="分布式有序推测"><a href="#分布式有序推测" class="headerlink" title="分布式有序推测"></a>分布式有序推测</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-34155.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Chronos使用推测执行来消除顺序约束。<br>Chronos可以在创建后立即运行任何任务，即使它的祖先仍然是推测性的。图5显示了每个任务的执行流程。顶部水平箭头表示正确的推测。当一个任务被创建时，它被发送到一个tile，它在那里保持空闲，排队直到它准备好分派。tile按时间戳顺序将空闲任务分派给PE。正在运行的任务完成执行后，它会保持推测（处于完成状态），直到系统确定可以安全提交。</p><p>Fig. 5显示任务可以在提交之前的任何时候中止。由于任务可能会在其祖先仍处于推测状态时运行，因此中止任务需要中止并丢弃其所有后代。这些级联中止是发现并行性所必需的，并且是有选择性的：中止会撤消中止任务、其后代以及按程序顺序稍后出现的任何数据相关任务的影响。如图5所示，如果一个任务因为它的父任务被中止而被中止，那么它就被丢弃；否则，中止是由于数据依赖性，然后任务重新排队执行。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-34746.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Fig. 6显示了Chronos中的推测执行示例。<br>任务被创建并无序运行：在Fig. 6a中，任务20已经运行并完成，即使较早的任务仍在运行；特别是任务0，即20的父任务，仍在运行。在Fig. 6b中，任务0创建了一个时间戳为10的子任务，它与任务15发生冲突。这导致任务15及其子任务25被中止。虽然中止可能影响多个任务，但它们是有选择性的：独立任务，例如20不会中止。</p><ul><li><strong>任务映射和冲突检测:</strong> 为了廉价地执行推测执行，Chronos使用了第3节中概述的任务映射和冲突检测策略。Chronos将对象id映射到tile，然后将每个创建的任务发送到映射其对象id的tile。我们当前的Chronos实现使用静态对象到图块映射：对象id被简单地散列以生成图块id。我们发现这在我们的工作负载中实现了良好的负载平衡；Chronos还可以基于tile之间对象的动态重新映射采用更复杂的负载平衡。</li><li><strong>任务调度:</strong> 任务单元按时间戳顺序将任务分派给PE，以优先处理较早的任务。为了避免冲突，任务单元将具有相同对象ID的任务的执行序列化。因此，运行任务之间的冲突永远不会出现；只有无序到达tile的任务才能产生冲突。</li><li><strong>投机价值管理:</strong> Chronos采用Eager版本管理：推测性写入更新内存，旧值写入单独的撤消日志。提交很快，因为撤消日志被简单地丢弃；中止需要从撤消日志中恢复旧值。<br>Eager版本管理有助于运行依赖数据的任务链，而无需等待它们提交：如果任务A写入的值稍后由（相同对象）任务B读取，即使A尚未提交，B也会自然地使用A的值.这个过程被称为推测转发，对于有序推测很重要，但是对于懒惰的版本管理来说很难做到。</li><li><strong>高吞吐量提交:</strong> 为了确定任务何时可以提交，Chronos从之前的工作中借用了全局虚拟时间 (GVT) 协议。Tiles定期（例如，每32个周期）通信以找到最早未完成任务的时间戳，然后提交所有较早的任务。此过程利用大型提交队列一次提交多个任务，以很少的通信实现每个周期多个任务的提交吞吐量。</li></ul><h3 id="任务单元设计"><a href="#任务单元设计" class="headerlink" title="任务单元设计"></a>任务单元设计</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-40232.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Chronos的任务单元由两个主要结构组成：一个任务队列(TQ)保存tile中的所有任务并将空闲任务分派到PE，以及一个提交队列(CQ)，保存正在运行或完成的任务的推测状态，并提交或中止他们根据需要。此外，一个小任务发送缓冲区(TSB)从PE接收新创建的任务并将它们发送到正确的tile。<br>Fig. 7详细说明了每个tile的微架构，并显示了这些结构，它们一起类似于任务级重新排序缓冲区。</p><h4 id="任务队列"><a href="#任务队列" class="headerlink" title="任务队列"></a>任务队列</h4><p>任务队列由两个主要结构组成：任务数组和顺序队列。任务数组是一个简单的内存，用于存储tile中每个任务的任务描述符。每个任务描述符包含运行任务所需的所有数据：其类型、时间戳、对象ID和参数。订单队列持有空闲任务并按时间戳顺序将它们分派给PE。<br>当任务到达tile时，任务会在任务数组和排序队列中分配条目。它们保留他们的订单队列条目，直到他们被分派到PE，但在他们的整个生命周期（即，直到他们提交或被丢弃）都保留他们的任务数组条目。这样，如果任务被中止，任务数组就有重新执行它所需的信息。当一个任务需要重新执行时，它被重新插入到订单队列中。<br><strong>任务溢出:</strong> 任务队列的容量有限，但SLOT程序可能会创建无限数量的任务。当任务队列快满时，Chronos通过将任务溢出到主内存来提供无限任务队列的假象。</p><h4 id="提交队列"><a href="#提交队列" class="headerlink" title="提交队列"></a>提交队列</h4><p>提交队列保存所有正在运行或已完成的任务的推测状态。在Chronos中，这种推测状态由任务的撤消日志（允许回滚任务的内存写入）和子指针（允许中止任务的后代）组成。<br>每个子指针跟踪子任务的tile和任务数组条目id。当一个孩子被创建时，它被发送到由其对象 id 指定的图块。 当接收 tile 将其排队时，它会回复子任务的指针。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ambit: In-Memory Accelerator for Bulk Bitwise Operations Using Commodity DRAM Technology</title>
      <link href="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/"/>
      <url>/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/</url>
      
        <content type="html"><![CDATA[<!-- 文章标题 --><!-- TOC --><ul><li><a href="#summary">Summary</a></li><li><a href="#research-objective">Research Objective</a></li><li><a href="#problem-statement">Problem Statement</a></li><li><a href="#methods">Method(s)</a><ul><li><a href="#detailed-design">Detailed Design</a><ul><li><a href="#ambit-and-or">Ambit-AND-OR</a></li><li><a href="#tra%E8%83%BD%E5%A4%9F%E5%B7%A5%E4%BD%9C%E9%9C%80%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98">TRA能够工作需要解决的问题</a></li><li><a href="#%E8%A7%A3%E5%86%B335%E7%9A%84ambit-and-or-flow">解决3~5的Ambit-AND-OR Flow</a></li><li><a href="#ambit-not">Ambit-NOT</a></li></ul></li><li><a href="#ambit-putting-it--all-together">Ambit: Putting it  all together</a><ul><li><a href="#row-address-grouping">Row address grouping</a></li><li><a href="#executing-bitwise-ops-the-aap-primitive">Executing Bitwise Ops: The AAP Primitive</a></li><li><a href="#accelerating-aap-with-a-split-row-decoder">Accelerating AAP with a Split Row Decoder</a></li><li><a href="#integrating-ambit-with-the-system">Integrating Ambit with the System</a></li></ul></li></ul></li><li><a href="#evaluation">Evaluation</a></li><li><a href="#conclusion">Conclusion</a><ul><li><a href="#circuit-level-spice-simulation">Circuit-level SPICE Simulation</a></li><li><a href="#analysis-of-throughput--energy">Analysis of Throughput &amp; Energy</a></li><li><a href="#effect-on-real-world-application">Effect on Real-World Application</a></li></ul></li><li><a href="#notes">Notes</a><ul><li><a href="#bulk-bitwise-operations%E7%9A%84%E5%8A%A0%E9%80%9F%E5%9C%BA%E6%99%AF%E5%8F%8A%E6%84%8F%E4%B9%89">Bulk bitwise operations的加速场景及意义</a></li><li><a href="#interleaved-memory-system-%E4%BA%A4%E9%94%99%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F">Interleaved Memory System (交错存储系统)</a></li></ul></li></ul><!-- /TOC --><p>HPCA-2020</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><!-- 写完笔记之后最后填，概述文章的内容，以后查阅笔记的时候先看这一段。 --><p>这篇文章介绍了一种存内计算的方法Ambit，可以在DRAM中实现整行的AND/OR/NOT逻辑操作，将源数据复制到预留的操作数行，不破坏原始数据，同时降低操作数译码电路的复杂度。</p><h2 id="Research-Objective"><a href="#Research-Objective" class="headerlink" title="Research Objective"></a>Research Objective</h2><!-- 作者的研究目标 --><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><!-- 问题陈述，要解决什么问题？ --><p>In existing architectures, the throughput of bulk bitwise operations is limited by the memory bandwidth available to the processing unit (e.g., CPU, GPU, FPGA, processing-in-memory).</p><h2 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a>Method(s)</h2><!-- 解决问题的方法/算法是什么？ --><p>Ambit利用DRAM技术的模拟操作完全在DRAM内部执行按位运算，从而充分利用了内部DRAM的全部带宽。<br>With modest changes to the DRAM design, Ambit can exploit:</p><ul><li>the maximum internal bandwidth available inside each DRAM array;</li><li>the memory-level parallelism across multiple DRAM arrays.</li></ul><h3 id="Detailed-Design"><a href="#Detailed-Design" class="headerlink" title="Detailed Design"></a>Detailed Design</h3><h4 id="Ambit-AND-OR"><a href="#Ambit-AND-OR" class="headerlink" title="Ambit-AND-OR"></a>Ambit-AND-OR</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-11-44-34.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="TRA"></p><p>TRA (triple-row activation) 同时将一个读出放大器与同一位线上的三个DRAM单元相连，假设这三个单元的电容相同，都为$C_c$，bitline的寄生电容为$C_b$，基于电荷共享原则，在电荷共享结束之后，bitline上的电压偏差为：<br>$$\delta = \frac{k\cdot C_c \cdot V_{DD} + C_b \cdot \frac{1}{2} \cdot V_{DD}}{3C_c + C_b} - \frac{1}{2}V_{DD} = \frac{(2k-3)C_c}{6C_c + 2C_b}V_{DD}$$<br>从上面的公式可以看出，如果$k = 2, 3$，则bitline deviation为正，如果$k = 0, 1$，则bitline deviation为负。<br>分别使用A, B, C表示三个cell的逻辑值，则最终的输出可以表示为$C(A+B) + \overline{C}(AB)$，由此我们可以得到：通过控制C的逻辑值，我们可以使用TRA实现逻辑AND和OR。</p><h4 id="TRA能够工作需要解决的问题"><a href="#TRA能够工作需要解决的问题" class="headerlink" title="TRA能够工作需要解决的问题"></a>TRA能够工作需要解决的问题</h4><ol><li>当同时激活三个单元时，位线上的偏差可能小于仅激活一个单元时的偏差。 这可能会延长感测放大的时间或更糟，感测放大器可能会检测到错误的值。</li><li>由于工艺的变化，所有电容相等的假设在实际设计中是不正确的。这会影响TRA的可靠性，从而影响其结果的正确性。</li><li>TRA会改写三个cell的原始数据。</li><li>电容可能会没有充电到满电荷，或者由于漏电会导致电荷随时间减少，如果漏电明显会影响运算结果。</li><li>同时激活DRAM子阵列中的三个任意行需要内存控制器和行解码器同时通信和解码三个行地址。这将在地址总线和行解码器上引入大量成本。</li></ol><h4 id="解决3-5的Ambit-AND-OR-Flow"><a href="#解决3-5的Ambit-AND-OR-Flow" class="headerlink" title="解决3~5的Ambit-AND-OR Flow"></a>解决3~5的Ambit-AND-OR Flow</h4><p>Ambit reserves a set of designed rows in each subarray thar are used to perform TRAs. These designated rows are chosen statically at design time.</p><ol><li>Copy data of row A to designated row T0</li><li>Copy data of row B to designated row T1</li><li>Initialize designated row T2 to 0</li><li>Activate designated rows T0, T1, and T2 simultaneously</li><li>Copy data of row T0 to row R</li></ol><h4 id="Ambit-NOT"><a href="#Ambit-NOT" class="headerlink" title="Ambit-NOT"></a>Ambit-NOT</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-46-47.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Ambit-NOT"></p><p>$\overline{\text{bitline}}$上的电压表示cell逻辑值的NOT逻辑，因此Ambit-NOT的方法是将$\overline{\text{bitline}}$上的数值连接到$bitline$，从而实现NOT逻辑，如上图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-52-29.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Bitwise NOT using a dual-contact cell"></p><ol><li>Activate the source row A;</li><li>Activate n-wordline of DCC (address B5);</li><li>Precharge the bank;</li><li>Copy data from d-wordline of DCC to row R (RowClone).</li></ol><h3 id="Ambit-Putting-it-all-together"><a href="#Ambit-Putting-it-all-together" class="headerlink" title="Ambit: Putting it  all together"></a>Ambit: Putting it  all together</h3><h4 id="Row-address-grouping"><a href="#Row-address-grouping" class="headerlink" title="Row address grouping"></a>Row address grouping</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-58-18.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Row address grouping"></p><p>Ambit将每个subarray中的行地址分为三类：</p><ul><li><strong>B</strong>itwise group</li><li><strong>C</strong>ontrol group</li><li><strong>D</strong>ata group</li></ul><p>Bitwise group的地址译码如下表所示：</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-16-07-51.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Mappping of B-group address"></p><h4 id="Executing-Bitwise-Ops-The-AAP-Primitive"><a href="#Executing-Bitwise-Ops-The-AAP-Primitive" class="headerlink" title="Executing Bitwise Ops: The AAP Primitive"></a>Executing Bitwise Ops: The AAP Primitive</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-16-29-14.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Command sequences for different bitwise operations"></p><p>从上图可以看出逻辑操作基本上可以使用AAP操作和AP操作来实现。</p><h4 id="Accelerating-AAP-with-a-Split-Row-Decoder"><a href="#Accelerating-AAP-with-a-Split-Row-Decoder" class="headerlink" title="Accelerating AAP with a Split Row Decoder"></a>Accelerating AAP with a Split Row Decoder</h4><h4 id="Integrating-Ambit-with-the-System"><a href="#Integrating-Ambit-with-the-System" class="headerlink" title="Integrating Ambit with the System"></a>Integrating Ambit with the System</h4><ol><li><p>ISA Support<br>$$bbop dst, src1, [src2], size$$</p></li><li><p>Ambit API/Driver Support</p><ul><li>an API that enables applications to specify bitvectors that are likely to be involved in bitwise operations;</li><li>a driver that is aware of the internal mapping of DRAM rows to subarrays and maps the bitvectors involved in bulk bitwise operations to the same DRAM array.</li></ul></li><li><p>Implementing the $bbop$ Instruction<br> 微架构需要检查：1)Ambit操作的源/目的地址是否行对齐；2)操作的长度是否是DRAM行长度的整数倍。如果检查通过，则CPU将操作发送到memory controller，否则CPU执行该操作。</p></li><li><p>Maintaining On-chip Cache Coherence</p><ul><li>flush any dirty cache lines from the source rows;</li><li>invalidate any cache lines from the source rows;<blockquote><p>Note: The above mechanism is already required by DMA. As Ambit operations are always row-wide, we can use structures like the Dirty-Block Index to speed up flushing dirty data.</p></blockquote></li></ul></li><li><p>Error Correction and Data Scrambling<br>暂时不深入这一块</p></li></ol><h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><!-- 作者如何评估自己的方法，有没有问题或者可以借鉴的地方 --><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-29-22.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><!-- 作者给了哪些strong conclusion, 又给了哪些weak conclusion? --><h3 id="Circuit-level-SPICE-Simulation"><a href="#Circuit-level-SPICE-Simulation" class="headerlink" title="Circuit-level SPICE Simulation"></a>Circuit-level SPICE Simulation</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-21-41.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Effect of process variation on TRA"></p><p><strong>Simulation tools:</strong><br>    HSPICE with the sense amplifier using 55nm DDR3 model parameters.<br><strong>Conclusion:</strong></p><ul><li>up to $\pm5%$ variation, there are zero errors in TRA.</li><li>even with $\pm10%$ and $\pm15%$ variation, the percentage of erroneous TRAs across 100,000 iterations each is just 0.29% and 6.01%.</li></ul><h3 id="Analysis-of-Throughput-amp-Energy"><a href="#Analysis-of-Throughput-amp-Energy" class="headerlink" title="Analysis of Throughput &amp; Energy"></a>Analysis of Throughput &amp; Energy</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-32-10.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Through of bbop"></p><p> Ambit (with 8 DRAM banks) outperform Skylake by 44.9%, GTX745 by 32.0x, and HMC 2.0 by 2.4X.</p><p> <img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-39-42.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Energy of bbop"></p><p><strong>Conclusion:</strong> Ambit reduces energy consumption by 25.1X-59.5X compared to copying data with the memory controller using the DDR3 interface.</p><h3 id="Effect-on-Real-World-Application"><a href="#Effect-on-Real-World-Application" class="headerlink" title="Effect on Real-World Application"></a>Effect on Real-World Application</h3><p><strong>Tools:</strong> GEM5<br><strong>Benchmark:</strong><br>    - a database bitmap index<br>    - BitWeaving, a mechanism to accelerate database column scan operations<br>    - a bitvector-based implementation of the widely-used set data structure</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-53-03.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Bitmap index performance"></p><p><strong>Conclusion:</strong> Ambit significantly reduces the query execution time compared to the baseline by 6X on average.</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-54-54.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Speedup offered by Ambit for BitWeaving"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-58-20.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Performance of set operations"></p><p><font color="blue" size="5">现有基于忆阻器的PIM能够加速的一大原因在于神经网络计算的高并行度，但是一旦并行度不高，这些慢的访存速度将强烈限制PIM的性能，因此在比cache访存速度慢的memory中实现非规则计算加速是不现实的，物理特性和容量升高都会导致访存变慢。但是有可能实现低功耗PIM。</font></p><h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><!-- 在这些框架外额外需要记录的笔记。 --><h3 id="Bulk-bitwise-operations的加速场景及意义"><a href="#Bulk-bitwise-operations的加速场景及意义" class="headerlink" title="Bulk bitwise operations的加速场景及意义"></a>Bulk bitwise operations的加速场景及意义</h3><p>In fact, many real-world databases support bitmap indice. A recent work, WideTable, designs an entire database around a technique called BitWeaving, which accelerates scans completely using bulk bitwise operations. Microsoft recently open-sourced a technology called BitFunnel that accelerates the document filtering portion of web search. BitFunnel relies on fast bulk bitwise AND operations. Bulk bitwise operations are also prevalent in DNA sequence alignment, encrayption algorithms, graph processing, and networking. Thus, accelerating bulk bitwise operations can significantly boost the performance of various applications.</p><h3 id="Interleaved-Memory-System-交错存储系统"><a href="#Interleaved-Memory-System-交错存储系统" class="headerlink" title="Interleaved Memory System (交错存储系统)"></a>Interleaved Memory System (交错存储系统)</h3><blockquote><p>参考链接：<a href="https://blog.csdn.net/wbcuc/article/details/8183369">https://blog.csdn.net/wbcuc/article/details/8183369</a></p></blockquote><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-47-52.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Non-interleaved Memory Organization"></p><p>非交错存储系统如上图所示，单个bank内地址连续，因此访问连续内存需要串行访问，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-51-32.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Non-interleaved Burst Access Timing"></p><p>不难看出上面这种方式的访问延时比较高，为了降低访存的延时，交错存储系统将地址连续的分布在bank之间，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-53-18.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Interleaved Memory Organization"></p><p>因此bank0和bank1的可以并行访问，从而将地址0和1并行读出，降低了访存的延时，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-55-01.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Intereaved Burst Access Timing"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Compute Caches</title>
      <link href="/2021/08/26/compute-caches/"/>
      <url>/2021/08/26/compute-caches/</url>
      
        <content type="html"><![CDATA[<h1 id="Compute-Caches"><a href="#Compute-Caches" class="headerlink" title="Compute Caches"></a>Compute Caches</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>转-四种基本的编程命名规范</title>
      <link href="/2021/08/13/zhuan-si-chong-ji-ben-de-bian-cheng-ming-ming-gui-fan/"/>
      <url>/2021/08/13/zhuan-si-chong-ji-ben-de-bian-cheng-ming-ming-gui-fan/</url>
      
        <content type="html"><![CDATA[<h1 id="转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）"><a href="#转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）" class="headerlink" title="转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）"></a>转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）</h1><h2 id="匈牙利命名法"><a href="#匈牙利命名法" class="headerlink" title="匈牙利命名法"></a>匈牙利命名法</h2><p>匈牙利命名法是早期的规范，由微软的一个匈牙利人发明的，是IDE还十分智障的年代的产物。那个年代，当代码量很多的时候，想要确定一个变量的类型是很麻烦的，不像现在IDE都会给提示，所以才产生了这样一个命名规范，估计现在已经没啥人用了吧……一个十分系统却又琐碎的命名规范。</p><p>该命名规范，要求前缀字母用变量类型的缩写，其余部分用变量的英文或英文的缩写，单词第一个字母大写。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int iMyAge;        #  &quot;i&quot;: int</span><br><span class="line">char cMyName[10];  #  &quot;c&quot;: char</span><br><span class="line">float fManHeight;  #  &quot;f&quot;: float</span><br></pre></td></tr></table></figure><p>其他前缀类型还有：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">a      数组（Array）</span><br><span class="line">b      布尔值（Boolean）</span><br><span class="line">by     字节（Byte）</span><br><span class="line">c      有符号字符（Char）</span><br><span class="line">cb     无符号字符（Char Byte，并没有神马人用的）</span><br><span class="line">cr     颜色参考值（Color Ref）</span><br><span class="line">cx,cy  坐标差（长度 Short Int）</span><br><span class="line">dw     双字（Double Word）</span><br><span class="line">fn     函数（Function）</span><br><span class="line">h      Handle（句柄）</span><br><span class="line">i      整形（Int）</span><br><span class="line">l      长整型（Long Int）</span><br><span class="line">lp     长指针（Long Pointer）</span><br><span class="line">m_     类成员（Class Member）</span><br><span class="line">n      短整型（Short Int）</span><br><span class="line">np     近程指针（Near Pointer）</span><br><span class="line">p      指针（Pointer）</span><br><span class="line">s      字符串（String）</span><br><span class="line">sz     以 Null 做结尾的字符串型（String with Zero End）</span><br><span class="line">w      字（Word）</span><br></pre></td></tr></table></figure><p>还有其他更多的前缀是根据微软自己的MFC/句柄/控件/结构等东西定义的，就不过多描述了。</p><h2 id="驼峰式命名法"><a href="#驼峰式命名法" class="headerlink" title="驼峰式命名法"></a>驼峰式命名法</h2><p>驼峰式命名法，又叫小驼峰式命名法（所以自然就存在大驼峰命名法啦……)。</p><p>该命名规范，要求第一个单词首字母小写，后面其他单词首字母大写，简单粗暴易学易用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int myAge;</span><br><span class="line">char myName[10];</span><br><span class="line">float manHeight;</span><br></pre></td></tr></table></figure><h2 id="帕斯卡命名法"><a href="#帕斯卡命名法" class="headerlink" title="帕斯卡命名法"></a>帕斯卡命名法</h2><p>帕斯卡命名法，又叫大驼峰式命名法。</p><p>与小驼峰式命名法的最大区别在于，每个单词的第一个字母都要大写。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int MyAge;</span><br><span class="line">char MyName[10];</span><br><span class="line">float ManHeight;</span><br></pre></td></tr></table></figure><h2 id="下划线命名法"><a href="#下划线命名法" class="headerlink" title="下划线命名法"></a>下划线命名法</h2><p>下划线命名法并不如大小驼峰式命名法那么备受推崇，但是也是浓墨重彩的一笔。尤其在宏定义和常量中使用比较多，通过下划线来分割全部都是大写的单词。</p><p>该命名规范，也是很简单，要求单词与单词之间通过下划线连接即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int my_age;</span><br><span class="line">char my_name[10];</span><br><span class="line">float man_height;</span><br></pre></td></tr></table></figure><h2 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h2><p>随着技术的发展，命名规范也在不断的细化，一种命名规范早已无法系统的满足各方需求（匈牙利命名法除外，但是已经基本淘汰了），不同的语言不同 IDE 推崇的规范也有所不同，无法评判哪一种最好，但是可以肯定的是，集后三种命名规范大成者，一定是受众最广的。</p><p>例如，谷歌 C++ 编程规范，从项目的命名到文件的命名，再到类和变量以及宏定义的命名都做到了细致入微，充分的结合了下划线命名法与驼峰式命名法（早先推崇的小驼峰，不过今年好像改成大驼峰了），又加入了一些新的元素，十分的系统完善。</p><p>当然，命名规范并不代表着编程规范，仅仅是编程规范的一部分而已，除去命名规范，还有很多编程上的细节是必须关注的，例如，等号两边留空格还是等号对齐？空行神马时候神马地方留更加符合代码结构？空格神马时候神马地方留更加美观？花括号是否对齐？</p><p>诸如此类，还有很多，无法一下子全部掌握并应用，但是在编程经验增加的过程中，一定也要不断的留意，自己所在的公司部门使用的是神马样的规范，没错，并不提倡大家练就自己的规范，一定要去融入工作环境的需求。</p><p>每次去新的工作环境，第一个要看的文档不是别的，一定是编程规范，如果没有这个东西，那么就努力去推一个统一的规范，推不动的话，那可以换工作了，否则日后将会带来无尽的麻烦。</p><p>本文转载自：<a href="https://zhuanlan.zhihu.com/p/89909623">https://zhuanlan.zhihu.com/p/89909623</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2021/08/07/hello-world/"/>
      <url>/2021/08/07/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>A 28 nm Configurable Memory (TCAM/BCAM/SRAM) Using Push-Rule 6T Bit Cell Enabling Logic-in-Memory</title>
      <link href="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/"/>
      <url>/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/</url>
      
        <content type="html"><![CDATA[<p>今天在阅读“CAPE: A Content-Addressable Processing Engine”这篇论文时，论文中引用的一篇仅使用6T SRAM实现CAM的工作引起了我的兴趣。</p><p>由于可以对存储的所有entry进行并行数据搜索/匹配的优良特性，CAM是高关联性缓存、TLB和寄存器重命名电路中不可或缺的部分。LUT也是IP路由器表的主要功能，如Fig. 1所示，因此CAM是许多路由器芯片的主要组成部分。<br><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-222208.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><!-- ![](202184-222208.jpg) --><p>但是传统的CAM存在一个严重的问题就是资源开销很大，无法高密度集成，比如一个BCAM需要10个晶体管，一个TCAM需要16个晶体管，如Fig. 2所示。<br><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-222641.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>因此本文能够使用6T SRAM紧凑的单元实现CAM的方案就显得非常有意义。同时，该论文在保留SRAM存储功能的基础上还实现了TCAM以及一些基础的逻辑操作（AND和NOR）。该论文不仅提出了实现方案，还通过一些精巧的设计保证了该设计的高性能，而且分析的面面俱到，是一个相当优秀的工作。</p><p>在此也先简单总结一下该设计的最终性能：基于6T 28nm FDSOI SRAM工艺，实现了$64\times 64 (4kb)$ BCAM，在1V工作电压下，BCAM的工作频率为370 MHz，能效为$0.5\ fJ/search/bit$，两个64-bit words的逻辑操作的频率达到787 MHz。</p><p>接下来开始介绍该工作的细节，受限简单介绍一下传统CAM搜索的原理。如Fig. 3所示，存储单元中的比特与输入的比特进行XNOR操作，然后同一根match line上的所有同或结果进行线与逻辑，最终通过SA输出匹配结果。在很多查找应用中，可能需要匹配多个结果，如果只需要单个地址，也可以对结果进行优先编码。<font color="blue">这里对搜索的结果进行优先编码也可能对今后的研究有一些启示，很多时候想用到优先编码，但是还没有遇到合适的场合。</font></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-224025.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>接下来看这篇论文提出的6T BCAM设计，如Fig. 4所示。该设计使用标准SRAM中的位线 作为match lines，使用WL表示搜索序列按列进行搜索匹配。而传统的SRAM存储功能仍然保持，可以动态配置成BCAM/TCAM/Logic/SRAM storage。为此，需要对电路进行一些特殊设计，以兼容多种模式，这些在本文中也一一进行了详细的介绍，之后我也会对一些关键的考虑进行简单的介绍。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-224830.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>从Fig. 4中，我们可以看到为了兼容CAM的功能，作者在传统的6T SRAM基础上进行了些微的改动，那就是将WL变为两根，WLR和WLL，分别对与BL和BLB相连的晶体管进行门控（这在Fig. 5中可以看得更加清楚）。文中对这一设计的代价总结为:</p><blockquote><p>“This creates two indeppendent access transistors but incur no area penalty since the push-rule layers are kept intact (i.e., only DRC-compliant metallization changes are made).”</p></blockquote><p><font color="blue">在这里重点指出这一点的原因在于：之前我在和其他人讨论类似的设计的时候，我想通过一根WL改进设计，大家觉得增加这一根线会对面积开销产生很大的影响，这与这边作者的观点相左，暂时看不懂这里为什么面积不会有很大的影响，今后的研究中可能会借鉴这个观点。</font></p><p>废话说完，开始真正介绍三种工作模式：</p><p><strong>1. BCAM</strong></p><p>Fig. 5展示的是该设计实现BCAM搜索的过程，Search string从WLR/WLL输入，当输入为1时，WLR=1，WLL=0，表明BL对应的门控晶体管开启，BLB对应的门控晶体管截止。如果对应的SRAM cell存的值为1，则BL对应的门控晶体管D/S端都为高电平，结果是BL和BLB的最终电位都为高，而如果存储的值为0，则BL预充的高电平会通过SRAM cell放电，从而将BL上电位下拉到0，BLB上电位仍然保持高电平。当输入为0时，工作情况类似，只是BLB对应的门控晶体管开启。因此同一条BL对应的SRAM cell只要有任意一比特无法跟search string bit匹配，BL或BLB会被下拉到低电平，最终与门输出为0，否则输出为1，表示完全匹配。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-230549.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Note:</p><ul><li>基于SRAM的CAM相对于忆阻器的CAM还有一个有点就是搜索的字长可以做到特别长，因为SRAM的off state可以做到几乎不漏电。</li><li>针对SRAM的读操作和BCAM的操作，SA的工作机制是不同的，该设计提出了一种SA，可以在不增加面积的基础上，实现可重构的两种功能的SA，如Fig. 6所示。<br><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-05002.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></li><li>SRAM是逐行写，CAM是对所有列进行匹配，数据需要逐列写。这要是在我看来就是不可能的，这个方案就放弃了，但是作者可能巧妙地解决了这一问题，不仅是磕盐的态度，对于行和列都要写的方案在今后的设计中也可以参考，毕竟有时候经常需要行/列都进行操作，比如矩阵的转置等等，比如从一个bank中逐行读出，逐列写入另一个bank。之前陈怡然也有一篇工作涉及到行列操作的CAM，也可以一起总结一下。这个按列去写刚好受益于有两根WL，这跟BL是等价的。逐行写数据从BL输入，逐列写数据从WL输入。</li><li>该工作还考虑了同时开启多行对SRAM cell中数据的破坏进行了分析，并提出了解决方案。</li></ul><p><strong>2. TCAM</strong></p><p>TCAM的工作原理如Fig. 13所示，由于TCAM中存在三种状态”1”, “0”, “X”，所以需要使用两比特来实现，相邻的两列表示一比特，其中存储”00”表示“0”，存储“11”表示“1”，存储“01”表示“X”，当存储的值为“01”是，左列的BLB对应的SRAM cell输出为“1”，右列的BL对应的SRAM输出也为“1”，因此无论输入是“0”还是“1”，都不会将BL或BLB下拉到低电平。<font color="blue">在其他文章中，认为该设计在实现TCAM时，只需要将WLR和WLL都设置为GND，这样使用BCAM同样的电路就可以实现TCAM的功能。而在本文中，作者自己竟然用了两倍的面积来实现TCAM的功能。不仔细看还会以为本文作者犯了一个错误，其实并不是这样子的。这是如何定义TCAM的一个问题。如果对于输入的某些bit进行mask的话，这样输入的这些bit与所有搜索项目的对应bit都不会去比较，个人感觉这种是比较常用的，但是对于优先编码等应用场合，这种就不适用了，需要将对应的某一搜索项的某些bit进行mask，这样就需要用到本文中所提出的方案，也没有去查TCAM的具体定义，可能这中才是真正的TCAM（杨老师Nature Electronics论文中也是实现的这种方式），以后研究过程中可以用这个电路。</font></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202193-12929.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><strong>3. Logic Operations</strong></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-15755.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该设计实现“AND”逻辑如Fig. 15所示，逻辑操作与存储相同，是以行为单位进行的。要对某两行进行逻辑操作，将对应的WL输入设置为“1”（即WLR=VDD, WLL=GND)，其他行WLL=WLR=GND进行MASK。开启的两行中对应的2个SRAM cell中只要有一个cell存储的值为0，就会将BL下拉到低电平，即实现了“AND”操作。“NOR”操作方式与“AND”类似，TABLE I总结了这两种操作的配置。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20434.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该设计的整体架构如Fig. 16所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20452.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>最后，放置一些实验结果，以对该设计的性能有一个更加深入的了解。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20730.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20753.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20813.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20832.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20851.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 挖坑待填 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决gem5运行时缺少pydot的问题</title>
      <link href="/2021/08/03/jie-jue-gem5-yun-xing-shi-que-shao-pydot-de-wen-ti/"/>
      <url>/2021/08/03/jie-jue-gem5-yun-xing-shi-que-shao-pydot-de-wen-ti/</url>
      
        <content type="html"><![CDATA[<h1 id="解决gem5运行时缺少pydot的问题"><a href="#解决gem5运行时缺少pydot的问题" class="headerlink" title="解决gem5运行时缺少pydot的问题"></a>解决gem5运行时缺少pydot的问题</h1><p>在运行gem5时，会显示：</p><blockquote><p>warn: No dot file generated. Please install pydot to generate the dot file and pdf.</p></blockquote><p>作为一个高度强迫症患者，实在无法忍受每次运行出现这个刺眼的warning，而且在进行系统仿真的时候，产生的config.dot.svg和config.dot.pdf等文件还可以可视化整个系统的架构，为此记录一下我解决这个问题的方法。</p><p>在网上搜索博客，基本上都是如下的<a href="https://blog.csdn.net/mjl960108/article/details/79981794">解决方案</a>：</p><blockquote><p>sudo apt install python-pydot python-pydot-ng graphviz</p></blockquote><p>但是运行时会事与愿违：</p><blockquote><p>root@9187b8755600:~/gem5/m5out# apt install python-pydot python-pydot-ng graphviz<br>Reading package lists… Done<br>Building dependency tree<br>Reading state information… Done<br>E: Unable to locate package python-pydot<br>E: Unable to locate package python-pydot-ng</p></blockquote><p>找不到安装包，也有博客指出需要使用pip命令安装，但是ubuntu自带的python无法找到pip命令，而也最好不要使用conda的虚拟python环境，因为无法定位到虚拟环境中的scons命令，这个我至今也没有解决，而是直接安装docker环境，配置python2.7和python3.8，用于不同版本的gem5，非常方便。</p><p>为此解决系统python环境缺少pydot的方法如下：</p><ol><li>下载<a href="https://pypi.org/project/pydot/#files">pydot源</a><blockquote><p>wget <a href="https://files.pythonhosted.org/packages/13/6e/916cdf94f9b38ae0777b254c75c3bdddee49a54cc4014aac1460a7a172b3/pydot-1.4.2.tar.gz">https://files.pythonhosted.org/packages/13/6e/916cdf94f9b38ae0777b254c75c3bdddee49a54cc4014aac1460a7a172b3/pydot-1.4.2.tar.gz</a></p></blockquote></li><li>解压文件</li><li>安装pydot<blockquote><p>python setup.py install (for python2.7)<br>python3 setup.py install (for python3.8)</p></blockquote></li></ol><p>完美解决！！！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>(转)Types of Memory Interleaving</title>
      <link href="/2021/07/30/zhuan-types-of-memory-interleaving/"/>
      <url>/2021/07/30/zhuan-types-of-memory-interleaving/</url>
      
        <content type="html"><![CDATA[<h1 id="转-Types-of-Memory-Interleaving"><a href="#转-Types-of-Memory-Interleaving" class="headerlink" title="(转)Types of Memory Interleaving"></a>(转)Types of Memory Interleaving</h1><p><a href="https://www.geeksforgeeks.org/memory-interleaving/">Memory Interleaving</a> is an abstraction technique which divides memory into a number of modules such that successive words in the address space are placed in the different module.</p><p>Suppose a 64 MB memory made up of the 4 MB chips as shown in the below:</p><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/1406-4.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>We organize the memory into 4 MB banks, each having eight of the 4 MB chips. The memory thus has 16 banks, each of 4 MB.</p><p>64 MB memory = $2^{26}$, so 26 bits are used for addressing.<br>16 = $2^4$, so 4 bits of address select the bank, and 4 MB = $2^{22}$, so 22 bits of address to each chip.</p><p>In general, an N-bit address, with $N = L + M$, is broken into two parts:</p><ol><li>L-bit bank select, used to activate one of the $2^L$ banks of memory, and</li><li>M-bit address that is sent to each of the memory banks.</li></ol><p>When one of the memory banks is active, the other ($2^L – 1$) are inactive. All banks receive the M-bit address, but the inactive one do not respond to it.</p><p><strong>Classification of Memory Interleaving:</strong><br>Memory interleaving is classified into two types:</p><ol><li><strong>High Order Interleaving –</strong> In high-order interleaving, the most significant bits of the address select the memory chip. The least significant bits are sent as addresses to each chip. One problem is that consecutive addresses tend to be in the same chip. The maximum rate of data transfer is limited by the memory cycle time.</li></ol><p>It is also known as Memory Banking.</p><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/223-1.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ol start="2"><li><strong>Low Order Interleaving –</strong> In low-order interleaving, the least significant bits select the memory bank (module). In this, consecutive memory addresses are in different memory modules. This allows memory access at much faster rates than allowed by the cycle time.</li></ol><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/3164-1.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>注：转载于<a href="https://www.geeksforgeeks.org/types-of-memory-interleaving/">https://www.geeksforgeeks.org/types-of-memory-interleaving/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CACTI 7.0介绍</title>
      <link href="/2021/07/29/cacti-7-0-jie-shao/"/>
      <url>/2021/07/29/cacti-7-0-jie-shao/</url>
      
        <content type="html"><![CDATA[<h1 id="CACTI-7-0介绍"><a href="#CACTI-7-0介绍" class="headerlink" title="CACTI 7.0介绍"></a>CACTI 7.0介绍</h1><h2 id="1-CACTI发展"><a href="#1-CACTI发展" class="headerlink" title="1. CACTI发展"></a>1. CACTI发展</h2><p>CACTI是HP公司推出的一款开源开源工具，广泛应用于对cache/DRAM的延时，功耗，cycle time[^1]和面积的评估。</p><p>[^1]: <font color="gray">(暂时不知道如何翻译比较好，感觉前面的延时指的是各个部分的延时信息，这边的cycle time应该指的是访问周期)</font></p><p>CACTI最初由Dr. Jouppi和Dr. Wilton于1993年开发，此后经历了六次版本的迭代。</p><h2 id="2-CACTI支持的特性"><a href="#2-CACTI支持的特性" class="headerlink" title="2. CACTI支持的特性"></a>2. CACTI支持的特性</h2><ul><li>以下memory的功耗、延时、cycle time的建模<ul><li>direct mapped caches</li><li>set-associative caches</li><li>fully associative caches</li><li>Embedded DRAM memories</li><li>Commodity DRAM memories</li></ul></li><li>多端口UCA(uniform cache access)，多端口的NUCA(non-uniform cache access)的建模</li><li>工作温度对泄露功耗的影响</li><li>路由功耗模型</li><li>具有不同延迟、功耗和面积属性的互连模型，包括低摆幅线模型</li><li>用于执行功率、延迟、面积和带宽之间权衡分析的接口</li><li>该工具使用的所有工艺特定值均从 ITRS 获得，目前该工具支持 90nm、65nm、45nm 和 32nm 技术节点</li><li>用于计算DDR总线延迟和能量的芯片IO模型。用户可以模拟不同的负载（扇出）并评估对频率和能量的影响。该模型可用于研究LR-DIMM、R-DIMM等。</li><li>Version 7.0在6.5版本的基础之上还融合了CACTI 3D</li></ul><h2 id="3-CACTI的使用方法"><a href="#3-CACTI的使用方法" class="headerlink" title="3. CACTI的使用方法"></a>3. CACTI的使用方法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/HewlettPackard/cacti</span><br><span class="line"><span class="built_in">cd</span> cacti</span><br><span class="line"><span class="comment"># modify the xxx.cfg for self configuration</span></span><br><span class="line">make</span><br><span class="line">./cacti -infile xxx.cfg</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows使用sftp获取服务器运行记录</title>
      <link href="/2021/07/25/windows-shi-yong-sftp-huo-qu-fu-wu-qi-yun-xing-ji-lu/"/>
      <url>/2021/07/25/windows-shi-yong-sftp-huo-qu-fu-wu-qi-yun-xing-ji-lu/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>函数的副作用</title>
      <link href="/2021/07/25/han-shu-de-fu-zuo-yong/"/>
      <url>/2021/07/25/han-shu-de-fu-zuo-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="转-函数的副作用"><a href="#转-函数的副作用" class="headerlink" title="(转)函数的副作用"></a>(转)函数的副作用</h1><p><strong>函数的副作用</strong>指当调用函数时，除了返回函数值之外，还对主调用函数产生附加的影响。例如修改全局变量（函数外的变量）或修改参数。</p><p>函数副作用会给程序设计带来不必要的麻烦，给程序带来十分难以查找的错误，并且降低程序的可读性。严格的函数式语言要求函数必须无副作用。</p><p>函数的副作用相关的几个概念， Pure Function、 Impure Function、 Referential Transparent。</p><ul><li><p><strong>纯函数 (Pure Function)</strong><br>输入输出数据流全是显式（Explicit）的。 显式（Explicit）的意思是，函数与外界交换数据只有一个唯一渠道——参数和返回值。函数从函数外部接受的所有输入信息都通过参数传递到该函数内部。函数输出到函数外部的所有信息都通过返回值传递到该函数外部。</p></li><li><p><strong>非纯函数 (Impure Function)</strong></p><p>与之相反。 隐式（Implicit）的意思是，函数通过参数和返回值以外的渠道，和外界进行数据交换。比如读取/修改全局变量，都叫作以隐式的方式和外界进行数据交换。</p></li><li><p><strong>引用透明 (Referential Transparent)</strong></p><p>引用透明的概念与函数的副作用相关，且受其影响。 如果程序中两个相同值得表达式能在该程序的任何地方互相替换，而不影响程序的动作，那么该程序就具有引用透明性。它的优点是比非引用透明的语言的语义更容易理解，不那么晦涩。纯函数式语言没有变量，所以它们都具有引用透明性。</p></li></ul><p>以下示例说明了引用透明与函数副作用的结合</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result1 = (fun(a) + b) / (fun(a) - c);</span><br><span class="line">temp = func(a);</span><br><span class="line">result2 = (temp + b) / (temp - c);</span><br></pre></td></tr></table></figure><p>如果函数没有副作用，那么result1和result2将是等价的。然而如果fun有副作用，比如让b或c加1，那么result1和result2将不相等。因此，副作用违背了引用透明性。</p><p>在JavaScript中，引入了函数。但显然JS中的函数可以访问、修改全局变量（或定义在函数外的变量），如下</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">5</span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fun</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">a = <span class="number">10</span>;</span><br><span class="line">&#125;</span><br><span class="line">fun();<span class="comment">// a变成了10</span></span><br></pre></td></tr></table></figure><p>JS中要想保证函数无副作用这项特性，只能依靠编程人员的习惯，即</p><ol><li><p>函数入口使用参数运算，而不修改它</p></li><li><p>函数内不修改函数外的变量，如全局变量</p></li><li><p>运算结果通过函数返回给外部（出口）</p></li></ol><blockquote><p>转载自：<a href="https://www.cnblogs.com/snandy/archive/2011/08/14/2137898.html">https://www.cnblogs.com/snandy/archive/2011/08/14/2137898.html</a></p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>(转)多核处理器的九大关键技术</title>
      <link href="/2021/07/23/zhuan-duo-he-chu-li-qi-de-jiu-da-guan-jian-ji-zhu/"/>
      <url>/2021/07/23/zhuan-duo-he-chu-li-qi-de-jiu-da-guan-jian-ji-zhu/</url>
      
        <content type="html"><![CDATA[<h1 id="转-多核处理器的九大关键技术"><a href="#转-多核处理器的九大关键技术" class="headerlink" title="(转)多核处理器的九大关键技术"></a>(转)多核处理器的九大关键技术</h1><p>与单核处理器相比，多核处理器在体系结构、软件、功耗和安全性设计等方面面临着巨大的挑战，但也蕴含着巨大的潜能。</p><p>CMP和SMT一样，致力于发掘计算的粗粒度并行性。CMP可以看做是随着大规模集成电路技术的发展，在芯片容量足够大时，就可以将大规模并行处理机结构中的SMP（对称多处理机）或DSM（分布共享处理机）节点集成到同一芯片内，各个处理器并行执行不同的线程或进程。在基于SMP结构的单芯片多处理机中，处理器之间通过片外Cache或者是片外的共享存储器来进行通信。而基于DSM结构的单芯片多处理器中，处理器间通过连接分布式存储器的片内高速交叉开关网络进行通信。由于SMP和DSM已经是非常成熟的技术了，CMP结构设计比较容易，只是后端设计和芯片制造工艺的要求较高而已。正因为这样，CMP成为了最先被应用于商用CPU的“未来”高性能处理器结构。</p><p>虽然多核能利用集成度提高带来的诸多好处，让芯片的性能成倍地增加，但很明显的是原来系统级的一些问题便引入到了处理器内部。</p><ol><li><p>核结构研究: 同构还是异构</p><p>CMP的构成分成同构和异构两类，同构是指内部核的结构是相同的，而异构是指内部的核结构是不同的。为此，面对不同的应用研究核结构的实现对未来微处理器的性能至关重要。核本身的结构，关系到整个芯片的面积、功耗和性能。怎样继承和发展传统处理器的成果，直接影响多核的性能和实现周期。同时，根据Amdahl定理，程序的加速比决定于串行部分的性能，所以，从理论上来看似乎异构微处理器的结构具有更好的性能。</p><p>核所用的指令系统对系统的实现也是很重要的，采用多核之间采用相同的指令系统还是不同的指令系统，能否运行操作系统等，也将是研究的内容之一。</p></li><li><p>程序执行模型</p><p>多核处理器设计的首要问题是选择程序执行模型。程序执行模型的适用性决定多核处理器能否以最低的代价提供最高的性能。程序执行模型是编译器设计人员与系统实现人员之间的接口。编译器设计人员决定如何将一种高级语言程序按一种程序执行模型转换成一种目标机器语言程序; 系统实现人员则决定该程序执行模型在具体目标机器上的有效实现。当目标机器是多核体系结构时，产生的问题是: 多核体系结构如何支持重要的程序执行模型？是否有其他的程序执行模型更适于多核的体系结构？这些程序执行模型能多大程度上满足应用的需要并为用户所接受？</p></li><li><p>Cache设计: 多级Cache设计与一致性问题</p><p>处理器和主存间的速度差距对CMP来说是个突出的矛盾，因此必须使用多级Cache来缓解。目前有共享一级Cache的CMP、共享二级Cache的CMP以及共享主存的CMP。通常，CMP采用共享二级Cache的CMP结构，即每个处理器核心拥有私有的一级Cache，且所有处理器核心共享二级Cache。</p><p>Cache自身的体系结构设计也直接关系到系统整体性能。但是在CMP结构中，共享Cache或独有Cache孰优孰劣、需不需要在一块芯片上建立多级Cache，以及建立几级Cache等等，由于对整个芯片的尺寸、功耗、布局、性能以及运行效率等都有很大的影响，因而这些都是需要认真研究和探讨的问题。</p><p>另一方面，多级Cache又引发一致性问题。采用何种Cache一致性模型和机制都将对CMP整体性能产生重要影响。在传统多处理器系统结构中广泛采用的Cache一致性模型有: 顺序一致性模型、弱一致性模型、释放一致性模型等。与之相关的Cache一致性机制主要有总线的侦听协议和基于目录的目录协议。目前的CMP系统大多采用基于总线的侦听协议。</p></li><li><p>核间通信技术</p><p>CMP处理器的各CPU核心执行的程序之间有时需要进行数据共享与同步，因此其硬件结构必须支持核间通信。高效的通信机制是CMP处理器高性能的重要保障，目前比较主流的片上高效通信机制有两种，一种是基于总线共享的Cache结构，一种是基于片上的互连结构。</p><p>总线共享Cache结构是指每个CPU内核拥有共享的二级或三级Cache，用于保存比较常用的数据，并通过连接核心的总线进行通信。这种系统的优点是结构简单，通信速度高，缺点是基于总线的结构可扩展性较差。</p><p>基于片上互连的结构是指每个CPU核心具有独立的处理单元和Cache，各个CPU核心通过交叉开关或片上网络等方式连接在一起。各个CPU核心间通过消息通信。这种结构的优点是可扩展性好，数据带宽有保证; 缺点是硬件结构复杂，且软件改动较大。</p><p>也许这两者的竞争结果不是互相取代而是互相合作，例如在全局范围采用片上网络而局部采用总线方式，来达到性能与复杂性的平衡。</p></li><li><p>总线设计</p><p>传统微处理器中，Cache不命中或访存事件都会对CPU的执行效率产生负面影响，而总线接口单元（BIU）的工作效率会决定此影响的程度。当多个CPU核心同时要求访问内存或多个CPU核心内私有Cache同时出现Cache不命中事件时，BIU对这多个访问请求的仲裁机制以及对外存储访问的转换机制的效率决定了CMP系统的整体性能。因此寻找高效的多端口总线接口单元（BIU）结构，将多核心对主存的单字访问转为更为高效的猝发（burst）访问; 同时寻找对CMP处理器整体效率最佳的一次Burst访问字的数量模型以及高效多端口BIU访问的仲裁机制将是CMP处理器研究的重要内容。</p></li><li><p>操作系统设计: 任务调度、中断处理、同步互斥</p><p>对于多核CPU，优化操作系统任务调度算法是保证效率的关键。一般任务调度算法有全局队列调度和局部队列调度。前者是指操作系统维护一个全局的任务等待队列，当系统中有一个CPU核心空闲时，操作系统就从全局任务等待队列中选取就绪任务开始在此核心上执行。这种方法的优点是CPU核心利用率较高。后者是指操作系统为每个CPU内核维护一个局部的任务等待队列，当系统中有一个CPU内核空闲时，便从该核心的任务等待队列中选取恰当的任务执行，这种方法的优点是任务基本上无需在多个CPU核心间切换，有利于提高CPU核心局部Cache命中率。目前多数多核CPU操作系统采用的是基于全局队列的任务调度算法。</p><p>多核的中断处理和单核有很大不同。多核的各处理器之间需要通过中断方式进行通信，所以多个处理器之间的本地中断控制器和负责仲裁各核之间中断分配的全局中断控制器也需要封装在芯片内部。</p><p>另外,多核CPU是一个多任务系统。由于不同任务会竞争共享资源，因此需要系统提供同步与互斥机制。而传统的用于单核的解决机制并不能满足多核，需要利用硬件提供的“读－修改－写”的原子操作或其他同步互斥机制来保证。</p></li><li><p>低功耗设计</p><p>半导体工艺的迅速发展使微处理器的集成度越来越高，同时处理器表面温度也变得越来越高并呈指数级增长，每三年处理器的功耗密度就能翻一番。目前，低功耗和热优化设计已经成为微处理器研究中的核心问题。CMP的多核心结构决定了其相关的功耗研究是一个至关重要的课题。</p><p>低功耗设计是一个多层次问题，需要同时在操作系统级、算法级、结构级、电路级等多个层次上进行研究。每个层次的低功耗设计方法实现的效果不同——抽象层次越高，功耗和温度降低的效果越明显。</p></li><li><p>存储器墙</p><p>为了使芯片内核充分地工作，最起码的要求是芯片能提供与芯片性能相匹配的存储器带宽，虽然内部Cache的容量能解决一些问题，但随着性能的进一步提高，必须有其他一些手段来提高存储器接口的带宽，如增加单个管脚带宽的DDR、DDR2、QDR、XDR等。同样，系统也必须有能提供高带宽的存储器。所以，芯片对封装的要求也越来越高，虽然封装的管脚数每年以20%的数目提升，但还不能完全解决问题，而且还带来了成本提高的问题，为此，怎样提供一个高带宽，低延迟的接口带宽，是必须解决的一个重要问题。</p></li><li><p>可靠性及安全性设计</p><p> 随着技术革新的发展，处理器的应用渗透到现代社会的各个层面，但是在安全性方面却存在着很大的隐患。一方面，处理器结构自身的可靠性低下，由于超微细化与时钟设计的高速化、低电源电压化，设计上的安全系数越来越难以保证，故障的发生率逐渐走高。另一方面，来自第三方的恶意攻击越来越多，手段越来越先进，已成为具有普遍性的社会问题。现在，可靠性与安全性的提高在计算机体系结构研究领域备受注目。</p></li></ol><p>转载于:<a href="http://blog.itpub.net/312079/viewspace-245322/">http://blog.itpub.net/312079/viewspace-245322/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux Tools Mannual</title>
      <link href="/2021/07/22/linux-tools-mannual/"/>
      <url>/2021/07/22/linux-tools-mannual/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux-常用工具使用命令速查表"><a href="#Linux-常用工具使用命令速查表" class="headerlink" title="Linux 常用工具使用命令速查表"></a>Linux 常用工具使用命令速查表</h1><h2 id="tmux"><a href="#tmux" class="headerlink" title="tmux"></a>tmux</h2><h3 id="tmu常用操作指令及快捷键"><a href="#tmu常用操作指令及快捷键" class="headerlink" title="tmu常用操作指令及快捷键"></a>tmu常用操作指令及快捷键</h3><ol><li>查看有所有tmux会话<br>指令：tmux ls<br>快捷键：Ctrl+b s</li><li>新建tmux窗口<br>指令：tmux new -s <session-name></session-name></li><li>重命名会话<br>指令：tmux rename-session -t <old-name> <new-name><br>快捷键：Ctrl+b $</new-name></old-name></li><li>分离会话<br>指令：tmux detach/exit(关闭窗口，杀死会话)<br>快捷键：Ctrl+b d</li><li>平铺当前窗口<br>快捷键：Ctrl+b z(再次Ctrl+b d恢复)</li><li>杀死会话<br>指令：tmux kill-session -t <session-name></session-name></li><li>切换会话<br>指令：tmux switch -t <session-name></session-name></li><li>划分上下两个窗格<br>指令：tmux split<br>快捷键：Ctrl+b “</li><li>划分左右两个窗格<br>指令：tmux split -h<br>快捷键：Ctrl+b %</li><li>光标切换到上方窗格<br>指令：tmux select-pane -U<br>快捷键：Ctrl+b 方向键上</li><li>光标切换到下方窗格<br>指令：tmux select-pane -D<br>快捷键：Ctrl+b 方向键下</li><li>光标切换到左边窗格<br>指令：tmux select-pane -L<br>快捷键：Ctrl+b 方向键左</li><li>光标钱换到右边窗格<br>指令：tmux select-pane -R<br>快捷键：Ctrl+b 方向键右</li></ol><p><a href="https://zhuanlan.zhihu.com/p/90464490">https://zhuanlan.zhihu.com/p/90464490</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
