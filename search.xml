<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>X-SRAM: Enabling In-Memory Boolean Computations in CMOS Static Random Access Memories</title>
      <link href="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/"/>
      <url>/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/</url>
      
        <content type="html"><![CDATA[<h1 id="X-SRAM-Enabling-In-Memory-Boolean-Computations-in-CMOS-Static-Random-Access-Memories"><a href="#X-SRAM-Enabling-In-Memory-Boolean-Computations-in-CMOS-Static-Random-Access-Memories" class="headerlink" title="X-SRAM: Enabling In-Memory Boolean Computations in CMOS Static Random Access Memories"></a>X-SRAM: Enabling In-Memory Boolean Computations in CMOS Static Random Access Memories</h1><h2 id="X-SRAM支持的操作"><a href="#X-SRAM支持的操作" class="headerlink" title="X-SRAM支持的操作"></a>X-SRAM支持的操作</h2><h3 id="NOR"><a href="#NOR" class="headerlink" title="NOR"></a>NOR</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-133447.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>8T SRAM的单元结构如图3(a)所示，在传统6T SRAM上增加了M1和M2形成单独的read通路。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin</title>
      <link href="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/"/>
      <url>/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/</url>
      
        <content type="html"><![CDATA[<h1 id="A-4-2T-SRAM-for-Searching-and-In-Memory-Computing-With-0-3-V-VDDmin"><a href="#A-4-2T-SRAM-for-Searching-and-In-Memory-Computing-With-0-3-V-VDDmin" class="headerlink" title="A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin"></a>A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin</h1><!-- TOC --><ul><li><a href="#a-4--2t-sram-for-searching-and-in-memory-computing-with-03-v-vddmin">A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin</a><ul><li><a href="#%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D">背景介绍</a></li><li><a href="#%E7%8E%B0%E6%9C%89%E5%B7%A5%E4%BD%9C%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98">现有工作存在的问题</a></li><li><a href="#%E6%9C%AC%E6%96%87%E7%9A%84%E7%9B%AE%E6%A0%87">本文的目标</a></li><li><a href="#%E6%9C%AC%E6%96%87%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82">本文工作细节</a><ul><li><a href="#4--2t-sram-cell-%E7%BB%93%E6%9E%84">4 + 2T SRAM Cell 结构</a></li><li><a href="#sram%E6%94%AF%E6%8C%81%E7%9A%84%E6%93%8D%E4%BD%9C%E6%A8%A1%E5%BC%8F">SRAM支持的操作模式</a></li></ul></li><li><a href="#%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C">测试结果</a></li><li><a href="#%E6%80%BB%E7%BB%93">总结</a></li></ul></li></ul><!-- /TOC --><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-14056.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>传统的冯诺依曼 (CVN) 架构在memory bank和计算元素之间持续传输数据，会产生大量的能源和延迟成本，这些成本可能会影响系统功率和性能，如图1所示。为了最小化能耗和延迟，最近提出了IMC(In-Memory Computing)。IMC同时激活多行，直接在BL上进行逻辑操作。IMC不仅减少了数据移动以及操作的延迟，而且受益于memory bank的高带宽，有可能实现高并行计算。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-14602.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>如图2所示，基于6T SRAM的IMC相比于传统冯诺依曼（CVN）显示出比较大的能效和速度优势。</p><h2 id="现有工作存在的问题"><a href="#现有工作存在的问题" class="headerlink" title="现有工作存在的问题"></a>现有工作存在的问题</h2><p>但是SRAM-based IMC仍存在一下问题：</p><ul><li>当多行同时激活时，传统的6T SRAM的读取噪声容限会降低。因此需要WL欠驱动来改善噪声容限，这会大幅度降低读取速度。此外，由于读取噪声容限下降，$VDD_{min}$被限制在大约0.7V。因此整体功耗很高。（memory access和leakage仍然主导IMC的系统能耗，如图2b所示。）</li><li>8T SRAM通过隔离SRAM的读取路径和编程路径，能够有效的提高读取的噪声容限，但是面积开销会增加30%。同时由于只有一根BL用于读取，8T SRAM只能实现AND逻辑。</li><li>10T SRAM能够克服8T SRAM的不足，但是会带来更大的面积开销。</li></ul><h2 id="本文的目标"><a href="#本文的目标" class="headerlink" title="本文的目标"></a>本文的目标</h2><p>因此，本文的目标是：<font color="blue">提出4 + 2T SRAM单元的方案，能够实现比传统6T SRAM更好的读取噪声容限，同时带来较小的面积开销，以及以较小的能耗支持更多的计算。</font></p><h2 id="本文工作细节"><a href="#本文工作细节" class="headerlink" title="本文工作细节"></a>本文工作细节</h2><h3 id="4-2T-SRAM-Cell-结构"><a href="#4-2T-SRAM-Cell-结构" class="headerlink" title="4 + 2T SRAM Cell 结构"></a>4 + 2T SRAM Cell 结构</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-15742.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该论文提出的4 + 2T SRAM结构如图3(a)所示。该SRAM中PU是使用DNW制作的深耗尽PMOS，能够通过体偏效应控制PMOS的阈值电压，从而不需要PG，只需要四个管子即可进行SRAM的编程。同时，读取BL也通过栅控晶体管与SRAM cell进行隔离，cell的电位能够通过栅控晶体管控制BL的放电与否，但是BL上的电压无法反向传播改写SRAM的值，因此可以同时打开多行SRAM进行计算。此外，互补的RBL和RBLB可以实现更多的逻辑操作。</p><h3 id="SRAM支持的操作模式"><a href="#SRAM支持的操作模式" class="headerlink" title="SRAM支持的操作模式"></a>SRAM支持的操作模式</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-21449.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>4 + 2T SRAM支持的所有操作以及各端口电压配置如表1所示。</p><ol><li><p>Write</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-21738.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图5展示了对2x2 SRAM阵列进行写操作。在Standby模式下，WBL和WBLB都处于高电平$VDD_H$，其中$VDD_H$高于$VDD$。对SRAM单元进行写操作时，以写”0”为例，先将WBL拉低至GND，此时节点n1从$VDD$降低至$V_{thp}$。然后拉低WWL，以降低PU的阈值电压，n1对应的PU导通，将n1拉低到0，同时n2对应的PU开启，PD关断，n2被上拉到1，WBL/WBLB上的输入会被写入SRAM单元中。</p></li><li><p>Read</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-24145.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>正常读操作如图9(a)所示，读操作时，某一行对应的RWL/RWLB被拉低到GND以激活读操作，SRAM cell保存的值决定两个栅控晶体管的开关，从而导致RBL或RBLB连通到RWL或RWLB放电，通过两个差分SA可以检测出RBL和RBLB上的电压。这边存在两点考虑：(1) 使用差分SA代替单端反相器，以提高感测速度；(2) 如果未选择行保存的值为1，则会导致RWL向RBL漏电，RBL无法下拉到GND，因此使用差分交叉耦合SA，能够检测RBL上很小的电压下降。</p></li><li><p>In-Memory-Logic operations</p><p>如图9(b)所示，该电路支持AND, NOR和XOR逻辑操作，所有的逻辑操作都在一个周期内完成。</p></li><li><p>BCAM</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-24717.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>BCAM操作如图11(a)所示，此时RBL和RBLB复用为SL和SLB，作为搜索的输入。RWL复用为ML。如果搜索的属于与该行保存的数据完全匹配，则不存在任何的ML不存在任何的放电通路。否则，SL或SLB将ML拉低，行方向的SA用于BCAM的检测。<br>该方案于传统的6T SRAM-based BCAM的优势在于：(1) 搜索仍是按行进行，因此保存的数据不需要转置（按列保存）；(2) 多行同时激活，数据不会被改写。图12展示的是一个BCAM搜索的例子。<br><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-25515.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p></li><li><p>TCAM</p><p>TCAM操作原理如图11(b)所示，操作于BCAM类似，区别在于使用2个cell保存三种状态。图13展示的是一个TCAM搜索的例子。<br><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-25525.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p></li></ol><h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95055.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95240.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95317.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图16显示了测量单元的write margin，绿色区域表明超过5$\sigma$的write margin，其中标注的balanced green region至少存在200mV margin。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95331.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图17显示：</p><ul><li>0.8V VDD下，写频率达到600MHz；</li><li>最小供电电压为VDD/VDDH=0.25/0.30V；</li><li>最优的写能效为4.02 fJ/bit，对应VDD=0.35V.</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95920.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图18是在1-bit mismatch下测量，结果表明：</p><ul><li>BCAM操作的$VDD_{min}=0.35V$，此时对应最优的BCAM搜索能效0.13 fJ/bit。</li><li>TCAM和TCAM实现的频率相同，在VDD=0.8V时达到225MHz。</li><li>TCAM的搜索能耗是BCAM的2倍。</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-100412.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图19表明：</p><ul><li>read $VDD_{min}=0.25V$;</li><li>logic operation $VDD_{min}=0.35V$（emploing single-port sensing and half-strength SA）;</li><li>最优读能效为3.96 fJ/bit，对应VDD=0.35V；</li><li>最优逻辑操作能效为6.57 fJ/bit，对应VDD=0.35V；</li><li>最高读频率350 MHz;</li><li>最高逻辑操作频率270 MHz。</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-100427.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>与近存计算相比，总延迟降低35%，总能耗降低25%。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-103838.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>实现最低的访问能耗和比较好的$VDD_{min}$</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-103854.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>我们以最小的面积开销实现了可比的$VDD_{min}$和最低的读取能量。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-103908.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>4 + 2T SRAM方案：</p><ul><li>相比于8T SRAM方案，面积节省15%。</li><li>差分解耦读取路径可实现可靠的多字同时激活以执行布尔逻辑功能。</li><li>与近内存计算相比，IMC 分别节省了 35% 和 25% 的延迟和能源。</li><li>BCAM 在 0.35 V 下达到 0.13 fJ/search/bit。</li><li>工艺角仿真实现0.3V读/写$VDD_{min}$。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Survey of SRAM-based Processing-in-Memory Techniques and Applications</title>
      <link href="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/"/>
      <url>/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/</url>
      
        <content type="html"><![CDATA[<h1 id="A-Survey-of-SRAM-based-Processing-in-Memory-Techniques-and-Applications"><a href="#A-Survey-of-SRAM-based-Processing-in-Memory-Techniques-and-Applications" class="headerlink" title="A Survey of SRAM-based Processing-in-Memory Techniques and Applications"></a>A Survey of SRAM-based Processing-in-Memory Techniques and Applications</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>随着冯诺依曼计算架构越来越受到数据移动开销的限制，研究人员开始探索内存处理(PIM)技术来抵消数据移动开销。由于SRAM的广泛使用，用于SRAM的PIM技术有望加速广泛的计算系统和应用程序。在本文中，我们对使用SRAM存储器进行内存处理的技术进行了调查。我们回顾了使用SRAM-PIM来实现布尔运算、搜索和算术运算，以及用于机器学习（尤其是神经网络）和自动机计算的加速器。本文旨在通过向算法和硬件架构领域的研究人员介绍基于SRAM的PIM技术的最新发展来加速协同设计工作。</p><h2 id="索引词"><a href="#索引词" class="headerlink" title="索引词"></a>索引词</h2><p>Review, deep neural networks, SRAM, cache, computing in memory, neural network, automata computing</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>数据传输产生的能量比算术运算高一百多倍。因此，传统的“冯诺依曼式”以计算为中心的处理器受到数据移动开销的严重限制。“内存处理”（PIM）是一种避免数据移动惩罚的有前途的方法。由于SRAM是一种商业成熟的技术，并且已经可用于各种规模和形状的计算系统，因此SRAM-PIM方法可以对计算行业的格局产生革命性的影响。</p><p>要了解SRAM-PIM的潜力，以具有多级缓存的CPU为例。在缓存子系统中，数据移动以两种方式发生。首先，数据传输发生在缓存级别之间。例如，数据从LLC移至L1，然后移至寄存器，最后移至功能单元。启用PIM的LLC可以避免这些开销。此外，共享LLC可以降低两个内核之间共享数据的开销，因为可以避免通过共享LLC在不同内核的私有L1缓存之间传输块。其次，由于H树互连上的数据传输和控制结构，缓存内部会产生延迟。在4GHz频率下，SRAM访问和LLC访问延迟分别为1个周期和30个周期。由于PIM方案仅访问SRAM阵列，因此它们产生的延迟可以忽略不计。</p><p>SRAM-PIM可以极大地有益于数据密集型应用，例如神经网络和模式匹配。例如，神经网络训练在大型数据集上运行，推理涉及对不同层的权重的计算。完全在SRAM中执行布尔运算和算术运算可以提高它们的效率。类似地，基因组学和自然语言处理中的许多模式匹配应用程序执行有限自动机式处理。在模式匹配应用中使用SRAM-PIM时，自动机状态转换完全发生在存储器内部。这避免了在基于CPU的处理中产生的分支错误预测和不规则内存访问的开销。此外，使用具有高扇入和扇出的互连可以将输入序列与许多候选序列相匹配。因此，SRAM-PIM可以提供大量的并行性。同样，在内存中执行搜索和比较操作可以提升压缩、编码和搜索引擎的性能。基于PIM的逻辑操作可以加速加密、图形索引和数据库应用程序。</p><p>然而，SRAM-PIM的使用也带来了许多挑战。在6T SRAM中，PIM的使用会导致严重的可靠性问题，例如读取干扰和读取噪声容限下降。虽然使用8T或10T单元减轻了这些限制，但它们也会导致更高的面积开销。此外，为大规模DNN设计加速器会带来诸如大列电流等挑战，这会导致供电问题和传感故障。最后，模拟域操作需要消耗大量面积和能量的ADC/DAC。显然，实现SRAM-PIM的全部潜力需要新颖和智能的技术。</p><p>在本文中，我们对基于SRAM的PIM技术进行了调研。图1显示了该论文的概述。第2节提供了动机和分类。第3节介绍了基于SRAM-PIM的逻辑、搜索和算术运算的实现。第4节展示了使用SRAM-PIM来加速神经网络应用。第5节展示了它在加速机器学习、自动机处理和偏微分方程求解方面的用途。第6节总结了论文，并简要提及了未来的研究挑战。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-112116.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>本文中经常使用以下缩写词：位线（BL）、位线条（BLB）、二元/-卷积/深度神经网络（BNN/CNN/DNN）、反向传播（BWP）、二元/三元内容可寻址存储器 (BCAM/TCAM)、缓存自动化 (CA)、卷积 (CONV)、数模转换器 (DAC)、双端口互锁存储单元 (DPDICE)、确定性下推自动机 (DPDA)、特征图 (fmap)、完全连接（FC）、指令集架构（ISA）、反相器（INV）、最近邻（kNN）、末级缓存（LLC）、查找表（LUT）、本地位线（LBL）、乘法和累加（MAC）、单片 3 维 (M3D)、矩阵向量乘法 (MVM)、非确定性有限自动机 (NFA)、感测放大器 (SA)、单指令多线程/数据 (SIMT/SIMD)、源代码行 (SL)、“连续-近似寄存器-模数转换器”（SAR-ADC）、支持向量机（SVM）、硅通孔（TSV）、“超大指令字”（VLIW）、字线(WL)、写 WL (WWL)、xnor 和累加 (XAC)</p><h2 id="动机和概述"><a href="#动机和概述" class="headerlink" title="动机和概述"></a>动机和概述</h2><p>在本节中，我们首先讨论实现基于SRAM的PIM（第2.1节）的挑战。为了正确看待事情，我们将SRAM-PIM方法与DRAM和RRAM中的PIM方法进行比较（第2.2节）。然后，我们提供了基于几个类别的研究工作分类（第2.3节）。</p><h3 id="基于SRAM的PIM的挑战"><a href="#基于SRAM的PIM的挑战" class="headerlink" title="基于SRAM的PIM的挑战"></a>基于SRAM的PIM的挑战</h3><ul><li><strong>SRAM密度低:</strong> SRAM具有低密度和高泄漏能量。因此，SRAM-PIM更适合小规模数据集。</li><li><strong>6T SRAM的局限性:</strong> 使用6T SRAM更适合设计最后一级缓存，因为它们已针对该区域进行了优化。在6T SRAM中，激活多行会降低读取噪声容限。它可以创建短路路径，可以随机翻转单元状态。此外，在BL放电后，由于6T SRAM的读写路径是共享的，因此激活下一个WL会导致伪写操作。<br>为避免数据损坏，可以调整WL电压。这严重限制了操作频率，例如Jeloka等人在1V下使用800 MHz频率，Wang等人在1.1V时使用475 MHz频率。此外，由于工作裕度小，Vdd不能低于0.7V。这导致高动态和泄漏能量消耗。为了提高噪声容限，需要进行WL欠驱动，这会增加读取延迟。作为避免6T SRAM数据损坏问题的另一种解决方案，可以使用脉宽调制WL。该解决方案避免了同时激活两个WL，但将外围电路的面积增加了2倍以上。<font color="blue">这边可以加上BLADE的local bitline</font></li><li><strong>8T/10T SRAM的局限性：</strong> 为了克服6T SRAM的限制，可以使用8T或10Tbitcell。8T SRAM将读和写路径解耦，这允许独立优化它们的读/写操作。这提高了裕度并允许降低最小Vdd，这降低了功耗。然而，与6T SRAM相比，8T SRAM会导致30%的面积损失。此外，由于8T SRAM使用单个读取BL，因此它仅计算AND运算。需要特殊的架构来支持其他逻辑功能。10T SRAM克服了这个问题，但会导致更高的面积损失。</li><li><strong>模拟域的限制：</strong> 模拟域操作更容易受到工艺变化、噪声、非线性I-V特性和老化的影响。此外，使用ADC/DAC会降低信号精度并造成能量/面积损失。</li><li><strong>映射大型DNN的挑战：</strong> 大规模DNN具有数千个量级的权重矩阵。然而，由于以下原因，无法在SRAM中实现如此大的矩阵：(1) 多个WL的激活需要高列电流。这会导致大量的瞬时功率，从而产生热和功率传输问题。(2) 工艺变化会使SA产生偏移。随着列电流的上升，感测失败的可能性更高。(3) 长导线具有高阻容(RC)延迟。这些挑战可以通过对SRAM阵列进行分区来缓解，该阵列将大矩阵拆分为多个较小的矩阵。但是，如果使用二元神经元累积来自不同子阵列的部分和，则此方法可能会影响分类精度。</li></ul><h3 id="在不同内存中处理内存中-近内存方法"><a href="#在不同内存中处理内存中-近内存方法" class="headerlink" title="在不同内存中处理内存中/近内存方法"></a>在不同内存中处理内存中/近内存方法</h3><p>比较不同内存技术中的 PIM 方法是很有见地的。</p><ul><li><strong>DRAM:</strong> 基于DRAM的内存处理提出了至关重要的挑战。(1) 由于DRAM读取是破坏性的，PIM计算破坏了原始数据。为了避免数据丢失，需要复制到别处，这会导致很大的开销。(2) 感测DRAM电容的余量小，导致模拟计算错误。修改单元设计的技术会导致大量的面积损失。(3) 技术差异阻碍了PIM所需的外围逻辑与DRAM的轻松集成。(4) DRAM中使用的数据/地址加扰技术对将其用于PIM操作提出了挑战。基于DRAM的近数据计算技术利用芯片堆叠将逻辑芯片与DRAM芯片集成在一起。然而，这会在制造和操作期间产生问题。</li><li><strong>RRAM:</strong> RRAM的优点是单元面积小。然而，RRAM设备具有非常低的耐用性和较大的写入延迟/能量。因此，频繁的重量更新可能会导致达到耐力极限。此外，基于RRAM的PIM在支持浮点计算方面面临着严峻的挑战。这是因为RRAM单元和ADC的分辨率有限。这需要使用多个单元格来表示浮点值。此外，指数归一化需要多次操作，由于RRAM的高延迟和低写耐久性，这尤其昂贵。事实上，范伯格等人使用128个RRAM单元来存储双精度 (64b) 数，其中64个单元仅用于执行归一化和对齐。相比之下，SRAM-PIM技术完全在SRAM阵列内部执行数字浮点计算。此外，在BWP阶段，使用转置权重矩阵执行CONV。为此，执行逐列读取操作，这会降低吞吐量和能源效率。</li></ul><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p>表 1 根据架构和实验参数对作品进行分类。如表 1 所示，大多数工作仅进行了电路或架构级评估。只有少数作品对从电路到系统的整个堆栈进行了评估。<br>表 2 根据它们的优化策略对作品进行分类。<br>表3根据实验平台和参数对作品进行分类。<br>表 4 根据实验结果对作品进行分类，例如它们的吞吐量和能效值。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114508.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114532.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114715.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114730.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114746.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="基于-SRAM-PIM-的搜索、逻辑和算术运算"><a href="#基于-SRAM-PIM-的搜索、逻辑和算术运算" class="headerlink" title="基于 SRAM-PIM 的搜索、逻辑和算术运算"></a>基于 SRAM-PIM 的搜索、逻辑和算术运算</h2><p>在本节中，我们将讨论基于SRAM-PIM的搜索操作（第3.1节）、逻辑运算（第3.2节）和算术运算（第3.3节）的实现。表5显示了由各种技术执行的基本操作。在BNN中，CONV操作被简单地计算为按位XNOR和population-count操作。因此，基于SRAM-PIM的XNOR实现可以加速BNN。<br>XOR运算可以使用NOR和AND运算来实现，如下所示： A XOR B = (A AND B) OR (A AND B)。大于/小于操作是通过减去操作数并读取MSB来执行的。大多数作品通过使用移位加法来执行乘法。对于有符号数的乘法，乘积的符号位是通过计算操作数的符号位的异或来获得的。</p><h3 id="搜索操作"><a href="#搜索操作" class="headerlink" title="搜索操作"></a>搜索操作</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-161130.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>通常，BCAM使用10T SRAM，TCAM使用16T SRAM。然而，非推规则CAM位单元比推规则6T SRAM大得多，这使得CAM区域非常大。杰洛卡等人提出了一种使用推式6T SRAM位单元设计的CAM电路。它们以列方式存储单词，如图 2(a)所示。它们的电路设计如图 2(b)所示。WL分为WL-right和WL-left，它们创建了两个独立的存取晶体管。搜索查询及其互补分别应用于WL-right和WL-left。如果匹配，BL和BLB都保持在Vdd。在不匹配的情况下，它们中的一个或两个放电。使用两个单端SA分别读取它们。它们之间的AND运算显示列中的匹配项。该过程对所有列并行完成。总体而言，他们的技术将搜索数据与存取晶体管中存储的数据执行XNOR，然后在BL SA上执行AND运算。</p><p>TCAM需要为每个单词使用两列，这将其容量减少了一半。在TCAM中，0和1分别对应组合“00”和“11”，而X对应组合“01”。屏蔽位(X)不会拉低BL或BLB，因为它在两个位置都存储了1。因此，它匹配搜索查询的0和1。要写入CAM，可以在内存模式下以行方式写入数据的转置。但是，这只执行批量写入，不允许写入特定元素。为了允许逐列写入操作，他们提出了一种写入策略，该策略在BCAM的两个周期和TCAM的三个周期内完成。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-161206.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>SRAM可以在三种模式下运行：内存、BCAM或TCAM。在传统存储模式中，字按行存储，地址应用于WL，正在读取的数据在BL上可用。他们提出的存储器可以对以行方式存储的多个字执行AND和NOR运算。例如，要实现与运算，就使用了BCAM模式。在这里，通过向WL-left和WL-right都提供0来屏蔽搜索字符串的输入位（在图 3中显示为M）。使用它，可以激活多行的WL。在图 3中，搜索查询是(1,M,1,M)，它为第1行和第3行启用WL-right。如果第1行或第3行中的任何位为0，则预充电的BL被下拉。此外，所有WL左晶体管都被停用，所有BLB保持高电平。这计算第1行和第3行的按位与。</p><p>为了执行NOR操作，只有WL左存取晶体管被激活，并且在搜索查询中应用0。“01”模式激活A行的WL-left和B行的WL-right。这读取BLB SA上的A和BL SA上的B。这些的AND运算提供了输出。他们的CAM实现了比传统CAM设计高四倍的密度。然而，在CAM模式下，他们的技术以比内存模式低的速度运行。此外，实现可重构功能所需的额外外设会导致较小的面积开销。</p><p>位线计算方法基于以下观察：在同时激活多个（例如，高达64个）WL时，共享BL提供存储在这两个激活行中的数据之间的NOR和AND运算的结果。为了防止由于多行访问而导致数据退化，降低WL电压以偏置SRAM阵列上的写入。通过进一步降低WL电压，可以增强鲁棒性，但也会增加延迟。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-161222.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>董等人提出了一种基于“深耗尽沟道”技术的4+2T SRAM单元。它可以执行逻辑操作并充当BCAM/TCAM。单元设计如图 4(a)所示。它具有解耦读写路径。该单元有6个晶体管，其中4个晶体管形成交叉耦合反相器对。这些逆变器具有不同的Vdd端子，用作WBL/WBLB。另外两个晶体管用作允许差分读取的存取晶体管。他们的单元有两个“栅极连接的差分读取端口”。这将存储节点与RWL和RBL/RBLB隔离。这提高了“读取噪声容限”并提高了激活多个字时的电路可靠性。该单元将n阱用作WWL，从而无需写存取晶体管。</p><p>他们使用差分RBL和RBLB来实现PIM操作。PIM操作的工作原理如图 4(b)所示。对于PIM，最初，RBLB和RBL都预充电到Vdd。此后，同时启用两对WL。如果A或B等于1，则RBL放电，因此，RBL计算(A NOR B)。如果A和B都等于1，则RBLB变高，因此，RBLB计算(A AND B)。他们用两个微小的差分SA评估RBLB和RBL。在通过来自Vdd的小电压降低RBL/RBLB时，SA在潜行电流消失之前将RBL/RBLB上的电压与参考电压(Vref)进行比较。由于SA的不同操作，AND/NAND和OR/NOR是同时计算的。两个SA结果之间的NOR门计算A XOR B。</p><p>对于CAM功能，RBL/RBLB提供搜索数据SL/SLB。此外，两个存取晶体管的RWL被分成ML/MLB。对于BCAM，一行的MLB和ML短接为一个ML。如果一行中的整个输入与存储的数据相同，ML保持高电平，否则它会被释放。每个ML都包含一个行级SA，其一端连接到Vref以评估结果。TCAM需要两个单元格。这里，ML[0]和MLB[1]相连，将单元A和B组合为一个TCAM单元。当AB单元格的值分别为00/11/01时，它表示1/0/X。他们的“4+2T单元”具有比6T SRAM更好的噪声容限和比8T SRAM更小的面积。此外，BCAM可以在0.3V的最小Vdd下运行。他们设计的局限性在于它依赖于一个不常见的4T位单元，该位单元面临不稳定和读取干扰问题。此外，它具有较差的性能/电压缩放（0.6V 时为 100Mhz）。</p><h3 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h3><h4 id="使用-2D-SRAM-对两个操作数的操作"><a href="#使用-2D-SRAM-对两个操作数的操作" class="headerlink" title="使用 2D SRAM 对两个操作数的操作"></a>使用 2D SRAM 对两个操作数的操作</h4><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-162315.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>阿加等人通过修改Jeloka等人提出的位线计算电路，提出了一种in-SRAM计算技术。他们添加了一个解码器来缓存子数组，这会激活两个WL，每个操作数一个。差分SA被重新配置以获得两个单端SA。它们用于分别感测绑定到位单元的两个BL。它们通过对BL和BLB进行NOR运算来扩展用于实现XOR运算的电路。为了比较两个字，他们使用有线NOR组合按位异或结果。搜索是通过与存储在子数组中的缓存块重复比较来执行的。为了将一个WL复制到另一个WL，SA的输出被反馈到BL。由于最后一个读取值要在下一个周期写入，因此“读写操作”合并以有效复制数据，如图5（a）所示。为了清零缓存块，在写操作之前，输入数据锁存器被复位。为了实现“无进位乘法”，首先将两个子阵列行进行“与”运算。然后，使用“XOR减少树”减少结果位。</p><p>PIM操作需要“操作数局部性”，即操作数必须映射到共享相同BL的子数组。他们将“块分区”定义为共享相同BL的子阵列中缓存块的集合。块分区中保存的任何两个缓存块之间都可以进行就地计算。考虑图 5(b)，它显示了一个带有四个子阵列的组。这里，子阵列中的每一行都有两个缓存块，因此每个子阵列都有两个块分区。就地计算可以发生在映射到相同“块分区”的块之间，例如，集合S1和S3中的块。如图 5(b)所示，他们的技术将集合的所有方式映射到相同的“块分区”，无论缓存块的存储方式如何，它都保留了操作数的局部性。此外，如图 5(c)所示，一些设置索引位（称为OLbits）用于决定块的存储体和分区。如果两个操作数的这些位相同，则将它们映射到同一分区。将集合的所有方式映射到同一分区的局限性在于它禁止并行标记数据访问。这种优化一般用在L1缓存中，以牺牲能量开销为代价来提高速度。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Chronos: Efcient Speculative Parallelism for Accelerators</title>
      <link href="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/"/>
      <url>/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/</url>
      
        <content type="html"><![CDATA[<p>ASPLOS-2020<br>Author: Maleen Abeydeera, Daniel Sanchez<br>Affiliations: MIT</p><!-- TOC --><ul><li><a href="#motivation">Motivation</a></li><li><a href="#target">Target</a></li><li><a href="#introduction">Introduction</a><ul><li><a href="#%E5%85%88%E5%89%8D%E5%8A%A0%E9%80%9F%E5%99%A8%E4%B8%AD%E7%9A%84%E5%B9%B6%E8%A1%8C%E7%B1%BB%E5%9E%8B">先前加速器中的并行类型</a></li><li><a href="#%E5%85%88%E5%89%8D%E7%9A%84%E6%8E%A8%E6%B5%8B%E6%9E%B6%E6%9E%84%E4%BE%9D%E8%B5%96%E4%BA%8E%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7">先前的推测架构依赖于缓存一致性</a></li><li><a href="#%E6%8A%95%E6%9C%BA%E6%89%A7%E8%A1%8C%E7%9A%84%E5%8E%9F%E5%9B%A0">投机执行的原因</a></li></ul></li><li><a href="#slot%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B">SLOT执行模型</a><ul><li><a href="#slot">SLOT</a></li><li><a href="#%E5%B0%86%E5%A4%9A%E5%AF%B9%E8%B1%A1%E8%AE%A1%E7%AE%97%E6%98%A0%E5%B0%84%E5%88%B0slot">将多对象计算映射到SLOT</a></li><li><a href="#discussion">Discussion</a></li></ul></li><li><a href="#chronos%E7%B3%BB%E7%BB%9F">Chronos系统</a><ul><li><a href="#%E8%AE%BE%E8%AE%A1%E8%A6%81%E6%B1%82%E5%92%8C%E6%8A%80%E6%9C%AF">设计要求和技术</a></li><li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%89%E5%BA%8F%E6%8E%A8%E6%B5%8B">分布式有序推测</a></li><li><a href="#%E4%BB%BB%E5%8A%A1%E5%8D%95%E5%85%83%E8%AE%BE%E8%AE%A1">任务单元设计</a><ul><li><a href="#%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97">任务队列</a></li><li><a href="#%E6%8F%90%E4%BA%A4%E9%98%9F%E5%88%97">提交队列</a></li></ul></li></ul></li></ul><!-- /TOC --><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>先前的加速器专注于易于利用并行性的领域，例如深度学习，并依赖于传统的并行化技术，如数据并行或数据流执行。</p><h2 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h2><p>在本文中，作者专注于为需要推测执行来提取并行性的应用程序构建加速器。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>例如，考虑离散事件模拟(des)，它在模拟数字电路、网络系统和物理过程方面具有广泛的适用性。离散事件模拟由动态创建的任务组成，这些任务可以在同一个模拟对象上运行，并且必须以正确的模拟时间顺序运行。非推测地运行这些任务需要过多的同步并限制并行性。推测性地运行任务更有利可图。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/2021831-215733.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>如Listing 1所示，每个des任务在特定时间处理一个门输入切换。如果此输入切换导致门的输出切换，则任务会在适当的时间将所有连接到该输出的输入的事件排入队列。顺序实现以模拟时间顺序一次处理一个任务，并在优先级队列中维护要处理的任务集。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/2021831-220352.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>以数字电路模拟为例，如Figure 1所示。Figure 1(a) 显示了具有输入波形和传播延迟的电路，Figure 1(b) 显示了在该电路上执行 des 的任务图。任务之间的箭头表示父子依赖关系（例如，任务O1创建任务A4和X6）。x轴显示任务顺序，y轴中任务的位置代表它操作的门。</p><p>在这个des中，我们可以发现一个很重要的现象：只有在同一门上操作的任务才具有数据依赖性；其他（例如，O1 和 N2）可能会在不违反正确性的情况下运行失序。但是任务和依赖项是未知的，因此乱序运行任务并不简单。虽然在des中，每个任务对单个对象（一个门）进行操作，并且这个对象是预先知道的。但这不足以确定哪些任务可以安全运行，因为一个任务可能与另一个在程序顺序中较早出现但尚不存在的任务相关。假设首先执行任务O1，产生任务X6。此时X6是系统中最早对XOR门进行操作的任务。但是执行X6会产生不正确的结果，因为X6必须遵循较早的依赖数据的任务X3，该任务尚不存在（因为N2尚未运行）。</p><h3 id="先前加速器中的并行类型"><a href="#先前加速器中的并行类型" class="headerlink" title="先前加速器中的并行类型"></a>先前加速器中的并行类型</h3><p>本文通过两个因素对并行类型进行分类：（1）任务是预先知道的还是动态创建的？（2）如果任务对共享数据进行操作，它们应该如何同步以应对算法的数据依赖性并产生正确的结果？<br>按此标准可以分为四类：</p><ul><li><strong>Static parallelism:</strong> 如果预先知道任务及其数据依赖性，则调度可以静态完成，不需要或需要非常简单的运行时机制。在对常规数据结构（例如密集矩阵）进行操作时会出现静态并行性。大多数先前的加速器都专注于静态并行性，如通过构建深度流水线和数据并行硬件，例如DaDianNao和Google的TPU。</li><li><strong>Dynamic parallelism with independent tasks:</strong> 某些算法，例如对树或图形进行操作的算法，必须动态创建任务，因为它们需要做更多的工作。在最简单的情况下，任务对不相交的数据进行操作，并且共享数据访问不需要同步。他们采用了由ESL和Cilk开创的fork-join模型。ParallelXL和TAPAS加速器针对这种动态并行性。它们的关键组成部分是对任务创建和负载平衡的硬件支持。</li><li><strong>Non-speculative synchronization of dependent tasks:</strong> 先前的工作已经展示了加速器，其中任务对共享数据进行操作，但大多数同步是通过停止而不是推测来实现的。</li><li><strong>Speculative synchronization of dependent tasks:</strong> 最后，Ma等人在FPGA上为图形分析应用程序构建加速器。它们支持原子任务，每个任务可以访问多个地址，冲突检测是使用全局共享的地址跟踪结构实现的，类似于一致性目录。因此，这种方法类似于基于一致性的冲突检测，并受到额外开销的影响。</li></ul><h3 id="先前的推测架构依赖于缓存一致性"><a href="#先前的推测架构依赖于缓存一致性" class="headerlink" title="先前的推测架构依赖于缓存一致性"></a>先前的推测架构依赖于缓存一致性</h3><p>先前的推测架构很难应用于加速器，因为它们都依赖于一致的缓存层次结构来执行推测执行，通过一致性协议检测任务之间的冲突。它需要实现一致的缓存和推测跟踪结构，虽然对于通用内核来说开销很小，但对于小型专用内核来说太昂贵了。(虽然依赖一致性对于多核来说是合理的，但对于加速器来说却是昂贵的。 一般的加速器和特别是可重新配置的硬件没有支持基于失效的冲突检测的一致缓存层次结构。实现一致性会增加复杂性、延迟和重要的片上 SRAM 以实现跟踪共享者的目录。除了一致性之外，对具有任意读写集的任务执行冲突检测会增加额外的开销，例如，每个核心价值几千字节的 Bloom 过滤器，这对于专门的处理核心来说太繁重了。)</p><h3 id="投机执行的原因"><a href="#投机执行的原因" class="headerlink" title="投机执行的原因"></a>投机执行的原因</h3><p>通常，当任务具有未知的读写集或任务间顺序约束时，需要进行推测。<br>为了应对这一挑战，在本文中，我们提出了一个硬件系统，该系统在不使用一致性的情况下实现推测执行。 相反，该系统遵循以数据为中心的方法，其中共享数据映射到整个系统； 工作被分成小任务，每个任务最多访问一个共享对象； 并且任务总是被发送到它们的数据被映射的地方运行。 为了强制跨任务组或其他顺序约束的原子性，任务通过时间戳排序（这些是完全与物理时间分离的程序指定的逻辑时间戳）。</p><p>通过SLOT (Spatially Located Ordered Tasks) 执行模型将这些语义形式化。在 SLOT 中，所有工作都通过使用时间戳排序的任务进行。一个任务可以创建在它们之后排序的子任务，并且父任务直接将输入值传递给子任务。==每个任务必须对单个读写对象进行操作，该对象必须在创建任务时声明（除此限制外，任务可以访问任意数量的只读数据）==</p><p>而本文提出的架构就是针对SLOT执行模型的实现，这可以在没有缓存一致性协议的情况下实现完全分布式操作。</p><h2 id="SLOT执行模型"><a href="#SLOT执行模型" class="headerlink" title="SLOT执行模型"></a>SLOT执行模型</h2><p>SLOT 限制每个任务访问单个读写对象，这在创建任务时必须知道。</p><h3 id="SLOT"><a href="#SLOT" class="headerlink" title="SLOT"></a>SLOT</h3><p>SLOT 应用程序由有序的、动态创建的任务组成。 每个任务都可以用软件或硬件来实现。 我们独立于实现来描述执行模型，并使用软件 API 对其进行说明。</p><p>每个任务在创建时都有两个属性：时间戳和对象ID。时间戳指定顺序约束：系统保证任务似乎按时间戳顺序执行。 具有相同时间戳的任务可以以任何顺序运行，但都是原子的（即它们不交错）。<br>对象id是指定任务之间数据依赖性的整数：当且仅当两个任务具有相同的对象id时，它们才被视为数据相关。对象ID限制每个任务最多访问共享内存中的一个读写对象。请注意，此限制仅适用于读写数据。一个任务可以访问任意数量的只读数据。<br>SLOT任务可以通过指定子任务的类型、时间戳、对象ID和它可能需要的任何输入数据值，在发现更多工作时创建子任务。每个子任务可能有任何大于或等于其父任务的时间戳。</p><p>在SLOT中，父子关系是单向的：父任务可以创建值并将值传递给它的子任务，但父任务在子任务之前被排序，因此在子任务执行之前完成。子任务不能返回值或与其父母通信。这与像Cilk这样的fork-join执行模型不同，在这种模型中，父母等待他们的孩子完成。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-10208.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ul><li><strong>API:</strong> Listing 2通过显示des任务的实现来说明SLOT软件API。在软件中，每个任务都由一个函数实现。该实现与Listing 1中的顺序实现几乎相同：每个任务模拟特定门的输入切换。这段代码通过调用slot::enqueue创建新任务，而不是将任务排入优先级队列，它指定了子任务的类型（它的函数指针，因为它是一个软件任务）、时间戳、对象ID和任何附加参数（门在这种情况下输入）。</li><li><strong>SLOT enables coherence-free conﬂict detection:</strong> 通过限制每个任务最多访问一个读写对象，SLOT的实现可以在没有复杂跟踪结构的情况下执行分布式冲突检测。如果实现将对象id映射到核心或区块，并将每个任务发送到其对象id映射的位置，那么查找冲突就成为本地操作。<br>例如，如果Fig. 1在四核系统上运行，NAND、OR、XOR和AND门可以映射到内核1-4。然后，如果任务X3在X6已经运行后到达核心3，核心3可以通过将X3的对象ID与仍然推测的任务的对象ID进行比较，在本地确定X3的冲突（相同门和更高时间戳的任务，在本例中为{X6}）。</li></ul><h3 id="将多对象计算映射到SLOT"><a href="#将多对象计算映射到SLOT" class="headerlink" title="将多对象计算映射到SLOT"></a>将多对象计算映射到SLOT</h3><p>多对象事务也可以表示为SLOT任务，方法是将每个事务分解为多个单对象任务，每个任务访问一个对象，并为每个事务提供不相交的时间戳范围。这样，事务中的任务不会与其他事务中的任务重叠。</p><p>例如，考虑一个银行应用程序，其中交易在帐户之间转移资金。每笔交易都必须自动减少源帐户的余额并增加目标帐户的余额。每个帐户都应该是不同的对象，但由于账户余额是读写数据，单个任务不能访问两个账户。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-11826.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Fig. 3显示了任务顺序如何使这成为可能。我们使用两个SLOT任务实现每笔交易，每个任务操作一个帐户：第一个减少源的余额并创建第二个任务来增加目的地的余额。每个事务都有一个不相交的时间戳范围，因此来自不同事务的任务不会交错。</p><p>这种技术推广到读写操作的任意组合。例如，我们的maxflow实现（第5节）使用它在图顶点的邻域上执行复杂的原子操作。</p><p>虽然将每个事务分解为许多小任务可能会给软件运行时增加大量开销，但小任务是加速器的自然匹配，因为硬件执行任务管理，小任务需要简单的处理元素。</p><h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><ul><li><strong>SLOT细粒度任务的好处:</strong> SLOT与先前工作相比的主要优势是实现无相干冲突检测。此外，先前的工作表明，即使在支持具有任意读/写集的任务的系统中，这种划分通常也是可取的，主要有以下三个原因：</li></ul><ol><li>增加并行性：将长串行事务分解为短任务允许这些任务并行运行。</li><li>减少中止的影响：在误推测时，只有冲突的任务被中止，而不是整个事务。</li><li>增加数据重用：不是在事务运行的系统中共享数据，而是将任务发送到靠近它们的数据运行，避免缓存行乒乓。由于每个任务消息比缓存行小得多，这减少了流量；并且任务是异步发送和执行的，因此它们的延迟比同步内存访问更容易隐藏。</li></ol><ul><li><strong>SLOT的局限:</strong> 虽然将程序分成短的单对象任务通常是有益的，但在一种情况下，基于一致性的冲突检测会优于SLOT：如果应用程序由很少修改的读写数据主导，这些数据具有大量重用，则基于一致性的冲突检测将允许在整个系统中缓存这些数据，在本地的零星写入之间进行读取，而SLOT需要在单独的任务中隔离对这些数据的每次访问，并将它们发送到一个地方。<br>我们在目标应用程序中没有发现这种行为，因此我们没有针对这种情况优化SLOT。SLOT的一个简单扩展可以通过让任务写入其对象ID未涵盖的地址来解决此问题。然后，系统可以将很少修改的数据视为只读数据，并允许将它们私下缓存。在写入时（这种情况很少见），一个简单的实现可以刷新所有缓存并中止所有未来任务；更复杂的实现可能会执行更精确的刷新和冲突检测。我们将对这些实施选择的详细研究留给未来的工作。</li></ul><h2 id="Chronos系统"><a href="#Chronos系统" class="headerlink" title="Chronos系统"></a>Chronos系统</h2><p>Chronos是一个架构框架，可以轻松地为具有有序并行性的应用程序设计加速器。<br>Chronos通过提供有效实现SLOT执行模型的架构模板来实现这一点。然后加速器可以通过定义他们自己的任务处理引擎或配置Chronos的非核心组件来专门化这个模板。通过这种划分，创建Chronos加速器就像指定处理引擎一样简单；该框架负责处理有序任务管理和推测执行的复杂性。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-13713.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Fig. 4显示了Chronos的组织架构。Chronos是一种平铺设计，具有完全分布式的任务管理和推测机制。每个tile都有多个执行任务的处理元素(PE)、一个本地（非一致性）缓存和一个用于排队、分派和提交有序任务的任务单元。</p><p><font color="blue">即使我们无法使用这个架构来完全处理无线项目的通用程序，但是这个架构解决了一类任务，可以放置适量的PE来处理带有这种特性的部分代码。</font></p><h3 id="设计要求和技术"><a href="#设计要求和技术" class="headerlink" title="设计要求和技术"></a>设计要求和技术</h3><ul><li><strong>高吞吐量任务管理:</strong> 短任务对系统提出了高吞吐量要求。例如，如果每个任务需要20个周期来执行，那么具有200个PE的Chronos系统每个周期必须创建、分派、冲突检查和提交10个任务以保持PE忙碌。这迫使设计没有集中组件：所有任务管理和推测机制必须完全分布式。Chronos的平铺设计实现了这一点。此外，每个tile的任务单元也需要保持高吞吐量。</li><li><strong>大投机窗口:</strong> 为了防止顺序限制并行性，系统必须能够在最早的未完成任务之前进行推测。更具体地说，由于顺序限制，任务在提交之前可能会在很长一段时间内处于推测状态——远远超过它们执行所需的时间。因此，系统应该能够跟踪比运行任务更多的推测任务。例如，正如我们将在Sec.6中看到的那样，有些应用程序每个运行任务需要大约10个推测任务</li></ul><p>这些要求强制完全分布式、深度无序执行。</p><h3 id="分布式有序推测"><a href="#分布式有序推测" class="headerlink" title="分布式有序推测"></a>分布式有序推测</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-34155.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Chronos使用推测执行来消除顺序约束。<br>Chronos可以在创建后立即运行任何任务，即使它的祖先仍然是推测性的。图5显示了每个任务的执行流程。顶部水平箭头表示正确的推测。当一个任务被创建时，它被发送到一个tile，它在那里保持空闲，排队直到它准备好分派。tile按时间戳顺序将空闲任务分派给PE。正在运行的任务完成执行后，它会保持推测（处于完成状态），直到系统确定可以安全提交。</p><p>Fig. 5显示任务可以在提交之前的任何时候中止。由于任务可能会在其祖先仍处于推测状态时运行，因此中止任务需要中止并丢弃其所有后代。这些级联中止是发现并行性所必需的，并且是有选择性的：中止会撤消中止任务、其后代以及按程序顺序稍后出现的任何数据相关任务的影响。如图5所示，如果一个任务因为它的父任务被中止而被中止，那么它就被丢弃；否则，中止是由于数据依赖性，然后任务重新排队执行。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-34746.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Fig. 6显示了Chronos中的推测执行示例。<br>任务被创建并无序运行：在Fig. 6a中，任务20已经运行并完成，即使较早的任务仍在运行；特别是任务0，即20的父任务，仍在运行。在Fig. 6b中，任务0创建了一个时间戳为10的子任务，它与任务15发生冲突。这导致任务15及其子任务25被中止。虽然中止可能影响多个任务，但它们是有选择性的：独立任务，例如20不会中止。</p><ul><li><strong>任务映射和冲突检测:</strong> 为了廉价地执行推测执行，Chronos使用了第3节中概述的任务映射和冲突检测策略。Chronos将对象id映射到tile，然后将每个创建的任务发送到映射其对象id的tile。我们当前的Chronos实现使用静态对象到图块映射：对象id被简单地散列以生成图块id。我们发现这在我们的工作负载中实现了良好的负载平衡；Chronos还可以基于tile之间对象的动态重新映射采用更复杂的负载平衡。</li><li><strong>任务调度:</strong> 任务单元按时间戳顺序将任务分派给PE，以优先处理较早的任务。为了避免冲突，任务单元将具有相同对象ID的任务的执行序列化。因此，运行任务之间的冲突永远不会出现；只有无序到达tile的任务才能产生冲突。</li><li><strong>投机价值管理:</strong> Chronos采用Eager版本管理：推测性写入更新内存，旧值写入单独的撤消日志。提交很快，因为撤消日志被简单地丢弃；中止需要从撤消日志中恢复旧值。<br>Eager版本管理有助于运行依赖数据的任务链，而无需等待它们提交：如果任务A写入的值稍后由（相同对象）任务B读取，即使A尚未提交，B也会自然地使用A的值.这个过程被称为推测转发，对于有序推测很重要，但是对于懒惰的版本管理来说很难做到。</li><li><strong>高吞吐量提交:</strong> 为了确定任务何时可以提交，Chronos从之前的工作中借用了全局虚拟时间 (GVT) 协议。Tiles定期（例如，每32个周期）通信以找到最早未完成任务的时间戳，然后提交所有较早的任务。此过程利用大型提交队列一次提交多个任务，以很少的通信实现每个周期多个任务的提交吞吐量。</li></ul><h3 id="任务单元设计"><a href="#任务单元设计" class="headerlink" title="任务单元设计"></a>任务单元设计</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-40232.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Chronos的任务单元由两个主要结构组成：一个任务队列(TQ)保存tile中的所有任务并将空闲任务分派到PE，以及一个提交队列(CQ)，保存正在运行或完成的任务的推测状态，并提交或中止他们根据需要。此外，一个小任务发送缓冲区(TSB)从PE接收新创建的任务并将它们发送到正确的tile。<br>Fig. 7详细说明了每个tile的微架构，并显示了这些结构，它们一起类似于任务级重新排序缓冲区。</p><h4 id="任务队列"><a href="#任务队列" class="headerlink" title="任务队列"></a>任务队列</h4><p>任务队列由两个主要结构组成：任务数组和顺序队列。任务数组是一个简单的内存，用于存储tile中每个任务的任务描述符。每个任务描述符包含运行任务所需的所有数据：其类型、时间戳、对象ID和参数。订单队列持有空闲任务并按时间戳顺序将它们分派给PE。<br>当任务到达tile时，任务会在任务数组和排序队列中分配条目。它们保留他们的订单队列条目，直到他们被分派到PE，但在他们的整个生命周期（即，直到他们提交或被丢弃）都保留他们的任务数组条目。这样，如果任务被中止，任务数组就有重新执行它所需的信息。当一个任务需要重新执行时，它被重新插入到订单队列中。<br><strong>任务溢出:</strong> 任务队列的容量有限，但SLOT程序可能会创建无限数量的任务。当任务队列快满时，Chronos通过将任务溢出到主内存来提供无限任务队列的假象。</p><h4 id="提交队列"><a href="#提交队列" class="headerlink" title="提交队列"></a>提交队列</h4><p>提交队列保存所有正在运行或已完成的任务的推测状态。在Chronos中，这种推测状态由任务的撤消日志（允许回滚任务的内存写入）和子指针（允许中止任务的后代）组成。<br>每个子指针跟踪子任务的tile和任务数组条目id。当一个孩子被创建时，它被发送到由其对象 id 指定的图块。 当接收 tile 将其排队时，它会回复子任务的指针。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ambit: In-Memory Accelerator for Bulk Bitwise Operations Using Commodity DRAM Technology</title>
      <link href="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/"/>
      <url>/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/</url>
      
        <content type="html"><![CDATA[<!-- 文章标题 --><!-- TOC --><ul><li><a href="#summary">Summary</a></li><li><a href="#research-objective">Research Objective</a></li><li><a href="#problem-statement">Problem Statement</a></li><li><a href="#methods">Method(s)</a><ul><li><a href="#detailed-design">Detailed Design</a><ul><li><a href="#ambit-and-or">Ambit-AND-OR</a></li><li><a href="#tra%E8%83%BD%E5%A4%9F%E5%B7%A5%E4%BD%9C%E9%9C%80%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98">TRA能够工作需要解决的问题</a></li><li><a href="#%E8%A7%A3%E5%86%B335%E7%9A%84ambit-and-or-flow">解决3~5的Ambit-AND-OR Flow</a></li><li><a href="#ambit-not">Ambit-NOT</a></li></ul></li><li><a href="#ambit-putting-it--all-together">Ambit: Putting it  all together</a><ul><li><a href="#row-address-grouping">Row address grouping</a></li><li><a href="#executing-bitwise-ops-the-aap-primitive">Executing Bitwise Ops: The AAP Primitive</a></li><li><a href="#accelerating-aap-with-a-split-row-decoder">Accelerating AAP with a Split Row Decoder</a></li><li><a href="#integrating-ambit-with-the-system">Integrating Ambit with the System</a></li></ul></li></ul></li><li><a href="#evaluation">Evaluation</a></li><li><a href="#conclusion">Conclusion</a><ul><li><a href="#circuit-level-spice-simulation">Circuit-level SPICE Simulation</a></li><li><a href="#analysis-of-throughput--energy">Analysis of Throughput &amp; Energy</a></li><li><a href="#effect-on-real-world-application">Effect on Real-World Application</a></li></ul></li><li><a href="#notes">Notes</a><ul><li><a href="#bulk-bitwise-operations%E7%9A%84%E5%8A%A0%E9%80%9F%E5%9C%BA%E6%99%AF%E5%8F%8A%E6%84%8F%E4%B9%89">Bulk bitwise operations的加速场景及意义</a></li><li><a href="#interleaved-memory-system-%E4%BA%A4%E9%94%99%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F">Interleaved Memory System (交错存储系统)</a></li></ul></li></ul><!-- /TOC --><p>HPCA-2020</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><!-- 写完笔记之后最后填，概述文章的内容，以后查阅笔记的时候先看这一段。 --><p>这篇文章介绍了一种存内计算的方法Ambit，可以在DRAM中实现整行的AND/OR/NOT逻辑操作，将源数据复制到预留的操作数行，不破坏原始数据，同时降低操作数译码电路的复杂度。</p><h2 id="Research-Objective"><a href="#Research-Objective" class="headerlink" title="Research Objective"></a>Research Objective</h2><!-- 作者的研究目标 --><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><!-- 问题陈述，要解决什么问题？ --><p>In existing architectures, the throughput of bulk bitwise operations is limited by the memory bandwidth available to the processing unit (e.g., CPU, GPU, FPGA, processing-in-memory).</p><h2 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a>Method(s)</h2><!-- 解决问题的方法/算法是什么？ --><p>Ambit利用DRAM技术的模拟操作完全在DRAM内部执行按位运算，从而充分利用了内部DRAM的全部带宽。<br>With modest changes to the DRAM design, Ambit can exploit:</p><ul><li>the maximum internal bandwidth available inside each DRAM array;</li><li>the memory-level parallelism across multiple DRAM arrays.</li></ul><h3 id="Detailed-Design"><a href="#Detailed-Design" class="headerlink" title="Detailed Design"></a>Detailed Design</h3><h4 id="Ambit-AND-OR"><a href="#Ambit-AND-OR" class="headerlink" title="Ambit-AND-OR"></a>Ambit-AND-OR</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-11-44-34.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="TRA"></p><p>TRA (triple-row activation) 同时将一个读出放大器与同一位线上的三个DRAM单元相连，假设这三个单元的电容相同，都为$C_c$，bitline的寄生电容为$C_b$，基于电荷共享原则，在电荷共享结束之后，bitline上的电压偏差为：<br>$$\delta = \frac{k\cdot C_c \cdot V_{DD} + C_b \cdot \frac{1}{2} \cdot V_{DD}}{3C_c + C_b} - \frac{1}{2}V_{DD} = \frac{(2k-3)C_c}{6C_c + 2C_b}V_{DD}$$<br>从上面的公式可以看出，如果$k = 2, 3$，则bitline deviation为正，如果$k = 0, 1$，则bitline deviation为负。<br>分别使用A, B, C表示三个cell的逻辑值，则最终的输出可以表示为$C(A+B) + \overline{C}(AB)$，由此我们可以得到：通过控制C的逻辑值，我们可以使用TRA实现逻辑AND和OR。</p><h4 id="TRA能够工作需要解决的问题"><a href="#TRA能够工作需要解决的问题" class="headerlink" title="TRA能够工作需要解决的问题"></a>TRA能够工作需要解决的问题</h4><ol><li>当同时激活三个单元时，位线上的偏差可能小于仅激活一个单元时的偏差。 这可能会延长感测放大的时间或更糟，感测放大器可能会检测到错误的值。</li><li>由于工艺的变化，所有电容相等的假设在实际设计中是不正确的。这会影响TRA的可靠性，从而影响其结果的正确性。</li><li>TRA会改写三个cell的原始数据。</li><li>电容可能会没有充电到满电荷，或者由于漏电会导致电荷随时间减少，如果漏电明显会影响运算结果。</li><li>同时激活DRAM子阵列中的三个任意行需要内存控制器和行解码器同时通信和解码三个行地址。这将在地址总线和行解码器上引入大量成本。</li></ol><h4 id="解决3-5的Ambit-AND-OR-Flow"><a href="#解决3-5的Ambit-AND-OR-Flow" class="headerlink" title="解决3~5的Ambit-AND-OR Flow"></a>解决3~5的Ambit-AND-OR Flow</h4><p>Ambit reserves a set of designed rows in each subarray thar are used to perform TRAs. These designated rows are chosen statically at design time.</p><ol><li>Copy data of row A to designated row T0</li><li>Copy data of row B to designated row T1</li><li>Initialize designated row T2 to 0</li><li>Activate designated rows T0, T1, and T2 simultaneously</li><li>Copy data of row T0 to row R</li></ol><h4 id="Ambit-NOT"><a href="#Ambit-NOT" class="headerlink" title="Ambit-NOT"></a>Ambit-NOT</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-46-47.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Ambit-NOT"></p><p>$\overline{\text{bitline}}$上的电压表示cell逻辑值的NOT逻辑，因此Ambit-NOT的方法是将$\overline{\text{bitline}}$上的数值连接到$bitline$，从而实现NOT逻辑，如上图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-52-29.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Bitwise NOT using a dual-contact cell"></p><ol><li>Activate the source row A;</li><li>Activate n-wordline of DCC (address B5);</li><li>Precharge the bank;</li><li>Copy data from d-wordline of DCC to row R (RowClone).</li></ol><h3 id="Ambit-Putting-it-all-together"><a href="#Ambit-Putting-it-all-together" class="headerlink" title="Ambit: Putting it  all together"></a>Ambit: Putting it  all together</h3><h4 id="Row-address-grouping"><a href="#Row-address-grouping" class="headerlink" title="Row address grouping"></a>Row address grouping</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-58-18.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Row address grouping"></p><p>Ambit将每个subarray中的行地址分为三类：</p><ul><li><strong>B</strong>itwise group</li><li><strong>C</strong>ontrol group</li><li><strong>D</strong>ata group</li></ul><p>Bitwise group的地址译码如下表所示：</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-16-07-51.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Mappping of B-group address"></p><h4 id="Executing-Bitwise-Ops-The-AAP-Primitive"><a href="#Executing-Bitwise-Ops-The-AAP-Primitive" class="headerlink" title="Executing Bitwise Ops: The AAP Primitive"></a>Executing Bitwise Ops: The AAP Primitive</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-16-29-14.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Command sequences for different bitwise operations"></p><p>从上图可以看出逻辑操作基本上可以使用AAP操作和AP操作来实现。</p><h4 id="Accelerating-AAP-with-a-Split-Row-Decoder"><a href="#Accelerating-AAP-with-a-Split-Row-Decoder" class="headerlink" title="Accelerating AAP with a Split Row Decoder"></a>Accelerating AAP with a Split Row Decoder</h4><h4 id="Integrating-Ambit-with-the-System"><a href="#Integrating-Ambit-with-the-System" class="headerlink" title="Integrating Ambit with the System"></a>Integrating Ambit with the System</h4><ol><li><p>ISA Support<br>$$bbop dst, src1, [src2], size$$</p></li><li><p>Ambit API/Driver Support</p><ul><li>an API that enables applications to specify bitvectors that are likely to be involved in bitwise operations;</li><li>a driver that is aware of the internal mapping of DRAM rows to subarrays and maps the bitvectors involved in bulk bitwise operations to the same DRAM array.</li></ul></li><li><p>Implementing the $bbop$ Instruction<br> 微架构需要检查：1)Ambit操作的源/目的地址是否行对齐；2)操作的长度是否是DRAM行长度的整数倍。如果检查通过，则CPU将操作发送到memory controller，否则CPU执行该操作。</p></li><li><p>Maintaining On-chip Cache Coherence</p><ul><li>flush any dirty cache lines from the source rows;</li><li>invalidate any cache lines from the source rows;<blockquote><p>Note: The above mechanism is already required by DMA. As Ambit operations are always row-wide, we can use structures like the Dirty-Block Index to speed up flushing dirty data.</p></blockquote></li></ul></li><li><p>Error Correction and Data Scrambling<br>暂时不深入这一块</p></li></ol><h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><!-- 作者如何评估自己的方法，有没有问题或者可以借鉴的地方 --><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-29-22.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><!-- 作者给了哪些strong conclusion, 又给了哪些weak conclusion? --><h3 id="Circuit-level-SPICE-Simulation"><a href="#Circuit-level-SPICE-Simulation" class="headerlink" title="Circuit-level SPICE Simulation"></a>Circuit-level SPICE Simulation</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-21-41.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Effect of process variation on TRA"></p><p><strong>Simulation tools:</strong><br>    HSPICE with the sense amplifier using 55nm DDR3 model parameters.<br><strong>Conclusion:</strong></p><ul><li>up to $\pm5%$ variation, there are zero errors in TRA.</li><li>even with $\pm10%$ and $\pm15%$ variation, the percentage of erroneous TRAs across 100,000 iterations each is just 0.29% and 6.01%.</li></ul><h3 id="Analysis-of-Throughput-amp-Energy"><a href="#Analysis-of-Throughput-amp-Energy" class="headerlink" title="Analysis of Throughput &amp; Energy"></a>Analysis of Throughput &amp; Energy</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-32-10.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Through of bbop"></p><p> Ambit (with 8 DRAM banks) outperform Skylake by 44.9%, GTX745 by 32.0x, and HMC 2.0 by 2.4X.</p><p> <img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-39-42.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Energy of bbop"></p><p><strong>Conclusion:</strong> Ambit reduces energy consumption by 25.1X-59.5X compared to copying data with the memory controller using the DDR3 interface.</p><h3 id="Effect-on-Real-World-Application"><a href="#Effect-on-Real-World-Application" class="headerlink" title="Effect on Real-World Application"></a>Effect on Real-World Application</h3><p><strong>Tools:</strong> GEM5<br><strong>Benchmark:</strong><br>    - a database bitmap index<br>    - BitWeaving, a mechanism to accelerate database column scan operations<br>    - a bitvector-based implementation of the widely-used set data structure</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-53-03.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Bitmap index performance"></p><p><strong>Conclusion:</strong> Ambit significantly reduces the query execution time compared to the baseline by 6X on average.</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-54-54.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Speedup offered by Ambit for BitWeaving"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-58-20.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Performance of set operations"></p><p><font color="blue" size="5">现有基于忆阻器的PIM能够加速的一大原因在于神经网络计算的高并行度，但是一旦并行度不高，这些慢的访存速度将强烈限制PIM的性能，因此在比cache访存速度慢的memory中实现非规则计算加速是不现实的，物理特性和容量升高都会导致访存变慢。但是有可能实现低功耗PIM。</font></p><h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><!-- 在这些框架外额外需要记录的笔记。 --><h3 id="Bulk-bitwise-operations的加速场景及意义"><a href="#Bulk-bitwise-operations的加速场景及意义" class="headerlink" title="Bulk bitwise operations的加速场景及意义"></a>Bulk bitwise operations的加速场景及意义</h3><p>In fact, many real-world databases support bitmap indice. A recent work, WideTable, designs an entire database around a technique called BitWeaving, which accelerates scans completely using bulk bitwise operations. Microsoft recently open-sourced a technology called BitFunnel that accelerates the document filtering portion of web search. BitFunnel relies on fast bulk bitwise AND operations. Bulk bitwise operations are also prevalent in DNA sequence alignment, encrayption algorithms, graph processing, and networking. Thus, accelerating bulk bitwise operations can significantly boost the performance of various applications.</p><h3 id="Interleaved-Memory-System-交错存储系统"><a href="#Interleaved-Memory-System-交错存储系统" class="headerlink" title="Interleaved Memory System (交错存储系统)"></a>Interleaved Memory System (交错存储系统)</h3><blockquote><p>参考链接：<a href="https://blog.csdn.net/wbcuc/article/details/8183369">https://blog.csdn.net/wbcuc/article/details/8183369</a></p></blockquote><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-47-52.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Non-interleaved Memory Organization"></p><p>非交错存储系统如上图所示，单个bank内地址连续，因此访问连续内存需要串行访问，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-51-32.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Non-interleaved Burst Access Timing"></p><p>不难看出上面这种方式的访问延时比较高，为了降低访存的延时，交错存储系统将地址连续的分布在bank之间，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-53-18.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Interleaved Memory Organization"></p><p>因此bank0和bank1的可以并行访问，从而将地址0和1并行读出，降低了访存的延时，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-55-01.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Intereaved Burst Access Timing"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Compute Caches</title>
      <link href="/2021/08/26/compute-caches/"/>
      <url>/2021/08/26/compute-caches/</url>
      
        <content type="html"><![CDATA[<h1 id="Compute-Caches"><a href="#Compute-Caches" class="headerlink" title="Compute Caches"></a>Compute Caches</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>转-四种基本的编程命名规范</title>
      <link href="/2021/08/13/zhuan-si-chong-ji-ben-de-bian-cheng-ming-ming-gui-fan/"/>
      <url>/2021/08/13/zhuan-si-chong-ji-ben-de-bian-cheng-ming-ming-gui-fan/</url>
      
        <content type="html"><![CDATA[<h1 id="转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）"><a href="#转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）" class="headerlink" title="转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）"></a>转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）</h1><h2 id="匈牙利命名法"><a href="#匈牙利命名法" class="headerlink" title="匈牙利命名法"></a>匈牙利命名法</h2><p>匈牙利命名法是早期的规范，由微软的一个匈牙利人发明的，是IDE还十分智障的年代的产物。那个年代，当代码量很多的时候，想要确定一个变量的类型是很麻烦的，不像现在IDE都会给提示，所以才产生了这样一个命名规范，估计现在已经没啥人用了吧……一个十分系统却又琐碎的命名规范。</p><p>该命名规范，要求前缀字母用变量类型的缩写，其余部分用变量的英文或英文的缩写，单词第一个字母大写。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int iMyAge;        #  &quot;i&quot;: int</span><br><span class="line">char cMyName[10];  #  &quot;c&quot;: char</span><br><span class="line">float fManHeight;  #  &quot;f&quot;: float</span><br></pre></td></tr></table></figure><p>其他前缀类型还有：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">a      数组（Array）</span><br><span class="line">b      布尔值（Boolean）</span><br><span class="line">by     字节（Byte）</span><br><span class="line">c      有符号字符（Char）</span><br><span class="line">cb     无符号字符（Char Byte，并没有神马人用的）</span><br><span class="line">cr     颜色参考值（Color Ref）</span><br><span class="line">cx,cy  坐标差（长度 Short Int）</span><br><span class="line">dw     双字（Double Word）</span><br><span class="line">fn     函数（Function）</span><br><span class="line">h      Handle（句柄）</span><br><span class="line">i      整形（Int）</span><br><span class="line">l      长整型（Long Int）</span><br><span class="line">lp     长指针（Long Pointer）</span><br><span class="line">m_     类成员（Class Member）</span><br><span class="line">n      短整型（Short Int）</span><br><span class="line">np     近程指针（Near Pointer）</span><br><span class="line">p      指针（Pointer）</span><br><span class="line">s      字符串（String）</span><br><span class="line">sz     以 Null 做结尾的字符串型（String with Zero End）</span><br><span class="line">w      字（Word）</span><br></pre></td></tr></table></figure><p>还有其他更多的前缀是根据微软自己的MFC/句柄/控件/结构等东西定义的，就不过多描述了。</p><h2 id="驼峰式命名法"><a href="#驼峰式命名法" class="headerlink" title="驼峰式命名法"></a>驼峰式命名法</h2><p>驼峰式命名法，又叫小驼峰式命名法（所以自然就存在大驼峰命名法啦……)。</p><p>该命名规范，要求第一个单词首字母小写，后面其他单词首字母大写，简单粗暴易学易用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int myAge;</span><br><span class="line">char myName[10];</span><br><span class="line">float manHeight;</span><br></pre></td></tr></table></figure><h2 id="帕斯卡命名法"><a href="#帕斯卡命名法" class="headerlink" title="帕斯卡命名法"></a>帕斯卡命名法</h2><p>帕斯卡命名法，又叫大驼峰式命名法。</p><p>与小驼峰式命名法的最大区别在于，每个单词的第一个字母都要大写。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int MyAge;</span><br><span class="line">char MyName[10];</span><br><span class="line">float ManHeight;</span><br></pre></td></tr></table></figure><h2 id="下划线命名法"><a href="#下划线命名法" class="headerlink" title="下划线命名法"></a>下划线命名法</h2><p>下划线命名法并不如大小驼峰式命名法那么备受推崇，但是也是浓墨重彩的一笔。尤其在宏定义和常量中使用比较多，通过下划线来分割全部都是大写的单词。</p><p>该命名规范，也是很简单，要求单词与单词之间通过下划线连接即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int my_age;</span><br><span class="line">char my_name[10];</span><br><span class="line">float man_height;</span><br></pre></td></tr></table></figure><h2 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h2><p>随着技术的发展，命名规范也在不断的细化，一种命名规范早已无法系统的满足各方需求（匈牙利命名法除外，但是已经基本淘汰了），不同的语言不同 IDE 推崇的规范也有所不同，无法评判哪一种最好，但是可以肯定的是，集后三种命名规范大成者，一定是受众最广的。</p><p>例如，谷歌 C++ 编程规范，从项目的命名到文件的命名，再到类和变量以及宏定义的命名都做到了细致入微，充分的结合了下划线命名法与驼峰式命名法（早先推崇的小驼峰，不过今年好像改成大驼峰了），又加入了一些新的元素，十分的系统完善。</p><p>当然，命名规范并不代表着编程规范，仅仅是编程规范的一部分而已，除去命名规范，还有很多编程上的细节是必须关注的，例如，等号两边留空格还是等号对齐？空行神马时候神马地方留更加符合代码结构？空格神马时候神马地方留更加美观？花括号是否对齐？</p><p>诸如此类，还有很多，无法一下子全部掌握并应用，但是在编程经验增加的过程中，一定也要不断的留意，自己所在的公司部门使用的是神马样的规范，没错，并不提倡大家练就自己的规范，一定要去融入工作环境的需求。</p><p>每次去新的工作环境，第一个要看的文档不是别的，一定是编程规范，如果没有这个东西，那么就努力去推一个统一的规范，推不动的话，那可以换工作了，否则日后将会带来无尽的麻烦。</p><p>本文转载自：<a href="https://zhuanlan.zhihu.com/p/89909623">https://zhuanlan.zhihu.com/p/89909623</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2021/08/07/hello-world/"/>
      <url>/2021/08/07/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>A 28 nm Configurable Memory (TCAM/BCAM/SRAM) Using Push-Rule 6T Bit Cell Enabling Logic-in-Memory</title>
      <link href="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/"/>
      <url>/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/</url>
      
        <content type="html"><![CDATA[<p>今天在阅读“CAPE: A Content-Addressable Processing Engine”这篇论文时，论文中引用的一篇仅使用6T SRAM实现CAM的工作引起了我的兴趣。</p><p>由于可以对存储的所有entry进行并行数据搜索/匹配的优良特性，CAM是高关联性缓存、TLB和寄存器重命名电路中不可或缺的部分。LUT也是IP路由器表的主要功能，如Fig. 1所示，因此CAM是许多路由器芯片的主要组成部分。<br><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-222208.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><!-- ![](202184-222208.jpg) --><p>但是传统的CAM存在一个严重的问题就是资源开销很大，无法高密度集成，比如一个BCAM需要10个晶体管，一个TCAM需要16个晶体管，如Fig. 2所示。<br><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-222641.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>因此本文能够使用6T SRAM紧凑的单元实现CAM的方案就显得非常有意义。同时，该论文在保留SRAM存储功能的基础上还实现了TCAM以及一些基础的逻辑操作（AND和NOR）。该论文不仅提出了实现方案，还通过一些精巧的设计保证了该设计的高性能，而且分析的面面俱到，是一个相当优秀的工作。</p><p>在此也先简单总结一下该设计的最终性能：基于6T 28nm FDSOI SRAM工艺，实现了$64\times 64 (4kb)$ BCAM，在1V工作电压下，BCAM的工作频率为370 MHz，能效为$0.5\ fJ/search/bit$，两个64-bit words的逻辑操作的频率达到787 MHz。</p><p>接下来开始介绍该工作的细节，受限简单介绍一下传统CAM搜索的原理。如Fig. 3所示，存储单元中的比特与输入的比特进行XNOR操作，然后同一根match line上的所有同或结果进行线与逻辑，最终通过SA输出匹配结果。在很多查找应用中，可能需要匹配多个结果，如果只需要单个地址，也可以对结果进行优先编码。<font color="blue">这里对搜索的结果进行优先编码也可能对今后的研究有一些启示，很多时候想用到优先编码，但是还没有遇到合适的场合。</font></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-224025.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>接下来看这篇论文提出的6T BCAM设计，如Fig. 4所示。该设计使用标准SRAM中的位线 作为match lines，使用WL表示搜索序列按列进行搜索匹配。而传统的SRAM存储功能仍然保持，可以动态配置成BCAM/TCAM/Logic/SRAM storage。为此，需要对电路进行一些特殊设计，以兼容多种模式，这些在本文中也一一进行了详细的介绍，之后我也会对一些关键的考虑进行简单的介绍。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-224830.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>从Fig. 4中，我们可以看到为了兼容CAM的功能，作者在传统的6T SRAM基础上进行了些微的改动，那就是将WL变为两根，WLR和WLL，分别对与BL和BLB相连的晶体管进行门控（这在Fig. 5中可以看得更加清楚）。文中对这一设计的代价总结为:</p><blockquote><p>“This creates two indeppendent access transistors but incur no area penalty since the push-rule layers are kept intact (i.e., only DRC-compliant metallization changes are made).”</p></blockquote><p><font color="blue">在这里重点指出这一点的原因在于：之前我在和其他人讨论类似的设计的时候，我想通过一根WL改进设计，大家觉得增加这一根线会对面积开销产生很大的影响，这与这边作者的观点相左，暂时看不懂这里为什么面积不会有很大的影响，今后的研究中可能会借鉴这个观点。</font></p><p>废话说完，开始真正介绍三种工作模式：</p><p><strong>1. BCAM</strong></p><p>Fig. 5展示的是该设计实现BCAM搜索的过程，Search string从WLR/WLL输入，当输入为1时，WLR=1，WLL=0，表明BL对应的门控晶体管开启，BLB对应的门控晶体管截止。如果对应的SRAM cell存的值为1，则BL对应的门控晶体管D/S端都为高电平，结果是BL和BLB的最终电位都为高，而如果存储的值为0，则BL预充的高电平会通过SRAM cell放电，从而将BL上电位下拉到0，BLB上电位仍然保持高电平。当输入为0时，工作情况类似，只是BLB对应的门控晶体管开启。因此同一条BL对应的SRAM cell只要有任意一比特无法跟search string bit匹配，BL或BLB会被下拉到低电平，最终与门输出为0，否则输出为1，表示完全匹配。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-230549.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Note:</p><ul><li>基于SRAM的CAM相对于忆阻器的CAM还有一个有点就是搜索的字长可以做到特别长，因为SRAM的off state可以做到几乎不漏电。</li><li>针对SRAM的读操作和BCAM的操作，SA的工作机制是不同的，该设计提出了一种SA，可以在不增加面积的基础上，实现可重构的两种功能的SA，如Fig. 6所示。<br><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-05002.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></li><li>SRAM是逐行写，CAM是对所有列进行匹配，数据需要逐列写。这要是在我看来就是不可能的，这个方案就放弃了，但是作者可能巧妙地解决了这一问题，不仅是磕盐的态度，对于行和列都要写的方案在今后的设计中也可以参考，毕竟有时候经常需要行/列都进行操作，比如矩阵的转置等等，比如从一个bank中逐行读出，逐列写入另一个bank。之前陈怡然也有一篇工作涉及到行列操作的CAM，也可以一起总结一下。这个按列去写刚好受益于有两根WL，这跟BL是等价的。逐行写数据从BL输入，逐列写数据从WL输入。</li><li>该工作还考虑了同时开启多行对SRAM cell中数据的破坏进行了分析，并提出了解决方案。</li></ul><p><strong>2. TCAM</strong></p><p>TCAM的工作原理如Fig. 13所示，由于TCAM中存在三种状态”1”, “0”, “X”，所以需要使用两比特来实现，相邻的两列表示一比特，其中存储”00”表示“0”，存储“11”表示“1”，存储“01”表示“X”，当存储的值为“01”是，左列的BLB对应的SRAM cell输出为“1”，右列的BL对应的SRAM输出也为“1”，因此无论输入是“0”还是“1”，都不会将BL或BLB下拉到低电平。<font color="blue">在其他文章中，认为该设计在实现TCAM时，只需要将WLR和WLL都设置为GND，这样使用BCAM同样的电路就可以实现TCAM的功能。而在本文中，作者自己竟然用了两倍的面积来实现TCAM的功能。不仔细看还会以为本文作者犯了一个错误，其实并不是这样子的。这是如何定义TCAM的一个问题。如果对于输入的某些bit进行mask的话，这样输入的这些bit与所有搜索项目的对应bit都不会去比较，个人感觉这种是比较常用的，但是对于优先编码等应用场合，这种就不适用了，需要将对应的某一搜索项的某些bit进行mask，这样就需要用到本文中所提出的方案，也没有去查TCAM的具体定义，可能这中才是真正的TCAM（杨老师Nature Electronics论文中也是实现的这种方式），以后研究过程中可以用这个电路。</font></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202193-12929.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><strong>3. Logic Operations</strong></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-15755.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该设计实现“AND”逻辑如Fig. 15所示，逻辑操作与存储相同，是以行为单位进行的。要对某两行进行逻辑操作，将对应的WL输入设置为“1”（即WLR=VDD, WLL=GND)，其他行WLL=WLR=GND进行MASK。开启的两行中对应的2个SRAM cell中只要有一个cell存储的值为0，就会将BL下拉到低电平，即实现了“AND”操作。“NOR”操作方式与“AND”类似，TABLE I总结了这两种操作的配置。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20434.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该设计的整体架构如Fig. 16所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20452.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>最后，放置一些实验结果，以对该设计的性能有一个更加深入的了解。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20730.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20753.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20813.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20832.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20851.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 挖坑待填 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决gem5运行时缺少pydot的问题</title>
      <link href="/2021/08/03/jie-jue-gem5-yun-xing-shi-que-shao-pydot-de-wen-ti/"/>
      <url>/2021/08/03/jie-jue-gem5-yun-xing-shi-que-shao-pydot-de-wen-ti/</url>
      
        <content type="html"><![CDATA[<h1 id="解决gem5运行时缺少pydot的问题"><a href="#解决gem5运行时缺少pydot的问题" class="headerlink" title="解决gem5运行时缺少pydot的问题"></a>解决gem5运行时缺少pydot的问题</h1><p>在运行gem5时，会显示：</p><blockquote><p>warn: No dot file generated. Please install pydot to generate the dot file and pdf.</p></blockquote><p>作为一个高度强迫症患者，实在无法忍受每次运行出现这个刺眼的warning，而且在进行系统仿真的时候，产生的config.dot.svg和config.dot.pdf等文件还可以可视化整个系统的架构，为此记录一下我解决这个问题的方法。</p><p>在网上搜索博客，基本上都是如下的<a href="https://blog.csdn.net/mjl960108/article/details/79981794">解决方案</a>：</p><blockquote><p>sudo apt install python-pydot python-pydot-ng graphviz</p></blockquote><p>但是运行时会事与愿违：</p><blockquote><p>root@9187b8755600:~/gem5/m5out# apt install python-pydot python-pydot-ng graphviz<br>Reading package lists… Done<br>Building dependency tree<br>Reading state information… Done<br>E: Unable to locate package python-pydot<br>E: Unable to locate package python-pydot-ng</p></blockquote><p>找不到安装包，也有博客指出需要使用pip命令安装，但是ubuntu自带的python无法找到pip命令，而也最好不要使用conda的虚拟python环境，因为无法定位到虚拟环境中的scons命令，这个我至今也没有解决，而是直接安装docker环境，配置python2.7和python3.8，用于不同版本的gem5，非常方便。</p><p>为此解决系统python环境缺少pydot的方法如下：</p><ol><li>下载<a href="https://pypi.org/project/pydot/#files">pydot源</a><blockquote><p>wget <a href="https://files.pythonhosted.org/packages/13/6e/916cdf94f9b38ae0777b254c75c3bdddee49a54cc4014aac1460a7a172b3/pydot-1.4.2.tar.gz">https://files.pythonhosted.org/packages/13/6e/916cdf94f9b38ae0777b254c75c3bdddee49a54cc4014aac1460a7a172b3/pydot-1.4.2.tar.gz</a></p></blockquote></li><li>解压文件</li><li>安装pydot<blockquote><p>python setup.py install (for python2.7)<br>python3 setup.py install (for python3.8)</p></blockquote></li></ol><p>完美解决！！！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>(转)Types of Memory Interleaving</title>
      <link href="/2021/07/30/zhuan-types-of-memory-interleaving/"/>
      <url>/2021/07/30/zhuan-types-of-memory-interleaving/</url>
      
        <content type="html"><![CDATA[<h1 id="转-Types-of-Memory-Interleaving"><a href="#转-Types-of-Memory-Interleaving" class="headerlink" title="(转)Types of Memory Interleaving"></a>(转)Types of Memory Interleaving</h1><p><a href="https://www.geeksforgeeks.org/memory-interleaving/">Memory Interleaving</a> is an abstraction technique which divides memory into a number of modules such that successive words in the address space are placed in the different module.</p><p>Suppose a 64 MB memory made up of the 4 MB chips as shown in the below:</p><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/1406-4.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>We organize the memory into 4 MB banks, each having eight of the 4 MB chips. The memory thus has 16 banks, each of 4 MB.</p><p>64 MB memory = $2^{26}$, so 26 bits are used for addressing.<br>16 = $2^4$, so 4 bits of address select the bank, and 4 MB = $2^{22}$, so 22 bits of address to each chip.</p><p>In general, an N-bit address, with $N = L + M$, is broken into two parts:</p><ol><li>L-bit bank select, used to activate one of the $2^L$ banks of memory, and</li><li>M-bit address that is sent to each of the memory banks.</li></ol><p>When one of the memory banks is active, the other ($2^L – 1$) are inactive. All banks receive the M-bit address, but the inactive one do not respond to it.</p><p><strong>Classification of Memory Interleaving:</strong><br>Memory interleaving is classified into two types:</p><ol><li><strong>High Order Interleaving –</strong> In high-order interleaving, the most significant bits of the address select the memory chip. The least significant bits are sent as addresses to each chip. One problem is that consecutive addresses tend to be in the same chip. The maximum rate of data transfer is limited by the memory cycle time.</li></ol><p>It is also known as Memory Banking.</p><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/223-1.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ol start="2"><li><strong>Low Order Interleaving –</strong> In low-order interleaving, the least significant bits select the memory bank (module). In this, consecutive memory addresses are in different memory modules. This allows memory access at much faster rates than allowed by the cycle time.</li></ol><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/3164-1.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>注：转载于<a href="https://www.geeksforgeeks.org/types-of-memory-interleaving/">https://www.geeksforgeeks.org/types-of-memory-interleaving/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CACTI 7.0介绍</title>
      <link href="/2021/07/29/cacti-7-0-jie-shao/"/>
      <url>/2021/07/29/cacti-7-0-jie-shao/</url>
      
        <content type="html"><![CDATA[<h1 id="CACTI-7-0介绍"><a href="#CACTI-7-0介绍" class="headerlink" title="CACTI 7.0介绍"></a>CACTI 7.0介绍</h1><h2 id="1-CACTI发展"><a href="#1-CACTI发展" class="headerlink" title="1. CACTI发展"></a>1. CACTI发展</h2><p>CACTI是HP公司推出的一款开源开源工具，广泛应用于对cache/DRAM的延时，功耗，cycle time[^1]和面积的评估。</p><p>[^1]: <font color="gray">(暂时不知道如何翻译比较好，感觉前面的延时指的是各个部分的延时信息，这边的cycle time应该指的是访问周期)</font></p><p>CACTI最初由Dr. Jouppi和Dr. Wilton于1993年开发，此后经历了六次版本的迭代。</p><h2 id="2-CACTI支持的特性"><a href="#2-CACTI支持的特性" class="headerlink" title="2. CACTI支持的特性"></a>2. CACTI支持的特性</h2><ul><li>以下memory的功耗、延时、cycle time的建模<ul><li>direct mapped caches</li><li>set-associative caches</li><li>fully associative caches</li><li>Embedded DRAM memories</li><li>Commodity DRAM memories</li></ul></li><li>多端口UCA(uniform cache access)，多端口的NUCA(non-uniform cache access)的建模</li><li>工作温度对泄露功耗的影响</li><li>路由功耗模型</li><li>具有不同延迟、功耗和面积属性的互连模型，包括低摆幅线模型</li><li>用于执行功率、延迟、面积和带宽之间权衡分析的接口</li><li>该工具使用的所有工艺特定值均从 ITRS 获得，目前该工具支持 90nm、65nm、45nm 和 32nm 技术节点</li><li>用于计算DDR总线延迟和能量的芯片IO模型。用户可以模拟不同的负载（扇出）并评估对频率和能量的影响。该模型可用于研究LR-DIMM、R-DIMM等。</li><li>Version 7.0在6.5版本的基础之上还融合了CACTI 3D</li></ul><h2 id="3-CACTI的使用方法"><a href="#3-CACTI的使用方法" class="headerlink" title="3. CACTI的使用方法"></a>3. CACTI的使用方法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/HewlettPackard/cacti</span><br><span class="line"><span class="built_in">cd</span> cacti</span><br><span class="line"><span class="comment"># modify the xxx.cfg for self configuration</span></span><br><span class="line">make</span><br><span class="line">./cacti -infile xxx.cfg</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows使用sftp获取服务器运行记录</title>
      <link href="/2021/07/25/windows-shi-yong-sftp-huo-qu-fu-wu-qi-yun-xing-ji-lu/"/>
      <url>/2021/07/25/windows-shi-yong-sftp-huo-qu-fu-wu-qi-yun-xing-ji-lu/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>函数的副作用</title>
      <link href="/2021/07/25/han-shu-de-fu-zuo-yong/"/>
      <url>/2021/07/25/han-shu-de-fu-zuo-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="转-函数的副作用"><a href="#转-函数的副作用" class="headerlink" title="(转)函数的副作用"></a>(转)函数的副作用</h1><p><strong>函数的副作用</strong>指当调用函数时，除了返回函数值之外，还对主调用函数产生附加的影响。例如修改全局变量（函数外的变量）或修改参数。</p><p>函数副作用会给程序设计带来不必要的麻烦，给程序带来十分难以查找的错误，并且降低程序的可读性。严格的函数式语言要求函数必须无副作用。</p><p>函数的副作用相关的几个概念， Pure Function、 Impure Function、 Referential Transparent。</p><ul><li><p><strong>纯函数 (Pure Function)</strong><br>输入输出数据流全是显式（Explicit）的。 显式（Explicit）的意思是，函数与外界交换数据只有一个唯一渠道——参数和返回值。函数从函数外部接受的所有输入信息都通过参数传递到该函数内部。函数输出到函数外部的所有信息都通过返回值传递到该函数外部。</p></li><li><p><strong>非纯函数 (Impure Function)</strong></p><p>与之相反。 隐式（Implicit）的意思是，函数通过参数和返回值以外的渠道，和外界进行数据交换。比如读取/修改全局变量，都叫作以隐式的方式和外界进行数据交换。</p></li><li><p><strong>引用透明 (Referential Transparent)</strong></p><p>引用透明的概念与函数的副作用相关，且受其影响。 如果程序中两个相同值得表达式能在该程序的任何地方互相替换，而不影响程序的动作，那么该程序就具有引用透明性。它的优点是比非引用透明的语言的语义更容易理解，不那么晦涩。纯函数式语言没有变量，所以它们都具有引用透明性。</p></li></ul><p>以下示例说明了引用透明与函数副作用的结合</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result1 = (fun(a) + b) / (fun(a) - c);</span><br><span class="line">temp = func(a);</span><br><span class="line">result2 = (temp + b) / (temp - c);</span><br></pre></td></tr></table></figure><p>如果函数没有副作用，那么result1和result2将是等价的。然而如果fun有副作用，比如让b或c加1，那么result1和result2将不相等。因此，副作用违背了引用透明性。</p><p>在JavaScript中，引入了函数。但显然JS中的函数可以访问、修改全局变量（或定义在函数外的变量），如下</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">5</span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fun</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">a = <span class="number">10</span>;</span><br><span class="line">&#125;</span><br><span class="line">fun();<span class="comment">// a变成了10</span></span><br></pre></td></tr></table></figure><p>JS中要想保证函数无副作用这项特性，只能依靠编程人员的习惯，即</p><ol><li><p>函数入口使用参数运算，而不修改它</p></li><li><p>函数内不修改函数外的变量，如全局变量</p></li><li><p>运算结果通过函数返回给外部（出口）</p></li></ol><blockquote><p>转载自：<a href="https://www.cnblogs.com/snandy/archive/2011/08/14/2137898.html">https://www.cnblogs.com/snandy/archive/2011/08/14/2137898.html</a></p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>(转)多核处理器的九大关键技术</title>
      <link href="/2021/07/23/zhuan-duo-he-chu-li-qi-de-jiu-da-guan-jian-ji-zhu/"/>
      <url>/2021/07/23/zhuan-duo-he-chu-li-qi-de-jiu-da-guan-jian-ji-zhu/</url>
      
        <content type="html"><![CDATA[<h1 id="转-多核处理器的九大关键技术"><a href="#转-多核处理器的九大关键技术" class="headerlink" title="(转)多核处理器的九大关键技术"></a>(转)多核处理器的九大关键技术</h1><p>与单核处理器相比，多核处理器在体系结构、软件、功耗和安全性设计等方面面临着巨大的挑战，但也蕴含着巨大的潜能。</p><p>CMP和SMT一样，致力于发掘计算的粗粒度并行性。CMP可以看做是随着大规模集成电路技术的发展，在芯片容量足够大时，就可以将大规模并行处理机结构中的SMP（对称多处理机）或DSM（分布共享处理机）节点集成到同一芯片内，各个处理器并行执行不同的线程或进程。在基于SMP结构的单芯片多处理机中，处理器之间通过片外Cache或者是片外的共享存储器来进行通信。而基于DSM结构的单芯片多处理器中，处理器间通过连接分布式存储器的片内高速交叉开关网络进行通信。由于SMP和DSM已经是非常成熟的技术了，CMP结构设计比较容易，只是后端设计和芯片制造工艺的要求较高而已。正因为这样，CMP成为了最先被应用于商用CPU的“未来”高性能处理器结构。</p><p>虽然多核能利用集成度提高带来的诸多好处，让芯片的性能成倍地增加，但很明显的是原来系统级的一些问题便引入到了处理器内部。</p><ol><li><p>核结构研究: 同构还是异构</p><p>CMP的构成分成同构和异构两类，同构是指内部核的结构是相同的，而异构是指内部的核结构是不同的。为此，面对不同的应用研究核结构的实现对未来微处理器的性能至关重要。核本身的结构，关系到整个芯片的面积、功耗和性能。怎样继承和发展传统处理器的成果，直接影响多核的性能和实现周期。同时，根据Amdahl定理，程序的加速比决定于串行部分的性能，所以，从理论上来看似乎异构微处理器的结构具有更好的性能。</p><p>核所用的指令系统对系统的实现也是很重要的，采用多核之间采用相同的指令系统还是不同的指令系统，能否运行操作系统等，也将是研究的内容之一。</p></li><li><p>程序执行模型</p><p>多核处理器设计的首要问题是选择程序执行模型。程序执行模型的适用性决定多核处理器能否以最低的代价提供最高的性能。程序执行模型是编译器设计人员与系统实现人员之间的接口。编译器设计人员决定如何将一种高级语言程序按一种程序执行模型转换成一种目标机器语言程序; 系统实现人员则决定该程序执行模型在具体目标机器上的有效实现。当目标机器是多核体系结构时，产生的问题是: 多核体系结构如何支持重要的程序执行模型？是否有其他的程序执行模型更适于多核的体系结构？这些程序执行模型能多大程度上满足应用的需要并为用户所接受？</p></li><li><p>Cache设计: 多级Cache设计与一致性问题</p><p>处理器和主存间的速度差距对CMP来说是个突出的矛盾，因此必须使用多级Cache来缓解。目前有共享一级Cache的CMP、共享二级Cache的CMP以及共享主存的CMP。通常，CMP采用共享二级Cache的CMP结构，即每个处理器核心拥有私有的一级Cache，且所有处理器核心共享二级Cache。</p><p>Cache自身的体系结构设计也直接关系到系统整体性能。但是在CMP结构中，共享Cache或独有Cache孰优孰劣、需不需要在一块芯片上建立多级Cache，以及建立几级Cache等等，由于对整个芯片的尺寸、功耗、布局、性能以及运行效率等都有很大的影响，因而这些都是需要认真研究和探讨的问题。</p><p>另一方面，多级Cache又引发一致性问题。采用何种Cache一致性模型和机制都将对CMP整体性能产生重要影响。在传统多处理器系统结构中广泛采用的Cache一致性模型有: 顺序一致性模型、弱一致性模型、释放一致性模型等。与之相关的Cache一致性机制主要有总线的侦听协议和基于目录的目录协议。目前的CMP系统大多采用基于总线的侦听协议。</p></li><li><p>核间通信技术</p><p>CMP处理器的各CPU核心执行的程序之间有时需要进行数据共享与同步，因此其硬件结构必须支持核间通信。高效的通信机制是CMP处理器高性能的重要保障，目前比较主流的片上高效通信机制有两种，一种是基于总线共享的Cache结构，一种是基于片上的互连结构。</p><p>总线共享Cache结构是指每个CPU内核拥有共享的二级或三级Cache，用于保存比较常用的数据，并通过连接核心的总线进行通信。这种系统的优点是结构简单，通信速度高，缺点是基于总线的结构可扩展性较差。</p><p>基于片上互连的结构是指每个CPU核心具有独立的处理单元和Cache，各个CPU核心通过交叉开关或片上网络等方式连接在一起。各个CPU核心间通过消息通信。这种结构的优点是可扩展性好，数据带宽有保证; 缺点是硬件结构复杂，且软件改动较大。</p><p>也许这两者的竞争结果不是互相取代而是互相合作，例如在全局范围采用片上网络而局部采用总线方式，来达到性能与复杂性的平衡。</p></li><li><p>总线设计</p><p>传统微处理器中，Cache不命中或访存事件都会对CPU的执行效率产生负面影响，而总线接口单元（BIU）的工作效率会决定此影响的程度。当多个CPU核心同时要求访问内存或多个CPU核心内私有Cache同时出现Cache不命中事件时，BIU对这多个访问请求的仲裁机制以及对外存储访问的转换机制的效率决定了CMP系统的整体性能。因此寻找高效的多端口总线接口单元（BIU）结构，将多核心对主存的单字访问转为更为高效的猝发（burst）访问; 同时寻找对CMP处理器整体效率最佳的一次Burst访问字的数量模型以及高效多端口BIU访问的仲裁机制将是CMP处理器研究的重要内容。</p></li><li><p>操作系统设计: 任务调度、中断处理、同步互斥</p><p>对于多核CPU，优化操作系统任务调度算法是保证效率的关键。一般任务调度算法有全局队列调度和局部队列调度。前者是指操作系统维护一个全局的任务等待队列，当系统中有一个CPU核心空闲时，操作系统就从全局任务等待队列中选取就绪任务开始在此核心上执行。这种方法的优点是CPU核心利用率较高。后者是指操作系统为每个CPU内核维护一个局部的任务等待队列，当系统中有一个CPU内核空闲时，便从该核心的任务等待队列中选取恰当的任务执行，这种方法的优点是任务基本上无需在多个CPU核心间切换，有利于提高CPU核心局部Cache命中率。目前多数多核CPU操作系统采用的是基于全局队列的任务调度算法。</p><p>多核的中断处理和单核有很大不同。多核的各处理器之间需要通过中断方式进行通信，所以多个处理器之间的本地中断控制器和负责仲裁各核之间中断分配的全局中断控制器也需要封装在芯片内部。</p><p>另外,多核CPU是一个多任务系统。由于不同任务会竞争共享资源，因此需要系统提供同步与互斥机制。而传统的用于单核的解决机制并不能满足多核，需要利用硬件提供的“读－修改－写”的原子操作或其他同步互斥机制来保证。</p></li><li><p>低功耗设计</p><p>半导体工艺的迅速发展使微处理器的集成度越来越高，同时处理器表面温度也变得越来越高并呈指数级增长，每三年处理器的功耗密度就能翻一番。目前，低功耗和热优化设计已经成为微处理器研究中的核心问题。CMP的多核心结构决定了其相关的功耗研究是一个至关重要的课题。</p><p>低功耗设计是一个多层次问题，需要同时在操作系统级、算法级、结构级、电路级等多个层次上进行研究。每个层次的低功耗设计方法实现的效果不同——抽象层次越高，功耗和温度降低的效果越明显。</p></li><li><p>存储器墙</p><p>为了使芯片内核充分地工作，最起码的要求是芯片能提供与芯片性能相匹配的存储器带宽，虽然内部Cache的容量能解决一些问题，但随着性能的进一步提高，必须有其他一些手段来提高存储器接口的带宽，如增加单个管脚带宽的DDR、DDR2、QDR、XDR等。同样，系统也必须有能提供高带宽的存储器。所以，芯片对封装的要求也越来越高，虽然封装的管脚数每年以20%的数目提升，但还不能完全解决问题，而且还带来了成本提高的问题，为此，怎样提供一个高带宽，低延迟的接口带宽，是必须解决的一个重要问题。</p></li><li><p>可靠性及安全性设计</p><p> 随着技术革新的发展，处理器的应用渗透到现代社会的各个层面，但是在安全性方面却存在着很大的隐患。一方面，处理器结构自身的可靠性低下，由于超微细化与时钟设计的高速化、低电源电压化，设计上的安全系数越来越难以保证，故障的发生率逐渐走高。另一方面，来自第三方的恶意攻击越来越多，手段越来越先进，已成为具有普遍性的社会问题。现在，可靠性与安全性的提高在计算机体系结构研究领域备受注目。</p></li></ol><p>转载于:<a href="http://blog.itpub.net/312079/viewspace-245322/">http://blog.itpub.net/312079/viewspace-245322/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux Tools Mannual</title>
      <link href="/2021/07/22/linux-tools-mannual/"/>
      <url>/2021/07/22/linux-tools-mannual/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux-常用工具使用命令速查表"><a href="#Linux-常用工具使用命令速查表" class="headerlink" title="Linux 常用工具使用命令速查表"></a>Linux 常用工具使用命令速查表</h1><h2 id="tmux"><a href="#tmux" class="headerlink" title="tmux"></a>tmux</h2><h3 id="tmu常用操作指令及快捷键"><a href="#tmu常用操作指令及快捷键" class="headerlink" title="tmu常用操作指令及快捷键"></a>tmu常用操作指令及快捷键</h3><ol><li>查看有所有tmux会话<br>指令：tmux ls<br>快捷键：Ctrl+b s</li><li>新建tmux窗口<br>指令：tmux new -s <session-name></session-name></li><li>重命名会话<br>指令：tmux rename-session -t <old-name> <new-name><br>快捷键：Ctrl+b $</new-name></old-name></li><li>分离会话<br>指令：tmux detach/exit(关闭窗口，杀死会话)<br>快捷键：Ctrl+b d</li><li>平铺当前窗口<br>快捷键：Ctrl+b z(再次Ctrl+b d恢复)</li><li>杀死会话<br>指令：tmux kill-session -t <session-name></session-name></li><li>切换会话<br>指令：tmux switch -t <session-name></session-name></li><li>划分上下两个窗格<br>指令：tmux split<br>快捷键：Ctrl+b “</li><li>划分左右两个窗格<br>指令：tmux split -h<br>快捷键：Ctrl+b %</li><li>光标切换到上方窗格<br>指令：tmux select-pane -U<br>快捷键：Ctrl+b 方向键上</li><li>光标切换到下方窗格<br>指令：tmux select-pane -D<br>快捷键：Ctrl+b 方向键下</li><li>光标切换到左边窗格<br>指令：tmux select-pane -L<br>快捷键：Ctrl+b 方向键左</li><li>光标钱换到右边窗格<br>指令：tmux select-pane -R<br>快捷键：Ctrl+b 方向键右</li></ol><p><a href="https://zhuanlan.zhihu.com/p/90464490">https://zhuanlan.zhihu.com/p/90464490</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
