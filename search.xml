<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Ubuntu系统解决上不去github问题</title>
      <link href="/2021/10/26/ubuntu-xi-tong-jie-jue-shang-bu-qu-github-wen-ti/"/>
      <url>/2021/10/26/ubuntu-xi-tong-jie-jue-shang-bu-qu-github-wen-ti/</url>
      
        <content type="html"><![CDATA[<h1 id="Ubuntu系统解决上不去github问题"><a href="#Ubuntu系统解决上不去github问题" class="headerlink" title="Ubuntu系统解决上不去github问题"></a>Ubuntu系统解决上不去github问题</h1><p>环境： Ubuntu系统，Firefox浏览器</p><ol><li>找有效的IP地址</li></ol><p>登入网站<a href="https://github.com.ipaddress.com/">https://github.com.ipaddress.com</a>, 复制IP地址备用。</p><ol start="2"><li>修改hosts文件</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/hosts</span><br></pre></td></tr></table></figure><p>打开hosts文件后写入备用的“IP地址+域名”后保存。</p><blockquote><p>140.82.112.3 github.com</p></blockquote><ol start="3"><li>重启DNS</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /etc/init.d/nscd restart</span><br></pre></td></tr></table></figure><p>如果出现nscd命令找不到：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nscd</span><br></pre></td></tr></table></figure><p>成功安装后再重启DNS。</p><p>本文转载自：<a href="https://blog.csdn.net/weixin_38638559/article/details/115005658">https://blog.csdn.net/weixin_38638559/article/details/115005658</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Environment </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Trie树（Prefix Tree）介绍(转)</title>
      <link href="/2021/10/24/trie-shu-prefix-tree-jie-shao/"/>
      <url>/2021/10/24/trie-shu-prefix-tree-jie-shao/</url>
      
        <content type="html"><![CDATA[<h1 id="Trie树（Prefix-Tree）介绍"><a href="#Trie树（Prefix-Tree）介绍" class="headerlink" title="Trie树（Prefix Tree）介绍"></a>Trie树（Prefix Tree）介绍</h1><p>本文用尽量简洁的语言介绍一种树形数据结构 —— Trie树。</p><h2 id="一、什么是Trie树"><a href="#一、什么是Trie树" class="headerlink" title="一、什么是Trie树"></a>一、什么是Trie树</h2><p><strong>Trie树</strong>，又叫<strong>字典树</strong>、<strong>前缀树（Prefix Tree）</strong>、<strong>单词查找树</strong>或<strong>键树</strong>，是一种多叉树结构。如下图：</p><p><img "" class="lazyload placeholder" data-original="/2021/10/24/trie-shu-prefix-tree-jie-shao/Trie.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>上图是一棵Trie树，表示了关键字集合{“a”, “to”, “tea”, “ted”, “ten”, “i”, “in”, “inn”} 。从上图可以归纳出Trie树的基本性质：</p><ol><li>根节点不包含字符，除根节点外的每一个子节点都包含一个字符。</li><li>从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串。</li><li>每个节点的所有子节点包含的字符互不相同。</li></ol><p>通常在实现的时候，会在节点结构中设置一个标志，用来标记该结点处是否构成一个单词（关键字）。</p><p>可以看出，Trie树的关键字一般都是字符串，而且Trie树把每个关键字保存在一条路径上，而不是一个结点中。另外，两个有公共前缀的关键字，在Trie树中前缀部分的路径相同，所以Trie树又叫做<strong>前缀树（Prefix Tree）</strong>。</p><h2 id="二、Trie树的优缺点"><a href="#二、Trie树的优缺点" class="headerlink" title="二、Trie树的优缺点"></a>二、Trie树的优缺点</h2><p>Trie树的核心思想是空间换时间，利用字符串的公共前缀来减少无谓的字符串比较以达到提高查询效率的目的。</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li>插入和查询的效率很高，都为O(m)，其中 m 是待插入/查询的字符串的长度。关于查询，会有人说 hash 表时间复杂度是O(1)不是更快？但是，哈希搜索的效率通常取决于 hash 函数的好坏，若一个坏的 hash 函数导致很多的冲突，效率并不一定比Trie树高。</li><li>Trie树中不同的关键字不会产生冲突。</li><li>Trie树只有在允许一个关键字关联多个值的情况下才有类似hash碰撞发生。</li><li>Trie树不用求 hash 值，对短字符串有更快的速度。通常，求hash值也是需要遍历字符串的。</li><li>Trie树可以对关键字按字典序排序。</li></ol><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol><li>当 hash 函数很好时，Trie树的查找效率会低于哈希搜索。</li><li>空间消耗比较大。</li></ol><h2 id="三、Trie树的应用"><a href="#三、Trie树的应用" class="headerlink" title="三、Trie树的应用"></a>三、Trie树的应用</h2><ol><li>字符串检索</li></ol><p>检索/查询功能是Trie树最原始的功能。思路就是从根节点开始一个一个字符进行比较：</p><ul><li>如果沿路比较，发现不同的字符，则表示该字符串在集合中不存在。</li><li>如果所有的字符全部比较完并且全部相同，还需判断最后一个节点的标志位（标记该节点是否代表一个关键字）。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">trie_node</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">bool</span> isKey;   <span class="comment">// 标记该节点是否代表一个关键字</span></span><br><span class="line">    trie_node *children[<span class="number">26</span>]; <span class="comment">// 各个子节点 </span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ol start="2"><li>词频统计</li></ol><p>Trie树常被搜索引擎系统用于文本词频统计 。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">trie_node</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">int</span> count;   <span class="comment">// 记录该节点代表的单词的个数</span></span><br><span class="line">    trie_node *children[<span class="number">26</span>]; <span class="comment">// 各个子节点 </span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>思路：为了实现词频统计，我们修改了节点结构，用一个整型变量count来计数。对每一个关键字执行插入操作，若已存在，计数加1，若不存在，插入后count置1。</p><p><strong>注意：第一、第二种应用也都可以用 hash table 来做。</strong></p><ol start="3"><li>字符串排序</li></ol><p>Trie树可以对大量字符串按字典序进行排序，思路也很简单：遍历一次所有关键字，将它们全部插入trie树，树的每个结点的所有儿子很显然地按照字母表排序，然后先序遍历输出Trie树中所有关键字即可。</p><ol start="4"><li>前缀匹配</li></ol><p>例如：找出一个字符串集合中所有以ab开头的字符串。我们只需要用所有字符串构造一个trie树，然后输出以a-&gt;b-&gt;开头的路径上的关键字即可。</p><p>trie树前缀匹配常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能。</p><ol start="5"><li>作为其他数据结构和算法的辅助结构</li></ol><p>如后缀树，AC自动机等。</p><h2 id="四、Trie树的实现"><a href="#四、Trie树的实现" class="headerlink" title="四、Trie树的实现"></a>四、Trie树的实现</h2><p>这里为了方便，我们假设所有的关键字都由 a-z 的字母组成。下面是 trie 树的一种典型实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ALPHABET_SIZE 26</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">trie_node</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="comment">/* data */</span></span><br><span class="line"><span class="keyword">int</span> count;<span class="comment">// 记录该节点代表的单词的个数</span></span><br><span class="line">trie_node *children[ALPHABET_SIZE]; <span class="comment">// 各个子节点</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">trie_node *<span class="title">create_trie_node</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">trie_node *pNode = <span class="keyword">new</span> <span class="built_in">trie_node</span>();</span><br><span class="line">pNode-&gt;count = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; ALPHABET_SIZE; i++)</span><br><span class="line">&#123;</span><br><span class="line">pNode-&gt;children[i] = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> pNode;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">trie_insert</span><span class="params">(trie_node *root, <span class="keyword">char</span> *key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">trie_node *node = root;</span><br><span class="line"><span class="keyword">char</span> *p = key;</span><br><span class="line"><span class="keyword">while</span> (*p)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span> (node-&gt;children[*p - <span class="string">&#x27;a&#x27;</span>] == <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">node-&gt;children[*p - <span class="string">&#x27;a&#x27;</span>] = <span class="built_in">create_trie_node</span>();</span><br><span class="line">&#125;</span><br><span class="line">node = node-&gt;children[*p - <span class="string">&#x27;a&#x27;</span>];</span><br><span class="line">++p;</span><br><span class="line">&#125;</span><br><span class="line">node-&gt;count += <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 查询：不存在返回0，存在则返回出现的次数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">trie_search</span><span class="params">(trie_node *root, <span class="keyword">char</span> *key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">trie_node *node = root;</span><br><span class="line"><span class="keyword">char</span> *p = key;</span><br><span class="line"><span class="keyword">while</span> (*p &amp;&amp; node != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">node = node-&gt;children[*p - <span class="string">&#x27;a&#x27;</span>];</span><br><span class="line">++p;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (node == <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">return</span> node-&gt;count;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">// 关键字集合</span></span><br><span class="line"><span class="keyword">char</span> keys[][<span class="number">8</span>] = &#123;<span class="string">&quot;the&quot;</span>, <span class="string">&quot;a&quot;</span>, <span class="string">&quot;there&quot;</span>, <span class="string">&quot;answer&quot;</span>, <span class="string">&quot;any&quot;</span>, <span class="string">&quot;by&quot;</span>, <span class="string">&quot;bye&quot;</span>, <span class="string">&quot;their&quot;</span>&#125;;</span><br><span class="line">trie_node *root = <span class="built_in">create_trie_node</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建trie树</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">8</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">trie_insert</span>(root, keys[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 检索字符串</span></span><br><span class="line"><span class="keyword">char</span> s[][<span class="number">32</span>] = &#123;<span class="string">&quot;Present in trie&quot;</span>, <span class="string">&quot;Not present in trie&quot;</span>&#125;;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%s --- %s\n&quot;</span>, <span class="string">&quot;the&quot;</span>, <span class="built_in">trie_search</span>(root, <span class="string">&quot;the&quot;</span>) &gt; <span class="number">0</span> ? s[<span class="number">0</span>] : s[<span class="number">1</span>]);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%s --- %s\n&quot;</span>, <span class="string">&quot;these&quot;</span>, <span class="built_in">trie_search</span>(root, <span class="string">&quot;these&quot;</span>) &gt; <span class="number">0</span> ? s[<span class="number">0</span>] : s[<span class="number">1</span>]);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%s --- %s\n&quot;</span>, <span class="string">&quot;their&quot;</span>, <span class="built_in">trie_search</span>(root, <span class="string">&quot;their&quot;</span>) &gt; <span class="number">0</span> ? s[<span class="number">0</span>] : s[<span class="number">1</span>]);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%s --- %s\n&quot;</span>, <span class="string">&quot;thaw&quot;</span>, <span class="built_in">trie_search</span>(root, <span class="string">&quot;thaw&quot;</span>) &gt; <span class="number">0</span> ? s[<span class="number">0</span>] : s[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于Trie树，我们一般只实现插入和搜索操作。这段代码可以用来检索单词和统计词频。</p><p>本文转载自：<a href="https://blog.csdn.net/lisonglisonglisong/article/details/45584721">https://blog.csdn.net/lisonglisonglisong/article/details/45584721</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C_C++代码调试——gdb</title>
      <link href="/2021/10/18/c-c-dai-ma-diao-shi-gdb/"/>
      <url>/2021/10/18/c-c-dai-ma-diao-shi-gdb/</url>
      
        <content type="html"><![CDATA[<h2 id="1-开发环境"><a href="#1-开发环境" class="headerlink" title="1. 开发环境"></a>1. 开发环境</h2><p>gcc: 用于开发纯C语言的程序<br>g++: 开发C/C++程序</p><p>二者区别：</p><ul><li><strong>文件后缀名的处理方式不同</strong> gcc会将后缀为.c的文件当作C程序，将后缀为.cpp的文件当作C++程序；g++会将后缀为.c和.cpp的都当作C++程序。gcc和g++都可以用于编译C和C++代码。</li><li><strong>链接方式不同</strong> gcc不会自动链接C++库（比如STL标准库），g++会自动链接C++库。</li><li><strong>预处理宏不同</strong> g++会自动添加一些预处理宏，比如__cplusplus，但是gcc不会。</li></ul><p>通用Makefile</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">EXECUTABLE:= chapter_3</span><br><span class="line">LIBDIR:=</span><br><span class="line">LIBS:=</span><br><span class="line">INCLUDES:=.</span><br><span class="line">SRCDIR:=</span><br><span class="line"></span><br><span class="line">CC:=g++</span><br><span class="line">CFLAGS:= -g -Wall -O0 -static -static-libgcc -static-libstdc++</span><br><span class="line">CPPFLAGS:= <span class="variable">$(CFLAGS)</span></span><br><span class="line">CPPFLAGS+= <span class="variable">$(<span class="built_in">addprefix</span> -I,<span class="variable">$(INCLUDES)</span>)</span></span><br><span class="line">CPPFLAGS+= -I.</span><br><span class="line">CPPFLAGS+= -MMD</span><br><span class="line"></span><br><span class="line"><span class="section">RM-F:= rm -f</span></span><br><span class="line"></span><br><span class="line">SRCS:= <span class="variable">$(<span class="built_in">wildcard</span> *.cpp)</span> <span class="variable">$(<span class="built_in">wildcard</span> $(<span class="built_in">addsuffix</span> /*.cpp, <span class="variable">$(SRCDIR)</span>)</span>)</span><br><span class="line">OBJS:= <span class="variable">$(<span class="built_in">patsubst</span> %.cpp,%.o,<span class="variable">$(SRCS)</span>)</span></span><br><span class="line">DEPS:= <span class="variable">$(<span class="built_in">patsubst</span> %.o,%.d,<span class="variable">$(OBJS)</span>)</span></span><br><span class="line">MISSING_DEPS:= <span class="variable">$(<span class="built_in">filter</span>-out $(<span class="built_in">wildcard</span> <span class="variable">$(DEPS)</span>)</span>,<span class="variable">$(DEPS)</span>)</span><br><span class="line"><span class="comment">#MISSING_DEPS_SOURCES:= $(wildcard $(patsubst %.d,%.cpp,$(MISSING_DEPS)))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">.PHONY : all deps objs clean</span><br><span class="line"><span class="section">all:<span class="variable">$(EXECUTABLE)</span></span></span><br><span class="line"><span class="section">deps:<span class="variable">$(DEPS)</span></span></span><br><span class="line"></span><br><span class="line"><span class="section">objs:<span class="variable">$(OBJS)</span></span></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">@$(RM-F) *.o</span><br><span class="line">@$(RM-F) *.d</span><br><span class="line"></span><br><span class="line"><span class="keyword">ifneq</span> (<span class="variable">$(MISSING_DEPS)</span>,)</span><br><span class="line"><span class="variable">$(MISSING_DEPS)</span>:</span><br><span class="line">@$(RM-F) <span class="variable">$(<span class="built_in">patsubst</span> %.d,%.o,<span class="variable">$@</span>)</span></span><br><span class="line"><span class="keyword">endif</span></span><br><span class="line"><span class="keyword">-include</span> <span class="variable">$(DEPS)</span></span><br><span class="line"><span class="variable">$(EXECUTABLE)</span> : <span class="variable">$(OBJS)</span></span><br><span class="line"><span class="variable">$(CC)</span> -o <span class="variable">$(EXECUTABLE)</span> <span class="variable">$(OBJS)</span> <span class="variable">$(<span class="built_in">addprefix</span> -L,<span class="variable">$(LIBDIR)</span>)</span> <span class="variable">$(<span class="built_in">addprefix</span> -l,<span class="variable">$(LIBS)</span>)</span></span><br></pre></td></tr></table></figure><h2 id="2-gdb简介"><a href="#2-gdb简介" class="headerlink" title="2. gdb简介"></a>2. gdb简介</h2><h3 id="gdb常用功能概览"><a href="#gdb常用功能概览" class="headerlink" title="gdb常用功能概览"></a>gdb常用功能概览</h3><table><thead><tr><th>支持的功能</th><th>描述</th></tr></thead><tbody><tr><td>断点管理</td><td>设置断点、查看断点</td></tr><tr><td>调试执行</td><td>逐语句、逐过程执行</td></tr><tr><td>查看数据</td><td>在调试状态下查看变量数据、内存数据等</td></tr><tr><td>运行时修改变量值</td><td>在调试状态下修改某个变量的值</td></tr><tr><td>显示源代码</td><td>查看源代码信息</td></tr><tr><td>搜索源代码</td><td>对源代码进行查找</td></tr><tr><td>调用堆栈管理</td><td>查看堆栈信息</td></tr><tr><td>线程管理</td><td>调试多线程程序，查看线程信息</td></tr><tr><td>进程管理</td><td>调试多个线程</td></tr><tr><td>崩溃转储（core dump）分析</td><td>分析core dump文件</td></tr><tr><td>调试启动方式</td><td>用不同的方式调试进程，比如加载参数启动、附加到进程等</td></tr></tbody></table><p>测试代码</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">NODE</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">int</span>ID;</span><br><span class="line"><span class="keyword">char</span>Name[<span class="number">40</span>];</span><br><span class="line"><span class="keyword">int</span>age;</span><br><span class="line">NODE*prev;</span><br><span class="line">NODE*next;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">NODE</span> *<span class="title">node_head</span> =</span> <span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">int</span> member_id = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add_member</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">NODE</span> *<span class="title">new_node</span> =</span> (NODE*)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(NODE));</span><br><span class="line">new_node-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">NODE* prev_node = node_head-&gt;prev;</span><br><span class="line"><span class="keyword">if</span>(prev_node)</span><br><span class="line">&#123;</span><br><span class="line">prev_node-&gt;next = new_node;</span><br><span class="line">new_node-&gt;prev = prev_node;</span><br><span class="line">node_head-&gt;prev = new_node;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">node_head-&gt;next = new_node;</span><br><span class="line">new_node-&gt;prev = node_head;</span><br><span class="line">node_head-&gt;prev = new_node;</span><br><span class="line">&#125;</span><br><span class="line">new_node-&gt;ID = member_id++;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;请输入会员姓名，然后按回车\n&quot;</span>);</span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>, new_node-&gt;Name);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;请输入会员年龄，然后按回车\n&quot;</span>);</span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;new_node-&gt;age);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;添加新会员成功\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">node_head = (struct NODE*)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(NODE));</span><br><span class="line">node_head-&gt;next = node_head-&gt;prev = <span class="literal">NULL</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;会员管理系统\n1.录入会员信息\nq:退出\n&quot;</span>);</span><br><span class="line"><span class="keyword">while</span>(<span class="literal">true</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in"><span class="keyword">switch</span></span>(<span class="built_in">getchar</span>())</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">case</span> <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line"><span class="built_in">add_member</span>();</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="string">&#x27;q&#x27;</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>启动调试：gdb <executable file></executable></li><li>运行：r</li><li>添加输入参数：set args admin passward</li><li>附加到进程：gdb attach pid</li><li>在源代码的某一行设置断点：break(b) 文件名:行号</li><li>为函数设置断点：break 函数名</li><li>为继承关系同名函数指定断点：break className:funcName</li><li>使用正则表达式设置函数断点：rbreak(rb) 正则表达式，如：rb test_fun*</li><li>通过偏移量设置断点：b +偏移量 / b -偏移量</li><li>设置条件断点：b 断点 条件，如：b main.cpp:79 if i==900</li><li>在指令地址上设置断点（如果调试程序没有符号信息，而我们又想在某些地方设置断点时，则可以使用在指令地址上设置断点的功能）：b *指令地址<br>先使用无调试符号的方式生成可执行文件（去除编译-g选项）。启动gdb并调试，然后在测试函数cond_fun_test上设置一个断点。因为没有调试符号信息，所以第一步先获得cond_fun_test函数的地址（p cond_fun_test），该命令会获得函数cond_fun_test的函数地址（0x400a0b），然后为地址设置断点(b * 0x400a0b).</li><li>设置临时断点（只命中一次）：tbreak(tb) 断点</li><li>启用/禁用断点：disable/enable 断点编号，如：disable 4-10</li><li>查看断点：info breadpoints; info break; info b; i b</li><li>启用断点一次：enable once 断点编号</li><li>启用断点并删除：enable delete 断点编号</li><li>启用断点并命中N次：enable count 数量 断点编号</li><li>忽略断点前N次命中：ignore 断点编号 次数</li><li>删除所有断点：delete</li><li>删除指定断点：delete 断点编号，如：delete 5 6</li><li>删除指令范围的断点：delete 范围，如：delete 5-7 10-12</li><li>删除指定函数的断点：clear 函数</li><li>删除指定行号的断点：clear 行号</li><li>继续运行并跳过当前断点N次：continue 次数</li><li>继续运行直到当前函数执行完成：finish</li><li>单步执行：step(s)</li><li>逐过程执行：next(n)</li><li>查看当前函数：info args; i args</li><li>查看/修改变量的值：print 变量名；p 变量名；print 变量名=值</li><li>查看结构体/类的值<br>set print null-stop; set print pretty; p *new_node;</li><li>查看数组：set print array on; p 数组名</li><li>自动显示变量的值：display 变量名，如：display {var1, var2, var3}</li><li>查看已经设置的自动显示的变量信息：info display</li><li>取消自动变量的显示：undisplay 编号</li><li>取消所有自动变量的显示：undisplay</li><li>删除所有的自动显示：delete display</li><li>删除部分变量的自动显示：delete display 序号</li><li>暂时禁用自动显示：disable display 序号</li><li>恢复禁用的自动显示：enable display 序号</li><li>显示源代码：list(l)</li><li>设置每次显示代码的行数：set listsize 20</li><li>查看指定函数的代码：list 函数名</li><li>查看内存：x /选项 地址</li><li>查看寄存器<br>info register: 查看所有的整型寄存器<br>info all-register: 查看所有寄存器，包含浮点寄存器<br>info 寄存器名：查看特定寄存器</li><li>查看调用栈<br>backtrace（bt）：栈回溯<br>bt 栈帧数量：查看指令数量的栈帧</li><li>切换栈帧，查看每一个栈帧对应的程序上下文：frame 栈帧号; f 帧地址</li><li>查看当前帧的所有局部变量值：info locals</li><li>查看帧信息：info frame; info frame 栈帧号（不需要切换栈帧）</li><li>线程管理（暂略）</li></ul><p>很多时候，程序只有在一些特定条件下才会出现BUG，比如某个变量的值发生变化时，或者几个因素同时发生变化时。观察点（watchpoint）或者监视点可以用来发现或者定位该类型的BUG。可以设置为监控一个变量或者一个表达式的值，当这个值或者表达式的值发生变化时程序会暂停，而不需要提前在某些地方设置断点。<br>在某些系统中，gdb是以软观察点的方式来实现的。通过单步执行程序的方式来监控变量的值是否发生改变，每执行一步就会检查变量是否发生变化。这种做法会比正常执行慢上百倍，但有时为了找到不容易发现的BUG，这是值得的。<br>而在有些系统中（比如LINUX），gdb是以硬件方式实现观察点功能，这并不会降低程序运行的速度。</p><ul><li>设置观察点：watch 变量或表达式，如：watch count=5</li><li>读取观察点：rwatch 变量或表达式。当变量或表达式被读取时，程序会发生中断</li><li>读写观察点：awatch 变量或表达式。无论这个变量是被读取还是被写入，程序都会发生中断</li><li>查看所有观察点：info watchpoints</li><li>禁用/启用/删除观察点：disable/enable/delete 观察点编号</li></ul><p>捕获点（catchpoint）指的是程序在发生某事件时，gdb能够捕获这些事件并使程序停止执行。该功能可以支持很多时间，比如C++异常、载入动态库等。语法如下：<br>catch 事件<br>可以捕获的事件如下所示：</p><ul><li>throw: 在C++代码中执行throw语句时程序会中断</li><li>catch: 当代码中执行到catch语句块时会中断，也就是说代码捕获异常时会中断</li><li>exec、fork、vfork: 调用这些系统函数时会中断，主要适用于HP-UNIX</li><li>load/unload: 加载或者卸载动态库时</li><li>代码搜索<br>search 正则表达式<br>forward-search 正则表达式<br>reverse-search 正则表达式</li><li>查看变量类型：ptype 可选参数 变量或类型</li></ul><p>在调试过程中，很多时候我们希望代码能够被反复执行，因为我们希望能够多次查看问题，以便更加仔细地观察问题。有时候又希望直接跳过某些代码，比如环境的问题、不能满足某些条件、部分代码没有意义或者会执行失败等。</p><ul><li>跳转执行：jump 位置</li></ul><p>窗口管理：gdb可以同时显示几个窗口。</p><ul><li>命令窗口：gdb命令输入和结果输出的窗口，该窗口始终是可见的。</li><li>源代码窗口：显示程序源代码的窗口，会随着代码的执行自动显示代码对应的行。</li><li>汇编窗口：汇编窗口也会随着代码的执行而变化，显示代码对应的汇编代码行。</li><li>寄存器窗口：显示寄存器的值。</li></ul><p>窗口layout管理命令：</p><ul><li>显示下一个窗口：layout next</li><li>显示前一个窗口：layout prev</li><li>只显示源代码窗口：layout src</li><li>只显示汇编窗口：layout asm</li><li>显示源代码和汇编窗口：layout split</li><li>显示寄存器窗口，域源代码以及汇编窗口一起显示：layout regs</li><li>设置窗口为活动窗口，以便能够响应上下滚动键：focus next | prev | src | asm | regs | split</li><li>刷新屏幕：refresh</li><li>更新源代码窗口：update</li><li>关闭除命令窗口之外的窗口：tui disable</li></ul><p>调用shell命令：shell 命令；!命令</p><p>assert宏使用（暂略）</p><p>内容来源于《C/C++代码调试的艺术》，此处只涉及gdb基本功能。此书还涉及多线程死锁调试、调试动态库、内存检查、远程调试、转储文件调试分析、发行版调试、调试高级话题等章节。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>标准单元库的理解</title>
      <link href="/2021/10/14/biao-zhun-dan-yuan-ku-de-li-jie/"/>
      <url>/2021/10/14/biao-zhun-dan-yuan-ku-de-li-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="标准单元库的理解"><a href="#标准单元库的理解" class="headerlink" title="标准单元库的理解"></a>标准单元库的理解</h1><p>对umc28nm standard cell library，做一些阅读理解，很多数据资料来源。</p><p><img "" class="lazyload placeholder" data-original="/2021/10/14/biao-zhun-dan-yuan-ku-de-li-jie/1.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="HVT-SVT-LVT的意思？"><a href="#HVT-SVT-LVT的意思？" class="headerlink" title="HVT/SVT/LVT的意思？"></a>HVT/SVT/LVT的意思？</h2><p>high Vt<br>Standard Vt（也有称为Regular Vt，即RVT)<br>low Vt<br>阈值电压越低，因为饱和电流变小，所以速度性能越高；但是因为漏电流会变大，因此功耗会变差。</p><h2 id="PVT"><a href="#PVT" class="headerlink" title="PVT"></a>PVT</h2><p>process、voltage、temperature<br>technology是28nm工艺；process是制造流程，一般分为FF/TT/SS。两者的内容应该包括high-speed/high-density/HVT/SVT/LVT/multi-channel等信息。</p><h2 id="multi-channel-library"><a href="#multi-channel-library" class="headerlink" title="multi-channel library"></a>multi-channel library</h2><p>对应不同的gate-length，即沟道长度。一般比工艺28nm要大一些。<br>例如，umc28nm的SVTmin 相对 SVTmax，性能增加20%，静态功耗增加80%。</p><h2 id="7T-9T-12T"><a href="#7T-9T-12T" class="headerlink" title="7T/9T/12T"></a>7T/9T/12T</h2><p>分别对应ultra-high-density（for lowest power in SOC blocks）、high-density（for highest density in GPU blocks）、high-speed（for highest performance in CPU blocks）。<br>T，代表track；是单元库的版图规则；作为一个计量单位。<br>标准单元库的单元高度，基本都是固定的，方便版图的布局；高度，通常以track作为计量单位，即用M2 track pitch来表示。<br>track和pitch的区别？<br>对于前端设计人员来说，不必深入。只要看懂databook就可以了。个人当前理解track和pitch，就是一样的；pitch=minSpacing+minWidth。</p><p>grid是单元库里，与工艺制造精度相关的名称。一般pin都放置在grid上，这也不需要多加深入，就认为是工艺在版图上的最小精度就可以了。</p><p><img "" class="lazyload placeholder" data-original="/2021/10/14/biao-zhun-dan-yuan-ku-de-li-jie/2.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="don’t-use单元列表"><a href="#don’t-use单元列表" class="headerlink" title="don’t use单元列表"></a>don’t use单元列表</h2><p>综合不允许使用的，一般是驱动能力太强或者太弱的标准单元不用；还有其它为了性能、功耗、面积衡量的单元。</p><h2 id="推荐的单元库选择方法"><a href="#推荐的单元库选择方法" class="headerlink" title="推荐的单元库选择方法"></a>推荐的单元库选择方法</h2><p><img "" class="lazyload placeholder" data-original="/2021/10/14/biao-zhun-dan-yuan-ku-de-li-jie/3.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="HLP和HPC的区别"><a href="#HLP和HPC的区别" class="headerlink" title="HLP和HPC的区别"></a>HLP和HPC的区别</h2><p>HLP，high performance low power；这个应该是主流？<br>HPC，high performace compact。<br>ps：28nmHLP的core电压，是1.05V；HPC的core电压，则是0.9V。<br>举例，以CA53来看，HPC相对HLP，性能增加32%；面积减小5%。</p><p><img "" class="lazyload placeholder" data-original="/2021/10/14/biao-zhun-dan-yuan-ku-de-li-jie/4.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>另外，发现HLP的版图，跟HPC不一样。</p><p><img "" class="lazyload placeholder" data-original="/2021/10/14/biao-zhun-dan-yuan-ku-de-li-jie/5.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="SOC系统需要的单元库划分"><a href="#SOC系统需要的单元库划分" class="headerlink" title="SOC系统需要的单元库划分"></a>SOC系统需要的单元库划分</h2><p><img "" class="lazyload placeholder" data-original="/2021/10/14/biao-zhun-dan-yuan-ku-de-li-jie/6.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="推荐的单元库优化方法"><a href="#推荐的单元库优化方法" class="headerlink" title="推荐的单元库优化方法"></a>推荐的单元库优化方法</h2><p><img "" class="lazyload placeholder" data-original="/2021/10/14/biao-zhun-dan-yuan-ku-de-li-jie/7.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/10/14/biao-zhun-dan-yuan-ku-de-li-jie/8.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>QEI: Query Acceleration Can be Generic and Efficient in the Cloud</title>
      <link href="/2021/09/15/qei-query-acceleration-can-be-generic-and-efficient-in-the-cloud/"/>
      <url>/2021/09/15/qei-query-acceleration-can-be-generic-and-efficient-in-the-cloud/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>VIM和shell的切换</title>
      <link href="/2021/09/14/vim-he-shell-de-qie-huan/"/>
      <url>/2021/09/14/vim-he-shell-de-qie-huan/</url>
      
        <content type="html"><![CDATA[<h1 id="VIM和shell的切换"><a href="#VIM和shell的切换" class="headerlink" title="VIM和shell的切换"></a>VIM和shell的切换</h1><p>解决vim编辑文件时需要执行系统命令的问题，存在三种方式：</p><ol><li>ctrl+Z将vim挂起，执行完shell命令之后使用fg将vim返回前台执行。多任务挂起时，先使用jobs参看vim id，然后使用fg %id恢复任务；</li><li>在vim normal模式下使用！{shell cmd}执行shell命令，不需要输入{}；</li><li>在vim normal模式下使用:shell命令重启一个新的shell，执行完命令后关闭shell返回vim。</li></ol><h2 id="保存vim会话"><a href="#保存vim会话" class="headerlink" title="保存vim会话"></a>保存vim会话</h2><p>保存当前vim编辑状态，以便下次编辑时恢复文件列表、窗口布局、全局变量、选项以及其他信息。</p><ol><li>创建一个会话文件，在vim normal模式下输入:mksession vimbook.vim</li><li>在vim normal模式下还原保存的会话输入:source vimbook.vim</li><li>在启动vim时直接恢复会话：vim -S vimbook.vim</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://blog.csdn.net/u014703817/article/details/45741397">https://blog.csdn.net/u014703817/article/details/45741397</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>CAPE: A Content-Addressable Processing Engine</title>
      <link href="/2021/09/14/cape-a-content-addressable-processing-engine/"/>
      <url>/2021/09/14/cape-a-content-addressable-processing-engine/</url>
      
        <content type="html"><![CDATA[<h1 id="CAPE-A-Content-Addressable-Processing-Engine"><a href="#CAPE-A-Content-Addressable-Processing-Engine" class="headerlink" title="CAPE: A Content-Addressable Processing Engine"></a>CAPE: A Content-Addressable Processing Engine</h1><!-- TOC --><ul><li><a href="#cape-a-content-addressable-processing-engine">CAPE: A Content-Addressable Processing Engine</a><ul><li><a href="#introduction">Introduction</a></li><li><a href="#%E5%85%B3%E8%81%94%E8%AE%A1%E7%AE%97associative-computing">关联计算（Associative Computing）</a></li><li><a href="#overview-of-cape">Overview of CAPE</a></li><li><a href="#cape%E7%9A%84csb">CAPE的CSB</a><ul><li><a href="#cell%E5%92%8Csubarray">Cell和Subarray</a></li><li><a href="#data-layout">Data Layout</a></li><li><a href="#%E5%A4%96%E5%9B%B4%E9%80%BB%E8%BE%91">外围逻辑</a></li><li><a href="#%E4%BC%A0%E8%BE%93%E9%93%BE">传输链</a></li></ul></li><li><a href="#%E6%94%AF%E6%8C%81%E5%BD%92%E7%BA%A6%E8%BF%90%E7%AE%97">支持归约运算</a></li><li><a href="#cape%E6%9E%B6%E6%9E%84">CAPE架构</a><ul><li><a href="#isa">ISA</a></li><li><a href="#cape%E5%BE%AE%E6%9E%B6%E6%9E%84">CAPE微架构</a></li><li><a href="#%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86">异常处理</a></li><li><a href="#%E5%90%91%E9%87%8F%E6%8E%A7%E5%88%B6%E5%8D%95%E5%85%83vector-control-unit">向量控制单元（Vector Control Unit）</a></li><li><a href="#vmu">VMU</a></li><li><a href="#%E5%8F%AF%E9%87%8D%E6%9E%84%E6%B4%BB%E5%8A%A8%E7%AA%97%E5%8F%A3">可重构活动窗口</a></li><li><a href="#cape-%E7%9A%84%E7%9F%A2%E9%87%8F%E5%8C%96">CAPE 的矢量化</a></li></ul></li><li><a href="#evaluation">Evaluation</a><ul><li><a href="#%E5%BE%AE%E6%93%8D%E4%BD%9C%E5%BB%BA%E6%A8%A1">微操作建模</a></li><li><a href="#%E6%8C%87%E4%BB%A4%E5%BB%BA%E6%A8%A1">指令建模</a></li><li><a href="#%E7%B3%BB%E7%BB%9F%E5%BB%BA%E6%A8%A1">系统建模</a></li></ul></li><li><a href="#reference">Reference</a></li></ul></li></ul><!-- /TOC --><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>起源于上世纪七十年代的内容可寻址并行处理器(Content-addressable parallel processor, CAPP)设计扩展了CAM的功能，使其能够并行更新多行。通过对此类搜索/更新操作进行排序，CAPP 设计还可以以大规模并行和双串行方式执行各种算术和逻辑运算（称为关联算法）。<br>最近的一些研究也提倡在现代微架构中利用CAPP。但是现在提出的解决方案存在以下问题：</p><ul><li>包含新兴存储技术；</li><li>使用昂贵的12T存储比特单元；</li><li>需要低级编程，或具有自定义编译流程的限制性编程语言。</li></ul><p>本文的思路：探究经典CAPP背后的理念能否用于构建一个完全基于CMOS的通用架构的微处理器，能够达到多倍加速的同时保持高度可编程性。</p><p>本文的工作：对内容可寻址处理引擎 (Content-Addressable Processing Engine, CAPE) 进行了全栈设计，该引擎由密集的push rule 6T SRAM阵列构建而成。CAPE可使用带有标准向量扩展的RISC-V ISA进行编程。</p><p>本文的贡献：</p><ol><li>基于CMOS实现密集6T SRAM阵列的具有关联计算能力的引擎。</li><li>这些 SRAM 阵列上的优化数据布局可最大化操作数局部性。</li><li>可以对数以万计的向量元素执行数据并行计算的微架构组织。</li><li>一个系统架构，能够执行有效的数据传输，以保持其固有的大规模并行计算能力的优势。</li><li>标准 RISC-V ISA 到此微体系结构的映射，具有通用性、高度可编程性以及与现有编译流程的兼容性。</li></ol><h2 id="关联计算（Associative-Computing）"><a href="#关联计算（Associative-Computing）" class="headerlink" title="关联计算（Associative Computing）"></a>关联计算（Associative Computing）</h2><p>关联计算引擎：1）以向量形式存储数据，2）可以并行（搜索）将键与所有向量元素进行比较，3）可以使用新值（更新）批量更新所有匹配元素。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/14/cape-a-content-addressable-processing-engine/2021914-05950.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>以对一个向量所有元素进行增加1操作，如图1所示，关联计算引擎首先将所有向量元素的最低有效位加 1 并记住任何进位。 然后，对于每个元素，它会将相应的进位添加到下一位；继续这一过程。 当然，关联计算引擎本身不能“添加”位。相反，它通过一系列搜索-更新对实现按位加法，这些对基本上遵循半加法器的真值表，一次一个位组合：1) 搜索第 i 位为 0 的向量元素，并为其运行进位元素（存储的额外位）为1，然后将匹配元素的第 i 位批量更新为 1，并将其运行进位改为 0。 2）搜索第 i 位为 1 且该元素的运行进位也是 1 的向量元素 ，然后将匹配元素的第 i 位批量更新为 0，并将运行的进位更新为 1。<br>以图一为例，对向量a={0,1,2}中所有元素进行加1操作，得到a={1,2,3}。操作流程如下：</p><ol><li>操作数映射到计算引擎中，如左上角所示，数据按行进行存储，每一行存储的值为$[c_i, a_i]$，因此，每一列对应的数据的同一比特位。开始$c_0, c_1, c_2$都初始化为1，即将加1的操作数存放到进位中。</li><li>第一次搜索-更新：更新最低位0-&gt;1翻转情况。从bit-wise加法的真值表可以看出$a_i$值只会在一种情况下($c_i=1, a_i=0$)发生0-&gt;1翻转，因此通过CAM搜索$1X0$，匹配的行对应的$a_0$翻转为1。同时根据真值表，对应的进位也需要更新为0，如图1最上面的第1行和第3行数据。</li><li>第二次搜索-更新：更新最低位1-&gt;0翻转情况。从bit-wise加法的真值表可以看出$a_i$值只会在一种情况下($c_i=1, a_i=1$)发生1-&gt;0翻转，因此通过CAM搜索$1X1$，匹配的行对应的$a_0$翻转为0。同时根据真值表，对应的进位也保持为1，如图1中间图片的第2行数据。</li><li>继续对高比特数据逐比特重复第2，3步操作，区别在于进位不需要初始化，直接利用低一比特的进位计算结果，如图1最下行图片所示，图中由于进位全为0，因此不需要继续计算下去，任务结束。</li></ol><p>从上面介绍的实例来看，关联计算存在三个开销：</p><ol><li>每行需要维持2 bits数据，分别作为进位和匹配tag，但是可以被所有bit复用；</li><li>每次只能搜索2 bits数据，进位$c$和当前计算比特位$a_i$，因此需要屏蔽其他比特位；(note: 通过一般的TCAM屏蔽需要改写CAM中存储的数据，这时候<a href="#refer-anchor-1"><sup>1</sup></a>的工作就特别合适了。)</li><li>实现增量操作指令的操作序列需要存储在某个位置。</li></ol><h2 id="Overview-of-CAPE"><a href="#Overview-of-CAPE" class="headerlink" title="Overview of CAPE"></a>Overview of CAPE</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/14/cape-a-content-addressable-processing-engine/2021915-02524.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>CAPE的结构如图2所示，由四部分组成：Control Processor，VMU，VCU和CSB。CP是一个小的RISC-V指令集顺序核，其执行标量指令，并将向量指令卸载到CSB执行。其中Load /Store向量指令通过VMU链接到CSB，其他的向量指令则通过VCU将产生微代码序列发送到CSB执行。</p><p>在向量指令执行时，接下来的标量指令可以继续发射核执行，但是不会提交指令，随后的向量指令则会等待向量指令提交。</p><h2 id="CAPE的CSB"><a href="#CAPE的CSB" class="headerlink" title="CAPE的CSB"></a>CAPE的CSB</h2><h3 id="Cell和Subarray"><a href="#Cell和Subarray" class="headerlink" title="Cell和Subarray"></a>Cell和Subarray</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/14/cape-a-content-addressable-processing-engine/2021915-02543.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Cell和Subarray以及读/写/搜索过程参考<a href="#refer-anchor-1"><sup>1</sup></a>。</p><h3 id="Data-Layout"><a href="#Data-Layout" class="headerlink" title="Data Layout"></a>Data Layout</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/14/cape-a-content-addressable-processing-engine/2021915-02616.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>CSB的数据结构如图4所示，左上角是单个向量存储到寄存器里面的映射方式，每个32-bit数据占据寄存器的一行。CSB由一个个32x32的子阵列组成，每个子阵列保存向量元素的同一比特位。如图4左下角图片所示，$V0_i$表示向量$V0$的第i比特，向量中的所有元素的第ibite都存在标红的一行中，而进位c的第i比特则存在同一subarray的其他行。从右下脚的图中可以看的更清楚，多个矢量$V2$，$V3$的同一bit保存在同一行的subarray中，不同bit保存在不同行的subarray中。</p><h3 id="外围逻辑"><a href="#外围逻辑" class="headerlink" title="外围逻辑"></a>外围逻辑</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/14/cape-a-content-addressable-processing-engine/2021915-02629.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h3 id="传输链"><a href="#传输链" class="headerlink" title="传输链"></a>传输链</h3><p>通常，位串行指令将信息从一个步骤传送到下一个步骤。 因为我们对向量元素进行位切片，所以我们需要支持跨连续子阵列垂直传输此类元数据，并且一列的子阵列因此形成传播链。 通常，一个链将具有与向量元素的位宽一样多的子数组。 为了支持这一点，我们添加了逻辑以选择性地允许子数组 i 的标记位选择子数组 i+1 中应该更新的列。 这就是在图 1 的增量示例中，搜索中生成的标记位可用于为子数组 i（更新 v0i）和子数组 i+1（更新 ci+1）选择要更新的向量元素 ) 的每个链。</p><h2 id="支持归约运算"><a href="#支持归约运算" class="headerlink" title="支持归约运算"></a>支持归约运算</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/14/cape-a-content-addressable-processing-engine/2021915-135418.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>归约操作如图6所示，从最高比特位计算到最低比特位。首先搜索当前比特位为1的个数，然后对Match的tag进行pop count操作得到该比特位为1的个数，然后进行与之前得到的结果乘以2的结果累加。逻辑相当简单，就是shift-add求和。</p><h2 id="CAPE架构"><a href="#CAPE架构" class="headerlink" title="CAPE架构"></a>CAPE架构</h2><h3 id="ISA"><a href="#ISA" class="headerlink" title="ISA"></a>ISA</h3><p>RISC-V 矢量名称通过 VCU 透明地映射到适当的 CAPE 位置； 程序员永远不会将 CAPE 的 CSB 视为可寻址存储器（尽管 CAPE 可以被配置为芯片仅用作存储器的块，我们将在第 VII 节中简要介绍）。<br>RISC-V 的 VLA 支持，其中矢量长度是可编程的，在 CAPE 中很容易支持，只需屏蔽未使用的 CSB 列或关闭整个链。 VLA 支持提供的灵活性实际上是 CAPE 能够适应具有不同数据级并行性的各种应用程序的关键。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/14/cape-a-content-addressable-processing-engine/2021915-135448.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>表 I 显示了 CAPE 支持的 RISC-V 指令的说明性子集的相关指标。</p><h3 id="CAPE微架构"><a href="#CAPE微架构" class="headerlink" title="CAPE微架构"></a>CAPE微架构</h3><p>在之前介绍过，由四部分组成。</p><h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p>向量指令仅在控制处理器流水线结束提交时才发布到 VCU/VMU，因此它们不会由于先前指令触发的异常而回滚。 至于由向量指令本身触发的异常，a) 加载/存储操作可以在发生页面错误的索引处重新启动 和 b) 算术/逻辑异常可能会被不精确地处理，与向量指令的 ISA 规范一致。</p><h3 id="向量控制单元（Vector-Control-Unit）"><a href="#向量控制单元（Vector-Control-Unit）" class="headerlink" title="向量控制单元（Vector Control Unit）"></a>向量控制单元（Vector Control Unit）</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/14/cape-a-content-addressable-processing-engine/2021915-135502.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>矢量控制单元 (VCU) 将每条矢量指令分解为一系列命令。 命令包括四个 CAPE 微操作（读取、写入、搜索和更新），以及重新配置命令（例如，重新配置向量长度）。 我们实现了 VCU 的分布式设计，由多个链控制器构建，跨链组共享。如图7左图所示。</p><ul><li>全局控制单元维护一个可编程真值表存储器和一组控制状态寄存器 (CSR)。 当 VCU 接收到向量指令时，它会将相应关联算法的真值表数据传播到每个链控制器，后者将其存储在一个小型专用 CAM（全局命令分布）中。</li><li>链控制器然后将命令分发到链中的适当子阵列（本地命令分发）。 链控制器（图 7，中间）由一个定序器、一个真值表存储器 (TTM) 和一个真值表解码器组成。 每个 TTM 条目对应一个 search-updatereduce 数据包，有效编码以仅存储操作中涉及的位的值。 TTM 中的条目使用标准格式来表示任何关联算法的真值表。 每个 TTM 条目的四个附加位（有效位和累加器启用）用于指示搜索（带/不带累加）或更新操作是否处于活动状态，以及是否将使用归约逻辑。</li><li>定序器实现了一个简单的 FSM，具有五个状态（图 7，顶部中心）：(1) 空闲，(2) 读取 TTM，(3) 为搜索生成比较和掩码，(4) 为更新生成数据和掩码，以及 ( 5）归约。 控制器默认处于空闲状态。 一旦控制处理器发送一个新请求，定序器就会转换到状态 (2)。 控制器跟踪一个计数器 µpc，它有助于导航 TTM 中的条目，另一个计数器位跟踪我们正在操作的位，并为链控制器生成适当的 idx 和子阵列选择信号。 计数器被适当地初始化：μpc=0 每个真值表 (TT) 循环，并且位被设置为 MSB 或 LSB，取决于操作，给定操作数大小。</li><li>真值表解码器（图 7，右上角）根据存储在 TTM 中的值生成搜索和更新数据以及掩码，方法是将它们移位适当的数量，然后对它们进行 OR 运算以生成供子阵列行使用的单个数字字 和列驱动程序。 这种方法类似于垂直微码方案。 在 32 位配置中，链控制器通过链命令总线分发 143 位命令，如图 7 所示。</li></ul><h3 id="VMU"><a href="#VMU" class="headerlink" title="VMU"></a>VMU</h3><h3 id="可重构活动窗口"><a href="#可重构活动窗口" class="headerlink" title="可重构活动窗口"></a>可重构活动窗口</h3><h3 id="CAPE-的矢量化"><a href="#CAPE-的矢量化" class="headerlink" title="CAPE 的矢量化"></a>CAPE 的矢量化</h3><h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>评估分为三个层次：微操作延迟/能耗评估，指令电路级延迟/能耗评估，系统评估</p><h3 id="微操作建模"><a href="#微操作建模" class="headerlink" title="微操作建模"></a>微操作建模</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/14/cape-a-content-addressable-processing-engine/2021915-135518.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>PDK: ASAP 7nm PDK (已经下载到EDA路径下)<br>综合工具：DC<br>自动布局布线工具：Innovus</p><h3 id="指令建模"><a href="#指令建模" class="headerlink" title="指令建模"></a>指令建模</h3><p>CAPE指令的延迟和能耗建模结果如表II所示。</p><h3 id="系统建模"><a href="#系统建模" class="headerlink" title="系统建模"></a>系统建模</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/14/cape-a-content-addressable-processing-engine/2021915-135536.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>系统仿真器采用的是gem5，CAPE是基于RISC-V RV64G MinorCPU(双发射，顺序，五级流水线)改动。</p><p>面积评估是根据Skylake tile进行推算的，从14 nm到7 nm面积，缩放因子设置为1.8。同时删除AVX和浮点支持。</p><p><strong>Microbenchmarks</strong></p><p><img "" class="lazyload placeholder" data-original="/2021/09/14/cape-a-content-addressable-processing-engine/2021915-135555.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>作者使用8个microbenchmarks评估了CAPE的性能，每个benchmark加载一个或两个向量，每个向量包含524,288个32-bit数。如图9所示，展示了不同CSB容量（MAX_VL）对CAPE性能的影响。</p><p><strong>可扩展性研究</strong></p><p>对于访存密集的benchmarks，如vld和vst，CAPE通过高效的从DRAM中移动大块数据到CSB，实现6.6~10.5倍加速。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><div id="refer-anchor-1"></div>1. Jeloka S, Akesh N B, Sylvester D, et al. A 28 nm configurable memory (TCAM/BCAM/SRAM) using push-rule 6T bit cell enabling logic-in-memory[J]. IEEE Journal of Solid-State Circuits, 2016, 51(4): 1009-1021.]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leveraging Caches to Accelerate Hash Tables and Memoization</title>
      <link href="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/"/>
      <url>/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/</url>
      
        <content type="html"><![CDATA[<h1 id="Leveraging-Caches-to-Accelerate-Hash-Tables-and-Memoization"><a href="#Leveraging-Caches-to-Accelerate-Hash-Tables-and-Memoization" class="headerlink" title="Leveraging Caches to Accelerate Hash Tables and Memoization"></a>Leveraging Caches to Accelerate Hash Tables and Memoization</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>哈希表在传统架构中存在两个关键的低效率问题：</p><ol><li>核心利用率低：每个哈希表操作都由一长串指令组成，用于计算哈希值、对键和值的内存访问以及比较。这些指令包括难以预测的、依赖于数据的分支，这些分支会增加浪费的周期，并导致限制指令级并行性的长延迟缓存未命中。</li><li>空间局部性低：为了减少映射冲突，散列将键值对均匀地分布在散列表的分配内存中。当键值对混合重用时，这会导致空间局部性较差，因为经常访问的对的同一行邻居很少被访问。这浪费了很大一部分缓存容量。</li></ol><p>本文思路：使用简单的 HTA 功能单元，这些指令比传统的哈希表操作消耗更少的流水线资源，从而可以利用更多的指令级和内存级并行性。 HTA 加速了大多数哈希表操作，将极少数情况留给了允许溢出到传统软件哈希表的软件路径。</p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>哈希表是无序的关联容器。它们保存键值对并支持三种操作：查找以检索与特定键关联的数据，以及插入和删除以添加或删除键值对。哈希表以分摊的常数时间复杂度执行这些操作。它们在许多领域被大量使用，如数据库、键值存储、网络、基因组学和memoization。</p><p>哈希表通常使用数组来实现，以保存键值对，键值对由键的哈希索引。当多个键值对映射到同一个数组索引时，就会发生冲突。随着阵列利用率的增加，冲突变得越来越普遍。为了支持高利用率，哈希表包括冲突解决策略，例如探测额外的位置，并在其利用率达到某个阈值时调整表的大小。</p><p>实现在几个方面有所不同，例如散列函数选择、冲突解决和调整大小机制。简单的散列函数，如XOR折叠和位选择速度快，但容易出现热点，而更复杂的散列函数，如通用散列更均匀地分布键值对，但会产生更多的开销。基本的冲突解决策略包括链接和开放寻址。发生冲突时，链接会将新的键值对附加到现有键值对，形成一个链表，而开放寻址会探测哈希表中的其他位置。调整大小可以一次性或逐步执行。</p><p>有多种具有不同算法权衡的哈希表实现，例如，为了查找效率而交易空间效率。例如，Cuckoo哈希以增加平均情况查找复杂性为代价提高了空间效率和最坏情况查找性能。它的变体进一步侧重于减少每次查找的内存访问或提高局部性。</p><h3 id="哈希表性能分析"><a href="#哈希表性能分析" class="headerlink" title="哈希表性能分析"></a>哈希表性能分析</h3><ol><li><p>低核心利用率</p><p> <img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021911-232837.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p> 图1展示了基于三种不同技术：libstdc++’s C++11 unordered_map，Google’s dense_hash_map以及FLAT-HTA实现哈希表的搜索，更新和插入操作的性能评估。对于搜索和更新，哈希表初始化为一百万条随机生成的键值对，容量为64MB。对于插入操作，哈希表初始化为空，然后插入随机生成的一百万条键值对。<br> 图1使用了一种非常有意思的分析方法，将执行时间划分成核心执行不同活动的周期数。这几部分分别为：</p><ul><li>发射提交指令；</li><li>执行错误路径指令（分支预测错误）；</li><li>前端（取指或译码）导致的流水线暂停；</li><li>后端事件（功能单元，L1缓存，L2缓存或主存）导致的流水线暂停。</li></ul> <!-- 从图1中可以看出，哈希表存在两大资源开销：难以预测的分支和未充分利用的后端并行性。 --> <!-- 第一点难以预测的分支很容易理解，哈希表操作需要执行很多分支来处理hash碰撞。对于第二点，每个哈希表操作都采用一系列指令，包括哈希计算、内存访问、比较和分支。这些指令占用数十到数百个微操作(µop)插槽，与重新排序缓冲区大小相当。如图1所示，这显着限制了内存级并行性：大多数后端停顿都用于等待主内存响应，并且重新排序缓冲区没有足够的资源来重叠多次未命中。 --><p> 从图一可以看出两点：</p><ul><li>哈希表探测中难以预测的分支会增加许多周期，高达74%的周期花费在错误的路径执行上[^1]；</li><li>哈希表操作没有充分利用指令级并行和存储级并行[^2]。</li></ul></li></ol><p>Flat-HTA有效地减少了这些开销，并将性能提高了2.5倍。首先，它的设计避免了难以预测的分支，减少甚至消除了错误路径的执行。其次，每个哈希表操作占用更少的微操作槽，提高了内存级并行性并将后端停顿减少了多达5.6倍。</p><ol start="2"><li><p>空间局部性低</p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021911-232908.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图2人为的将hash表存储空间分配从64MB增加到256MB，这样hash碰撞的几率大大降低，基本上可以认为每次只需要访问一次就可以获取key对应的value，因此不在存在低核心利用率的问题。从图2中我们可以看出，消除了分支预测的问题，FLAT-HTA只比最好的软件实现性能提升1%，其花费80%的时间用于等待LLC相应。而HIERARCHICAL-HTA将频繁访问的键值对密集地打包在较低级别的缓存中，从而减少未命中，性能相比于FLAT-HTA提升84%。</p></li></ol><h2 id="HTA软硬件接口"><a href="#HTA软硬件接口" class="headerlink" title="HTA软硬件接口"></a>HTA软硬件接口</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021911-232934.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>HTA技术使用硬件处理大多数的Hash表访问，而将很少出现的状况，如表溢出和table resizing，留给软件进行处理。</p><ol><li><p>HTA 采用了一种哈希表格式，利用缓存的特性来快速查找和更新。 HTA 将哈希表存储在可缓存内存中。 这避免了现有硬件技术使用的专用硬件高速缓存的大量成本。==(其实是对每一个hash entry进行了连续内存空间的存储，而hash碰撞的问题则是利用软件来解决，如果某一entry对应的键值对超出了分配的连续空间，则用基于软件的非规律访存数据结构(链表)来解决。)==</p></li><li><p>HTA 为查找和更新引入了哈希表指令，这些指令适合快速简单的实现。 软件哈希表查找使用多条指令和难以预测的分支，而 HTA 哈希表查找是通过具有分支语义的单个指令完成的。 内核现有的分支预测器可以准确预测查找的结果（已解决或未解决），从而避免大多数控制流停顿。</p></li></ol><p>两种实现方式FLAT-HTA和HIERARCHICAL-HTA如图3所示。</p><p>Flat-HTA跨HTA表和软件哈希表存储键值对。HTA表存储在可缓存内存中，并且可能分布在多个缓存或主内存中。HTA表的大小可以容纳大多数键值对，软件哈希表用作受害者缓存，以保存溢出HTA表的对。</p><p>Hierarchical-HTA通过让缓存级别保留单独的键值对而不是Cache line，来扩展Flat-HTA。具体来说，它们将HTA表的键值对缓存在称为HTA存储的小型、特定于缓存级别的区域中。溢出HTA存储的对由下一个级别处理。这提高了中间缓存级别的空间局部性，因为它们的行充满了经常访问的对。然而，Hierarchical-HTA并没有改善最后一级缓存的空间局部性（这样做会使与主内存的接口复杂化），因此它相对于Flat-HTA的优势不大。图3b显示了一个Hierarchical-HTA的例子，其中一个HTA stash固定到L1。==(FLAT-HTA只是将非规律访存转换成规律性访存，而Hierarchical-HTA则是进一步缓存频繁访问的键值对，这样连规律性访存和对比都减少了。但是从图1可以看出，影响hash操作性能的瓶颈在于前端分支导致的stall，低空间局部性占总体时间很低，只有在第一个问题解决之后，第二个问题带来的影响才会显现出来，成为限制hash操作性能的瓶颈。因此第一种方案对现有加速效果比较明显，以现有方案为参考，则第二种方案于第一种方案相差不大。但是第二种方案相比于第一种方案的相对收益还是很高的。)==</p><h3 id="HTA哈希表格式"><a href="#HTA哈希表格式" class="headerlink" title="HTA哈希表格式"></a>HTA哈希表格式</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021911-232947.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>HTA的哈希表存储格式如图4所示，每一个entry对应的key-value pairs存储到同一行cache line中，溢出的部分通过软件维护。首先对key进行hash操作得到cache line的地址，然后对比cache line中保存的key，来获取value。如图4所示，key为128b，value为64b，一个cache line能够保存两个键值对。同时，因为hash表是动态开辟cache空间，而不是采取的静态保留策略，因此需要考虑valid bit。该论文中采用的策略是HTA会初始化每一个cache entry为无效的key值，即对该key进行hash得到的cache line不可能对应到该cache line。<br>由于Cache line容量显示，单条entry超出cache line容量的键值对通过软件hash表进行处理。</p><h2 id="HTA-ISA扩展"><a href="#HTA-ISA扩展" class="headerlink" title="HTA ISA扩展"></a>HTA ISA扩展</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021911-233045.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021911-233058.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>HTA会在架构寄存器中存储HTA表的描述，同时支持4条HTA表的描述信息。HTA支持4条指令：</p><ul><li><em>hta_lookup</em></li><li><em>hta_update</em></li><li><em>hta_swap</em></li><li><em>hta_delete</em></li></ul><ol><li>hta_lookup</li></ol><p>hta_lookup的指令格式如图5所示，执行哈希表的查找，对应的哈希表描述信息由<em>table_id</em>指定。hta_lookup支持高达四个整数或浮点数字长的key和一个整形或浮点型value，这些都保存在寄存器中。<br>如果查找已解决，即找到了键或行未满，则hta_lookup将充当已采取的分支。它跳转到指令中编码的目标PC（PC-relative格式），设置溢出标志以指示查找是否成功，并用相应的值更新结果寄存器。如果查找未解决，即未找到键且行已满，则hta_lookup充当未采用的分支，并继续执行下一条指令，见图5中的<em>call swLookup</em>，继续查找软件维护的溢出部分。</p><ol start="2"><li>hta_update</li></ol><p>与hta_lookup一样，hta_update对键和值寄存器以及表id进行编码。如果找到key或line未满，hta_update更新缓存line中的对并跳转到目标PC。否则，如果没有找到key，行已经满了，hta_update不做任何修改，继续执行下一条指令(继续执行软件维护的部分)。</p><ol start="3"><li>hta_swap</li></ol><p>hta_swap的功能比hta_updata的功能更强一些。在hta cache line中如果找到了对应的key或者行未满(即未溢出，不需要继续使用软件维护)，hta_swap执行的过程于hta_update相同，要么更新找到的key-value，要么增加新的key-value。如果key没有找到，且cache line已满，则可能溢出。hta_swap会随机选择一个key-value的位置更新为该条指令对应的key-value，而踢出的key-value将保存到寄存器中，然后hta_swap会使用软件路径维护受害的key-value（见图6中的<em>call swHandleInsert</em>)。（note：这个思路可以保证cache line中保存的都为高频访问的key-value pairs）</p><ol start="4"><li>hta_delete</li></ol><p>hta_delete也是首先在hta table中查找对应的key-value pair，如果找到则将对应的key替换成特殊的<em>deleted key</em>，跳出分支。否则，hta_delete继续执行软件维护的路径。</p><p>note: Deleted key需要不同于invalid key，因为hta_lookup需要区分invalid key和deleted key，不能将删除的key-value pair当作空，否则就不会继续查找软件维护的部分。而hta_update和hta_swap则需要将其当作空，以插入新的键值对。</p><h3 id="ISA设计方案"><a href="#ISA设计方案" class="headerlink" title="ISA设计方案"></a>ISA设计方案</h3><p>本文中ISA指令格式采用的是X86处理器指令格式，CISC指令在执行时译码成多条$\mu ops$。</p><h2 id="FLAT-HTA实现"><a href="#FLAT-HTA实现" class="headerlink" title="FLAT-HTA实现"></a>FLAT-HTA实现</h2><p>如图3a所示，Flat-HTA使用存储在可缓存内存中的单级HTA表。Flat-HTA大大减少了软件哈希表的开销，但仍然存在空间局部性差的问题。</p><h3 id="核心流水线改变"><a href="#核心流水线改变" class="headerlink" title="核心流水线改变"></a>核心流水线改变</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021911-233118.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>HTA对处理器的改动比较简单，其实就是增加了一个功能单元，处理HTA的四条指令。</p><h3 id="硬件开销"><a href="#硬件开销" class="headerlink" title="硬件开销"></a>硬件开销</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-11850.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>作者使用RTL语言实现了HTA功能单元，使用yosys基于45 nm FreePDK45标准库进行综合，频率为3GHz，最终硬件开销如表1所示。</p><h3 id="软件路径"><a href="#软件路径" class="headerlink" title="软件路径"></a>软件路径</h3><p>软件路径主要处理溢出的情况，这是很少出现的。其次，还需要维护resizing算法，这个算法具体可以参考原文。</p><h3 id="并行哈希表实现"><a href="#并行哈希表实现" class="headerlink" title="并行哈希表实现"></a>并行哈希表实现</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-11903.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-11914.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图5和图6展示了简单的哈希表操作，需要一些细化来保证线程安全。主要实现方式是HTA指令的原子性，如图8和图9所示。</p><h2 id="Hierarchical-HTA实现"><a href="#Hierarchical-HTA实现" class="headerlink" title="Hierarchical-HTA实现"></a>Hierarchical-HTA实现</h2><p>HTA表限制：为简单起见，我们对后备HTA表引入一些限制：它必须在物理内存的连续区域中，必须是2的幂大小，并且必须是大小对齐的。（Flat-HTA表存在于可分页的虚拟内存中，因此它们没有这些限制。）这些限制让我们可以对物理地址进行操作，避免在缓存上使用TLB，并简化寻址。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15718.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>HTA 存储格式：</p><p>如图10所示，假设HTA Stash占据$2^K$行Cache line，后背HTA Table占据$2^M$行Cache line。key首先被hash成M-bit HTA Table地址，然后将高M-K为地址置0，则转换成HTA Stash的地址，cache line对应的byte offset保持不变。如图10中HTA Table中0000b，0100b，1100b行的键值对都被映射到HTA Stash的00b位置。<br>缓存控制器存储有关每个HTA存储的一些信息：其对应HTA表的起始地址和大小，以及键值对格式。这限制了每个缓存可以保存的分层HTA哈希表的数量（在我们的实现中为四个哈希表）。<br>每对管理：缓存控制器被扩展为操作和通信每个级别内的单个键值对：它们在键值对上执行共享fetch(GETS)、独占fetch(GETX) 和脏写回 (PUTX)，类似于常规缓存中的行获取和驱逐的常见请求。每个HTA操作都会依次检查哈希表的HTA stashes，只有当当前stash无法解析操作时，才会访问下一级HTA存储（以及最终的HTA表）。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15729.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图11显示了Hierarchical-HTA的lookup和Eviction操作。</p><p>溢出：HTA存储中的溢出对软件是透明的：缓存将随机选择的一对驱逐到下一级，为新的键值对腾出空间。HTA表中的溢出的处理方式与Flat-HTA中的相同，通过调用软件回退路径进行更新。请注意，由于HTA表包含HTA stash，因此HTA stash中的溢出或驱逐永远不会导致HTA表溢出。</p><p>一致性：最后，我们保守地保持一致性。对于HTA表中的每一行，在共享的最后一级缓存中跟踪一致性。当HTA表中的LLC行被逐出时，或者当该线路被共享并接收到独占请求时，该线路的所有共享者都会被发送无效信息。在包含HTA存储的较小缓存中，落在具有共享权限（由于查找）的HTA stash行上的独占请求（由于更新）导致行中的对被丢弃。这些策略让我们可以重用行级一致性元数据，尽管它们不如我们执行成对一致性的精确。</p><h2 id="HTA-加速备忘"><a href="#HTA-加速备忘" class="headerlink" title="HTA 加速备忘"></a>HTA 加速备忘</h2><p>Memoization通过缓存和重用重复计算的输出来提高性能并节省能源。先前的软件和硬件备忘技术有明显的缺点。软件备忘受到高运行时开销的影响，因此仅限于长计算。先前的硬件技术实现了低开销并且可以备忘短函数，但它们依赖于浪费大量面积和能量的大型专用备忘缓存。<br>我们利用HTA以低成本加速备忘，在没有专用片上存储的情况下匹配先前硬件备忘技术的性能。</p><p>备忘表是为备忘功能分配的。每个备忘表都是一个哈希表，将参数存储为键，返回值作为值。由于备忘表很小，我们使用Flat-HTA来实现它们。这些Flat-HTA表没有操作软件哈希表的传统软件路径。相反，在HTA表上错过了软件路径，只需调用memoizable函数。这是一个很好的权衡：执行短函数比软件哈希表查找便宜。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15742.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图12显示了使用hta指令加速备忘的代码。</p><p>探索可备忘区域：我们开发了一个pintool来识别可备忘（即纯）函数(这边也有一篇该作者的工作可以参考)。如果一个函数满足两个条件，它就被定义为可备忘的。首先，它的内存读取要么是只读数据，要么是它的堆栈。其次，它的内存写入仅限于它自己的堆栈。然后，我们手动将hta_lookup和hta_swap指令添加到这些函数的调用点。由于其低开销，HTA不需要像在软件技术中那样基于成本效益分析来执行选择性备忘。因此，我们记住了我们的工具识别为可备忘的每个功能。我们记住应用程序和标准库函数。</p><h2 id="实验方法学"><a href="#实验方法学" class="headerlink" title="实验方法学"></a>实验方法学</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15759.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该工作使用的仿真器是zsim，系统参数设置见表2。</p><h3 id="哈希表工作负载"><a href="#哈希表工作负载" class="headerlink" title="哈希表工作负载"></a>哈希表工作负载</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15809.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该论文使用的工作负载为四个深度使用hash表的应用：</p><ol><li>bfcounter是一种内存高效的软件，用于计算DNA序列数据中的kmers，这对于生物信息学中的许多方法（包括基因组和转录组组装）至关重要。bfcounter使用大量更新的哈希表来保存k-mers。我们使用来自ENCODE的DNA序列作为输入。</li><li>lzw是基于LZW算法的文本压缩基准，这是一种广泛使用的无损数据压缩技术。哈希表用于保存字典。我们使用圣经作为输入文本文件。</li><li>hashjoin是散列连接算法的单线程实现。hashjoin连接两个合成表。程序有两个阶段：第一阶段，扫描内表，构建哈希表；然后在第二阶段，扫描外部表，同时探测哈希表以产生输出元组。</li><li>ycsb是雅虎的一个实现！在DBx1000上运行的云服务基准测试。哈希表用于哈希索引。我们使用两种配置评估ycsb：100%读取查询和100%写入查询。<br>表 3 详细说明了这些应用程序及其特性。<br>我们修改每个应用程序以支持多个哈希表实现（使用模板元编程来实现，没有运行时开销）。我们比较了以下实现：</li></ol><ul><li>Baselin：因为没有一个哈希表设计适合所有应用程序，所以我们使用最好的 libstdc++ 的 C++11 unordered_map 和谷歌的dense_hash_map 作为Baseline实现。 两者中最好的要么匹配要么优于应用程序现有的哈希表。</li><li>Flat-HTA and Hierarchical-HTA: 为了评估 HTA，我们使用哈希表实现，其中 HTA 哈希表通过 hta_lookup/update/swap/delete 指令访问。 HTA 哈希表开始时为空，并在插入元素时调整大小。 具体来说，如果软件路径调用占 HTA 访问总数的比例超过 1%，则 HTA 表的大小将增加一倍。 这涉及分配一个两倍大的新 HTA 表，然后将先前 HTA 表和软件哈希表中的所有对插入到新 HTA 表中。 对于每个应用程序，HTA 使用相同的软件哈希表作为baseline。 由于HTA很少使用软件哈希表，其性能对软件哈希表的选择不敏感。</li><li>HTA-SW: 为了进一步分析 HTA 并说明性能差异的来源，我们实现了一个软件方案 HTA-SW，它实现了与 HTA 相同的算法，但没有任何硬件支持。 HTA-SW 使用相同的表格式、相同的软件哈希表和相同的大小调整算法。 HTA-SW 不依赖任何硬件支持：哈希表操作中的所有步骤，包括散列、密钥比较、内存访问和分支，都是纯软件实现的。 HTA-SW 以连续格式将密钥存储在缓存行中，以便可以使用 SIMD 加载和比较指令进行比较。 具体来说，我们使用英特尔 AVX 矢量加载、比较和屏蔽指令来利用关键查找中的并行性。</li></ul><h3 id="备忘工作负载"><a href="#备忘工作负载" class="headerlink" title="备忘工作负载"></a>备忘工作负载</h3><p>如表4所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15823.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><h3 id="Flat-HTA在单线程应用的表现"><a href="#Flat-HTA在单线程应用的表现" class="headerlink" title="Flat-HTA在单线程应用的表现"></a>Flat-HTA在单线程应用的表现</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15838.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ul><li>FLAT-HTA outperforms the baseline by 24% on bfcounter, 70% on lzw, 2.0x on hashjoin, 23% on ycsb-read, and 69% on ycsb-write</li><li>FLAT-HTA outperforms HTA-SW substantially, by 6.3% on bfcounter, 7.4% on lzw, 2.1x on hashjoin, 28% on ycsb-read, and 73% on ycsb-write.</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15852.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ul><li>bfcounter and lzw benefit mainly from reduced mispredidcted branches</li><li>hashjoin and ycsb gain mostly from better backend parallelism.</li><li>Fig. 14 shows these benefits stem from reduced wrong-path execution and backend stalls. Specifically, though FLAT-HTA incurs the same cache misses as HTA-SW, applications with abundant operation-level parallism, like hash join and ycsb, benefit from HTA significantly by using the reorder buffer better: since each hash table operation uses far fewer $\mu ops$, more operations are overlapped, reducing backend stalls.</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15904.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>表5报告了不同实现的内存消耗，我们可以看到存储分配存在很多的2倍关系，论文作者认为由于HTA表的分配是按幂指数分配的，很小的resizing阈值波动就会导致呈2倍关系。</p><h3 id="Flat-HTA在多线程应用上的表现"><a href="#Flat-HTA在多线程应用上的表现" class="headerlink" title="Flat-HTA在多线程应用上的表现"></a>Flat-HTA在多线程应用上的表现</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15919.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图15显示了FLAT-HTA多线程对ycsb-read和ycsb-write的加速效果，可以看出多线程性能会比单线程好，因为大多数HTA操作执行不需要锁。</p><h3 id="具有层次感知布局的-HTA"><a href="#具有层次感知布局的-HTA" class="headerlink" title="具有层次感知布局的 HTA"></a>具有层次感知布局的 HTA</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15931.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图16比较了两种方案的性能。在ycsbread和ycsb-write上，键值对混合重用，Hierarchical-HTA分别将L2未命中减少了4.1倍和3.9倍。发生这种情况是因为Hierarchical-HTA让L1和L2保持密集的对。这种未命中减少意味着ycsb读取的性能提高了35%。然而，ycsb-write获得了相同的性能，因为Flat-HTA通过利用内存级并行性完全隐藏了更新延迟。最后，其他三个应用程序没有表现出混合重用，因此Hierarchical-HTA没有比Flat-HTA显着提高性能。</p><h3 id="多道程序工作负载上的HTA"><a href="#多道程序工作负载上的HTA" class="headerlink" title="多道程序工作负载上的HTA"></a>多道程序工作负载上的HTA</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15942.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-15952.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-20007.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-20020.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-20033.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/10/leveraging-caches-to-accelerate-hash-tables-and-memoization/2021913-20044.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>[^1]: 这是因为，在 unordered_map 和dense_hash_map 中，这样的分支将控制流定向到操作结束(key match)或另一次哈希表探测(key mismatch)。这些分支依赖于从内存加载的数据(如使用链表解决碰撞，则需要从内存中得到下一个访存的地址），因此它们需要很长时间来解析并且对分支预测器具有挑战性。<br>[^2]: 每个哈希表操作都采用一系列指令，包括哈希计算、内存访问、比较和分支。 这些指令占用数十到数百个微操作 (µop) slot，与ROB大小相当。 如图 1 所示，这显着限制了内存级并行性：大多数后端停顿都用于等待主内存响应，并且重新排序缓冲区没有足够的资源来重叠多次未命中。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A 65-nm 0.6-fJ/Bit/Search Ternary Content Addressable Memory Using an Adaptive Match-Line Discharge</title>
      <link href="/2021/09/09/a-65-nm-0-6-fj-bit-search-ternary-content-addressable-memory-using-an-adaptive-match-line-discharge/"/>
      <url>/2021/09/09/a-65-nm-0-6-fj-bit-search-ternary-content-addressable-memory-using-an-adaptive-match-line-discharge/</url>
      
        <content type="html"><![CDATA[<h1 id="A-65-nm-0-6-fJ-Bit-Search-Ternary-Content-Addressable-Memory-Using-an-Adaptive-Match-Line-Discharge"><a href="#A-65-nm-0-6-fJ-Bit-Search-Ternary-Content-Addressable-Memory-Using-an-Adaptive-Match-Line-Discharge" class="headerlink" title="A 65-nm 0.6-fJ/Bit/Search Ternary Content Addressable Memory Using an Adaptive Match-Line Discharge"></a>A 65-nm 0.6-fJ/Bit/Search Ternary Content Addressable Memory Using an Adaptive Match-Line Discharge</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>用于完全并行搜索操作的匹配线 (ML) 和搜索线 (SL) 的大量切换是以巨大的动态功耗为代价的。此外，随着内存容量和时钟速度的增加，CAM 设计变得更加难以满足功耗和性能预算。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/09/a-65-nm-0-6-fj-bit-search-ternary-content-addressable-memory-using-an-adaptive-match-line-discharge/202199-160318.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>如图1所示，传统的CAM设计存在三点挑战：</p><ol><li>多有访问条目每个周期都会改变具有大寄生电容布线的电压，这会导致巨大的功耗并产生大量的热量；</li><li>由失配数量的差异，entry之间具有不同的感知延迟，导致搜索性能下降；</li><li>由于所有访问entry的搜索操作的行数(ML和SL)多，因此阵列密度低。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Memory sizing of a scalable SRAM in-memory computing tile based architecture</title>
      <link href="/2021/09/09/memory-sizing-of-a-scalable-sram-in-memory-computing-tile-based-architecture/"/>
      <url>/2021/09/09/memory-sizing-of-a-scalable-sram-in-memory-computing-tile-based-architecture/</url>
      
        <content type="html"><![CDATA[<h1 id="Memory-sizing-of-a-scalable-SRAM-in-memory-computing-tile-based-architecture"><a href="#Memory-sizing-of-a-scalable-SRAM-in-memory-computing-tile-based-architecture" class="headerlink" title="Memory sizing of a scalable SRAM in-memory computing tile based architecture"></a>Memory sizing of a scalable SRAM in-memory computing tile based architecture</h1><h2 id="Motivation-and-Key-Ideas-of-This-Work"><a href="#Motivation-and-Key-Ideas-of-This-Work" class="headerlink" title="Motivation and Key Ideas of This Work"></a>Motivation and Key Ideas of This Work</h2><p>本文作者根据给定的缓存大小研究了一组应用程序，结果表明单个缓存实例不足以包含大型数据集，并且需要多个具有线互连的缓存实例。</p><p>本文提出了一种根据支持IMC的应用程序集来评估以数据为中心的架构的互连成本的方法，目的是创建一个连线模型。与完整的布局布线设计流程相比，该模型的新颖性为存储器设计人员提供了更精确的尺寸和更快的估计。</p><p><strong>Achievements:</strong> 通过将缓存拆分为多个子块，与单个大型 IMC 内存实例相比，我们可以实现更低的能量（高达 78% 的增益）和更快（高达 49% 的增益）的 IMC 块。</p><h2 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/09/memory-sizing-of-a-scalable-sram-in-memory-computing-tile-based-architecture/202199-150754.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>这边相关的工作就不过多介绍了，都是一些比较经典的相关论文。但是这边的图1比较有意思。可以看出作者将数据中心计算的解决方案分为了四类，分别是：IMC，IMC++，NMC和PE，分别对应着不同的加速粒度/复杂度。</p><h2 id="IMC的应用探索"><a href="#IMC的应用探索" class="headerlink" title="IMC的应用探索"></a>IMC的应用探索</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/09/memory-sizing-of-a-scalable-sram-in-memory-computing-tile-based-architecture/202199-154524.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>本文选取的应用以及操作占比如表1所示。这边结果的提取方式比较有意义，应用的是基于LLVM的一个框架<a href="#refer-anchor-1"><sup>1</sup></a><sup>,</sup><a href="#refer-anchor-2"><sup>2</sup></a>，有空可以学习一下。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id="refer-anchor-1"></div>- [1]     M. Kooli, H. Charles, C. Touzet, B. Giraud, and J. Noël, "Software Platform Dedicated for In-Memory Computing Circuit Evaluation," in 2017 International Symposium on Rapid System Prototyping (RSP), 19-20 Oct. 2017 2017, pp. 43-49. <div id="refer-anchor-2"></div>- [2]     M. Kooli, H. Charles, C. Touzet, B. Giraud, and J. Noel, "Smart instruction codes for in-memory computing architectures compatible with standard SRAM interfaces," in 2018 Design, Automation & Test in Europe Conference & Exhibition (DATE), 19-23 March 2018 2018, pp. 1634-1639, doi: 10.23919/DATE.2018.8342276. ]]></content>
      
      
      
        <tags>
            
            <tag> 未完待续 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FReaC Cache: Folded-logic Reconfigurable Computing in the Last Level Cache</title>
      <link href="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/"/>
      <url>/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/</url>
      
        <content type="html"><![CDATA[<h1 id="FReaC-Cache-Folded-logic-Reconfigurable-Computing-in-the-Last-Level-Cache"><a href="#FReaC-Cache-Folded-logic-Reconfigurable-Computing-in-the-Last-Level-Cache" class="headerlink" title="FReaC Cache: Folded-logic Reconfigurable Computing in the Last Level Cache"></a>FReaC Cache: Folded-logic Reconfigurable Computing in the Last Level Cache</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>不断提出的加速器工作会面临一些问题：在哪里放置这些加速器？如何向它们提供数据？</p><p>本文中举了两个例子：</p><ol><li>PCIe连接的加速器以有限的带宽访问系统内存中的数据，例如PCIe 3.0 x16中的带宽为16GB/s，但是PCIe系统驱动程序会在每个加速器事务中产生数万条指令，从而导致更长的延迟和带宽损失。因此，每次DMA传输的成本在1μs到160μs之间。此外，连接PCIe的卡会消耗额外的功率，最近的一项研究指出，连接PCIe的FPGA在空闲时消耗12W。</li><li>片上和片下memory性能存在很大差距，从片下DRAM中取数需要56ns，消耗28-45pJ/bit (40nm)的能量。相比之下，从片上32K-word的SRAM阵列中读取16 bits只需要消耗11pJ。</li></ol><p>在边缘计算场景中，工作集的大小可能足够小，以至于来回穿梭数据所花费的时间和精力使得许多应用不希望使用off-chip和off-die加速器。</p><p>为了应对这些挑战，我们寻求在能效、成本和性能之间提供一个中间地带，以对现有系统、处理器和内存架构进行有限更改的方式。</p><p>因此本文提出了RReaC架构，该架构利用现有的LLC来构建加速器，大概思路是使用LLC的SRAM构建查找表，从而可以实现基于查找表的可重构加速器。此外，该论文还使用了logic folding技术，但是这也是以时间换空间的方法。</p><p>该论文的目标是卸载小而重要的内核，这些内核将从定制的加速器逻辑以及FReaC Cache的高吞吐量和高带宽中受益。</p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><h3 id="LLC设计"><a href="#LLC设计" class="headerlink" title="LLC设计"></a>LLC设计</h3><p>该段介绍的LLC设计参考自原文中参考文献[36]，并且从[36][38][39][40]可以看出Intel LLC从UCA到NUCA的发展，有空可以总结一下。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202198-213747.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图1说明了20路组相联的2.5MB缓存切片组织，每个切片(slice)有多个数据阵列(data array, DA)组成，以平铺方式组织在四个象限中。每一路由来自每个象限的单个数据阵列组成，即每路由四个数据阵列以及一个Tag/State和CV(valid)/LRU数组。Control box单元位于缓存的中间，负责所有控制操作、一致性和互连接口。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202198-213802.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>每个 32KB 数据阵列由两个 16KB 子阵列组成，每个子阵列都有一个 32 位端口。图 2 展示了子阵列（SA）的微架构。子阵列由32个bit-slice组成，每个slice为子阵列输出贡献1 bit，并由两个块组成。</p><p>从图2中我们可以得到以下计算公式：</p><p>$$16KB = 32\ bit\ slices = 32 \times 2\ Chunks\ = 32 \times 2 \times 4\ sets = 32 \times 2 \times 4 \times 512\ bits$$</p><p>在本文中，系统LLC的总容量为1.25MB，因此每个SA为8KB。</p><p>考虑到这种架构，我们提出了四个观察结果：</p><ol><li>SA的组织，使得在缓存数据数组中引入任何新逻辑都非常昂贵。</li><li>子阵列以lock-step方式按way运行，并行访问它们的单元。</li><li>由于缓存线在多路数据阵列之间不交错，因此可以独立访问、修改甚至关闭各个路。</li><li>虽然高速缓存访问可能需要几个周期，但单个数据阵列操作只有1到2个周期，而位线感测是1个周期长。数据数组以某种方式共享数据总线，从而串行化缓存线读取和写入。</li></ol><h3 id="可重构架构"><a href="#可重构架构" class="headerlink" title="可重构架构"></a>可重构架构</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202198-220410.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>现场可编程门阵列 (FPGA) 实际上是可重构计算的同义词，可以通过多种方式实现。通常，FPGA 由一系列逻辑块组成，即可配置逻辑块 (CLB)，以岛状布局组织，具有可编程布线结构，例如开关盒 (SB) 和连接盒 (CB)，提供每个模块之间的互连。如图3所示。CLB由几个基本逻辑元件 (BLE) 组成，每个基本逻辑元件包括一个查找表 (LUT) 和一个触发器。现代 FPGA 还包括特殊 IO（输入/输出）、DSP 和内存块。FPGA LUT 由多路复用器树或复用树和 SRAM 配置存储器组成，SRAM 配置存储器存储 LUT 实现的布尔函数的配置位。因此，K 输入 LUT 或 K-LUT 将需要 2<sup>K</sup> SRAM 单元来存储其功能。图3(c) 展示了一个 3-LUT。连接 CLB 的全局布线结构，例如开关盒和互连线，是 FPGA 中延迟的主要来源，并且可以占据近 80% 的面积。</p><h3 id="逻辑折叠-Logic-Folding"><a href="#逻辑折叠-Logic-Folding" class="headerlink" title="逻辑折叠(Logic Folding)"></a>逻辑折叠(Logic Folding)</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202198-220829.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>逻辑折叠利用动态重新配置，通过随时间折叠电路并跨时间共享可用逻辑资源，即时间流水线，允许使用有限的逻辑资源实现大型电路。因此，可以在较小的区域内实现相对较大的电路，尽管延迟较长。在图 4(a)中，图中的每个节点都是组合电路中的查找表 (LUT)。通过将图划分为四个级别，我们现在可以将每个级别实现为时间流水线的状态，从而只需要三个 LUT 而不是十个，但将延迟增加到四个时间步长。在每个时间步长，必须重新配置三个 LUT 以实现下一级别的操作。因此，如果我们可以重新配置每个周期，则可以在 4 个周期内实现该电路。 级别之间的相关性由锁存输出处理。</p><h2 id="FReaC-Cache"><a href="#FReaC-Cache" class="headerlink" title="FReaC Cache"></a>FReaC Cache</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202199-10654.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>FReC Cache 建立在两个关键思想之上：</p><ol><li>通过将 LLC 的 SRAM 用于 LUT 配置存储器，并通过最小化复杂的全局布线，可以实现密集的可重配置逻辑。</li><li>逻辑折叠允许我们用延迟（时钟周期）来减少每个周期的资源需求，以便映射电路。 高频抵消了折叠过程中产生的延迟损失。</li></ol><p>图 5 对单个LLC切片的FReaC Cache端到端操作进行了六个步骤的高层次概述。</p><ol><li>为了利用FReac Cache作为加速器，必须选择LLC的一部分作为加速器运行。</li><li>由于整个路都用于形成计算逻辑，因此必须刷新所选路中的脏行。</li><li>选定的方式被锁定为计算模式。请注意，为了刷新和锁定缓存方式，我们通过在现有的缓存控制框架中引入我们自己的计算集群控制器(CC Ctrl)。主机仅通过本机加载和存储(LD/ST)指令与CC Ctrl单元交互。</li><li>为计算模式准备SRAM way后，我们写入(加载)加速器配置比特。</li><li>如果需要，主机可以在开始计算之前填充暂存器并配置任何偏移量。</li><li>最后，主机通过LD/ST向CC Ctrl单元发出运行命令，并等待操作完成。一旦加速器完成，就可以通过重复步骤4和5对一组新的加速器进行编程或将新数据提供给现有的一组加速器。</li></ol><h3 id="Dense-Compute-Sub-Arrays"><a href="#Dense-Compute-Sub-Arrays" class="headerlink" title="Dense Compute Sub-Arrays"></a>Dense Compute Sub-Arrays</h3><p>从图3(c)可以看出LUT由SRAM配置比特位和mux-tree组成，LLC的sub-array能够通过每一次访问读取固定比特的数据，因此sub-array的每一行可以存储一个或多个LUT的配置信息，通过逐行读取sub-array的值，可以实现不同的LUTs。因此每次访问可以实现不同的逻辑操作。也就是说，子阵列的每一行都可以在逻辑折叠中实现一个时间流水线阶段。</p><p>为了实现这一点，子阵列通过存储器锁存器与多路复用树配对，如图4(b)所示。缓存锁存器与复用树一起形成了一个单一的查找表。请注意，复用树的输入是LUT输入。在读取新行时，LUT被重新配置以执行新操作。由于子阵列比较小，每次访问都可以在一个周期内进行。</p><p>因此，我们可以在每个周期动态重新配置 LUT。 由于单个 LUT 可能不足以实现布尔电路，因此可以将 LUT 的输出存储在状态锁存器中，以便在稍后的时间步长反馈到另一个 LUT 的输入中。 至关重要的是，复用树、锁存器和其他额外逻辑位于子阵列的外部，不会干扰现有的存储器设计。</p><p>从图4(b)可以看出，由于每一行存储32 bits，因此可以配置一个5输入LUT，或2个4输入LUT，或4个3输入LUT。</p><h3 id="微计算集群"><a href="#微计算集群" class="headerlink" title="微计算集群"></a>微计算集群</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/202199-11806.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>单个计算子阵列可能需要大量折叠周期才能实现逻辑折叠电路。因此，我们建议通过将每两个相邻数据阵列分组，将计算子阵列组织成微计算集群(MCC)。即四个子阵列，组成一个微计算集群，如图6(b)所示。在微计算集群内，每个子阵列借助锁存器和放置在子阵列外部的多路复用树，在每个周期激活一个或多个LUT。为了让每个计算子阵列实现的LUT一起运行，我们还在集群中添加了一个操作数交叉开关，类似于FPGA的CLB中的那种。接下来，我们提供一小部分寄存器来存储来自折叠电路的中间状态并在原始设计中实现时序逻辑。最后，由于使用LUT实现乘法等算术运算的成本很高，因此我们还添加了专用的整数乘法累加(MAC)单元。引入的附加逻辑结构放置在子阵列之外，并在两个数据阵列之间间隔开。因此，我们不会影响记忆的区域或时间。</p><h4 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h4><p>现在可以通过从每个子阵列加载新配置，逐个周期地实现电路的每一级，在微计算集群内实现逻辑折叠电路。为了简化这一点，我们将每个级别的配置位存储在子阵列中的顺序地址中，并重用现有的地址总线来遍历地址。步数（折叠级别）由逻辑折叠计划决定。调度由我们添加到缓存控制箱的微型计算集群控制器 (CC Ctrl) 单元执行和管理。接下来，在每个时间步长，操作数可以缓存在寄存器或 LUT 中或从总线中提取。操作数交叉开关促进了这种移动，它必须为每个时间步长配置，由调度决定。因此，交叉开关也需要配置位，这些配置位存储在路的标记/状态数组中，在路用于计算时不使用。因此，我们不需要额外的配置内存。</p><h4 id="物理设计注意事项"><a href="#物理设计注意事项" class="headerlink" title="物理设计注意事项"></a>物理设计注意事项</h4><h3 id="可重构计算切片的操作"><a href="#可重构计算切片的操作" class="headerlink" title="可重构计算切片的操作"></a>可重构计算切片的操作</h3><p>图 6a说明了具有微计算集群的LLC切片。出于说明目的，我们展示了8个CC tiles，其中显示了五个tiles及其所有逻辑组件——两个数据阵列和集群逻辑 (CL)。集群逻辑包括锁存器、复用树、MAC 单元、寄存器和交叉开关，如图 6b所示。请注意，由于微计算集群是通过两路方式使用DA构建的，因此一次完全消耗两路Cache，因此在它们的位置形成四个计算集群(MCC)切片。<font color="red">为了获得最大的灵活性，我们将集群逻辑添加到所有DA对中。这允许我们按需使用整个缓存切片或仅使用切片的一小部分，有效地对切片进行动态分区和重新配置，以启用计算逻辑。(怎么理解？)</font>我们还在切片的控制盒中引入了一个计算集群控制器（CC Ctrl）单元，以协助锁定和刷新方式，以及集群的控制和协调。 CC Ctrl 利用缓存控制器的现有功能和机制来完成其任务。来自内核的传入请求由 LLC 控制器提供服务，即使缓存的一部分用于计算，CC Ctrl 单元也不会干扰。如果整个 LLC 都用于计算，那么核心请求将被视为未命中，并转发到内存。</p><h4 id="主机接口"><a href="#主机接口" class="headerlink" title="主机接口"></a>主机接口</h4><p>FReC Cache不需要自定义指令。主机通过加载和存储(LD/ST)操作与加速器和CC Ctrl单元交互。每个切片的地址范围是为FReaC缓存操作保留的，以便CC Ctrl单元的控制寄存器暴露给主机内核。主机通过写入CC Ctrl单元中的控制寄存器来设置LLC切片以进行计算。此设置包括选择、刷新和锁定计算方式（图5中的步骤1、2和3）。为了配置加速器，主机将微计算集群配置数据写入CC Ctrl Unit中的指定地址，然后将配置数据写入集群子阵列（步骤4）。然后，主机可以填充暂存缓冲区（稍后讨论），并通过写入另一个地址范围来设置加速器地址偏移量（步骤5）。同样，CC Ctrl单元负责将数据转发到相应的子阵列中。最后，还分配了一个运行寄存器（步骤6）。这些控制和数据寄存器对于缓存片是唯一的，并且每个片必须执行一次设置和配置。地址空间和控制寄存器可以通过有限的操作系统支持暴露给用户代码。在内核驱动程序的帮助下，可以为物理地址范围分配虚拟地址（ioremap()操作），然后通过字符设备驱动程序暴露给用户空间，用户程序可以通过mmap()操作访问该驱动程序.</p><h4 id="设置和配置"><a href="#设置和配置" class="headerlink" title="设置和配置"></a>设置和配置</h4><p>图5中的步骤1、2和3概述了如何为计算设置LLC切片。首先，必须选择和刷新方式，然后锁定计算模式。启用此功能的机制已在现代LLC中可用，并由CC Ctrl单元利用。缓存中的路是相互独立的，因此可以指示缓存控制逻辑忽略一组路。LLC已经包含睡眠逻辑以节省功率，以及熔断位以在良率低或制造缺陷的情况下关闭。现有的LLC还可以专门为单个内核分配缓存方式，从而修改其他内核看到的有效LLC。但是，在将路配置为计算之前，必须清除脏缓存行中的路。清除路径的开销取决于几个因素，包括：包含策略、缓存层次结构、内存带宽以及有多少行是脏的。在最坏的情况下，如果必须刷新LLC中的所有行，则刷新速度会受到片外存储器带宽的限制。对于10MB的LLC，这可能是数百微秒的数量级。一旦通道被刷新并锁定到计算模式，它们就不会参与缓存。其余方式继续作为LLC的一部分运作。然后，主机可以通过切片中的CC Ctrl单元将配置位（图5中的步骤4）写入微计算集群。一旦加载了加速器的配置位，除非配置被驱逐或覆盖，否则不需要再次获取它们。</p><h3 id="加速器操作"><a href="#加速器操作" class="headerlink" title="加速器操作"></a>加速器操作</h3><h3 id="Large-Micro-Compute-Clusters-and-Multi-Cores"><a href="#Large-Micro-Compute-Clusters-and-Multi-Cores" class="headerlink" title="Large Micro Compute Clusters and Multi-Cores"></a>Large Micro Compute Clusters and Multi-Cores</h3><p>FReaC Cache是一种分块架构，其中每个微计算集群(CC)可以通过将加速器电路映射到其上来操作自己的独立计算单元（加速器分块），如图5所示。为此，加速器电路被折叠和调度，每个时间步都被映射到LUT、MAC和触发器（第四节）。在每个时间步上，集群最多可以访问四个5-LUT或八个4-LUT、一个MAC和一个总线操作。微计算集群以某种方式共享地址总线，从而以锁步方式运行。为了进一步简化设计，并尽可能多地重用结构，我们将所有簇的地址线连接起来。由于所有集群都运行相同的加速器并具有相同的调度，因此所有加速器块都以锁步方式运行。如前所述，CC Ctrl单元负责逐步执行调度并在地址总线上广播集群的下一个地址。</p><h4 id="操作数移动"><a href="#操作数移动" class="headerlink" title="操作数移动"></a>操作数移动</h4><p>为了提供对外部操作数的访问，我们建议使用数据总线之一作为操作数数据路径（图6b）。集群首先将操作数的地址放在总线上，总线将地址传送到CC Ctrl单元。CC Ctrl单元处理地址，在需要时应用任何偏移量，并将其移交给要服务的缓存控制器。如果缓存切片在本地命中，则操作数将通过相同的数据总线转发回集群。写入请求遵循类似的过程。由于集群以锁步方式运行，因此可能一次接收多个请求，并且集群将停止直到所有请求都得到服务。与CPU内核不同，集群等待写回完成。在读取和写入两种情况下，缓存负责合并请求（如果有能力的话）。由于数据数组共享一条总线，请求和响应可能需要跨多个周期进行序列化。</p><h4 id="FReC-缓存暂存器"><a href="#FReC-缓存暂存器" class="headerlink" title="FReC 缓存暂存器"></a>FReC 缓存暂存器</h4><p>为了充分利用FReaC Cache的功能，我们引入了对暂存器的支持。通过锁定缓存中的路径，我们允许 CC Ctrl以为暂存器保留的方式将加速器加载和存储路由到子阵列。使用现有的缓存线映射，每次可以从每路加载总共32个字节。然而，由于子阵列之间的共享数据总线和缓存控制盒中的窄数据路径，字的传递是串行化的。我们使用处理器内核来填充暂存器，从而使内核能够将数据直接初始化到暂存器中。这样做，我们避免了从上层缓存中刷新数据的需要，以及将数据复制到暂存器的开销（图5中的步骤5）。FReaC Cache不需要暂存器，但大多数加速器使用本地暂存器来提高性能和功耗。此外，暂存器有助于解决LLC无法访问TLB的问题，这会增加开销。如果没有暂存器或访问TLB，FReaC Cache将需要：(1) 工作集从上层缓存中清除，(2) 加速器运行时内核不接触数据，(3) 内核提供物理地址，(4) 数据是连续的，页面被固定在主机内存中。</p><h3 id="大型微计算集群和多核"><a href="#大型微计算集群和多核" class="headerlink" title="大型微计算集群和多核"></a>大型微计算集群和多核</h3><h4 id="启用更大的计算集群"><a href="#启用更大的计算集群" class="headerlink" title="启用更大的计算集群"></a>启用更大的计算集群</h4><p>通过将加速器限制为单个微计算集群，我们将它们限制为每个周期4到8个LUT（假设有5输入或4输入LUT）。对于控制或逻辑繁重的应用程序，可能具有基于LUT的大型电路，这可能会导致大量折叠步骤并损害性能。因此，我们建议添加轻量级FPGA风格的开关盒，其中每个开关盒执行静态路由，段连接相邻的微计算集群。我们现在可以将4、8、16或最多32个计算集群分组以形成一个大型加速器tile，每个周期有更多可用的LUT。图6c显示了最终切片概览，并说明了一个示例，其中使用四个MCC形成加速器tile，并使用两种方式形成暂存器。<br>由于计算集群的密度、每个集群的LUT数量有限以及集群之间的距离较短，因此支持这种全局路由结构并不像传统FPGA那样昂贵。此外，单个缓存切片比FPGA小得多，这使得在单个时钟周期内将位从一端路由到另一端成为可能。</p><h4 id="多核系统中的-FReC-缓存"><a href="#多核系统中的-FReC-缓存" class="headerlink" title="多核系统中的 FReC 缓存"></a>多核系统中的 FReC 缓存</h4><p>在FReC Cache中，每个切片中实现的加速器彼此独立运行。加速器之间的通信是通过全局地址空间执行的，就像在GPU等其他数据并行架构中一样。在大型计算需求的情况下，问题可以分解为较小的独立问题，由每个切片的加速器处理。因此，FReaC Cache非常适合解决数据并行问题。请注意，互连计算集群的交换基础设施也仅限于单个切片。因此，加速器块的大小受LLC切片的大小和关联性限制。在某些情况下，整体性能取决于关联性、LLC切片的数量和MAC单元的总数。</p><h2 id="映射加速器"><a href="#映射加速器" class="headerlink" title="映射加速器"></a>映射加速器</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-110042.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>FReaC Cache是一个灵活的架构，一部分LLC slice可以用于计算，其余的部分则可以用于缓存数据，如图7(a)所示。<br>图7(b)则描述了映射的流程，具体可以参考文中列出的文献。</p><h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><p>我们的评估使用了gem5模拟器。我们在gem5中实现了一个周期精确的时序模型，通过考虑以下因素来模拟FReaC Cache的性能：每个基准加速器的综合电路的折叠时间表、将操作数从暂存器移动到集群时缓存总线上的争用、集群IO带宽以及将操作数加载到加速器tile。对于每个基准加速器，我们执行RTL模拟以生成所用内存访问的跟踪，以及它运行的确切周期数。我们模拟的系统是一个8核ARM微架构，类似于Exynos-5 SoC中的A15s，在表I中进行了描述。我们使用McPat和Cacti 6.5来生成尺寸、功率，以及存储器阵列的延迟（表II）。对于我们的模拟，我们考虑从子阵列读取一个字的延迟和功率，而不是从L3获取整个缓存行的延迟。因此，我们看到从子阵列读取单个字的延迟允许我们每个周期执行一次读取，从而允许我们在每个周期重新配置我们的子阵列。类似地，将数据以一种方式从子阵列移动到另一种方式需要沿高速缓存控制盒内的共享数据总线移动并且也是串行化的。我们通过McPat估计LLC的总泄漏功率为1.125W。<br>对于我们的评估，我们选择了MachSuite中的基准测试和一些手写的基准，它们非常适合FReaC Cache的预期用例，并代表计算、内存和逻辑(LUT)绑定应用程序。我们排除了n体分子动力学（KNN、GRID）和DNN训练（反向传播）等基准，因为我们在本文中针对边缘处理。==FReaC Cache 能够加速小型但重要的内核，这些内核将从 FReaC Cache 的低延迟、高吞吐量和高带宽数据访问中受益。== 因此，我们专注于内核，而不是大型多相应用程序。由于原始基准数据集非常小，我们以批处理方式将问题扩大了256倍。工作以数据并行的方式在所有可用的加速器tile/CPU 线程之间平均分配。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-110833.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h3 id="时间和面积开销"><a href="#时间和面积开销" class="headerlink" title="时间和面积开销"></a>时间和面积开销</h3><p>为了评估FReaC Cache中涉及的开销，我们使用Cacti、McPat、DSENT和RTL综合以及一个45nm库缩放到32nm。FreaC Cache添加了以下组件以形成微计算集群(MCC)：Mux Trees、Operand XBars、Intermediate Registers和MACs。MCC的组织和功能远没有处理器复杂，我们特别考虑以尽量减少对缓存时序的影响：(1) 通过添加缓冲区，我们避免加载现有总线。(2) 我们不修改内存阵列本身。(3) 大多数关键组件布线繁重，但集中在一个集群中，现代工艺节点具有高布线密度。(4) 正如我们将要证明的，新元件的面积可以忽略不计，因此它们的添加不会显着影响关键的导线路径。<br>我们对我们的面积和延迟建模采取保守的方法，并考虑最坏的情况。由于我们在短段中添加了新的布线，我们可以通过Cacti和DSENT合理地估计这些，如[55]中所示。特别是，Cacti 6+被开发用于识别大型缓存中的线路延迟。首先，我们考虑微计算集群。添加了四个组件：操作数xbar、复用树、中间寄存器和MAC单元。我们使用RTL模型来估计32位MAC单元和256个中间值保持触发器的成本分别为1011μm2和1086μm2。接下来，我们使用DSENT估计32X1 Mux树的成本为45μm2，操作数交叉开关为1239μm2。因此，每个簇增加的总面积为0.0034 mm2。如果我们在切片中启用32个集群，使用 16 路，总开销为0.109 mm2，仅占表II中描述的LLC切片总面积的3.5%。这将启用每个切片32个独立加速器切片的基本FReaC缓存模式。<br>然而，启用更大的集群有潜在的好处。为此，我们考虑了图3所示的FPGA式孤岛路由。为此，我们在四个微计算集群的组之间放置了一个开关盒，以及一个额外的开关盒来跨越标签阵列和控制盒，以启用X-Y路由。因此，我们总共有28个(7X4)开关盒，放置在16路缓存中，在8X4微计算集群块之间创建互连结构。请注意，FPGA路由结构和互连可以设计为放置在缓冲区和逻辑之上。因此，一旦我们确定了逻辑块的面积，我们就可以确定导线和互连的长度。然后，我们使用DSent和CACTI扫描模型的频率，直到在最坏的情况下不违反时序，因此为大型计算集群确定为3GHz，为小型计算集群确定为4GHz。可能的最长路径是切片对角的两个交换机之间的曼哈顿距离。我们发现这是2.864 毫米，基于高速缓存切片和子阵列的几何形状，必须在交换机之间的10条链路上完成，并且必须满足0.3 ns的延迟才能在一个周期内完成。我们考虑32位链路，并计算全局路由和链路的总面积为3469 μm2。最后，开关盒也需要配置，我们为每四个微计算集群添加一个宽输出8KB内存。这增加了0.35 mm2的总开销。请注意，这仅在我们需要以3GHz运行非常大的加速器块时才需要。因此，我们总共向切片添加了0.48 mm2或15.3%的开销。这是一个保守的估计，因为我们选择了短链接和更多的开关盒，因此为交换机增加了更多的配置内存。</p><p><strong>Summary: 运行3GHz大型计算集群时，面积开销为0.48 mm<sup>2</sup>，占LLC总面积的15.3%。</strong></p><h3 id="加速器设计空间"><a href="#加速器设计空间" class="headerlink" title="加速器设计空间"></a>加速器设计空间</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-131237.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><!-- 图8显示的时计算集群tile数对折叠周期的影响，MCC数越多，每次折叠步骤可以实现的逻辑越多，完成操作所需的折叠周期越少。因此，存在一个加速器延迟和网络吞吐率的平衡，以最大化性能和能效。 --><p>我们首先探索映射到FReC Cache的加速器的设计空间。我们使用Xilinx Vivado HLS综合了基准测试。首先，我们探讨了对用于实现加速器tile的计算集群tile数量的影响。每个加速器可用的MCC越多，每个折叠步骤可以分配的资源就越多，因此折叠周期就越少。我们展示了图8中每个基准在不同tile尺寸下的折叠周期数。虽然为每个加速器tile分配更多MCC减少了折叠次数，但每个切片的并发加速器tile数量存在权衡。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-135631.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>因此，加速器块的延迟和净吞吐量之间存在权衡。这种权衡还需要考虑工作集邻近度的影响。为了最大限度地提高性能和效率，工作集必须在缓存中可用。因此，并发加速器tile的数量也受到每个加速器tile的工作集 ==(数据量？)== 的限制。为了说明这一点，我们考虑了被分配到计算和缓存的LLC的不同比率。我们从16个Cache way用于计算和4个Cache way用于缓存开始，创建32个MCC和一个256KB缓存器，然后扫描到2个Cache way用于计算和18个Cache way用于缓存，创建4个MCC和一个1.1MB缓存器。图9显示了可以放入单个切片的最大加速器切片数量，切片大小为1（每个切片1 MCC）。具有较小工作集的加速器，例如AES和点积引擎，能够用加速器填充所有32个MCC块。然而，GEMM、KMP、Sorting 和 Stencil 等计算内核和存储绑定内核都通过将更多的LLC分配给缓存来达到最大的切片数量（以及吞吐量）。请注意，这是加速器工作集和可用切片数量的函数。总体而言，我们观察到由32个MCC和256KB缓存以及16个具有768KB暂存器的MCC组成的组织允许在单个切片中实例化大多数加速器块。</p><h3 id="FReC-缓存性能和效率"><a href="#FReC-缓存性能和效率" class="headerlink" title="FReC 缓存性能和效率"></a>FReC 缓存性能和效率</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152647.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152659.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>我们将FreaC Cache与其基础系统的8个ARM内核、一个大型PCIe连接的FPGA(Xilinx ZCU102 FPGA) 和一个独立的Ultra 96​​ SoC FPGA系统进行了比较。我们使用OpenMP以数据并行的方式跨所有可用的物理内核并行化基线基准测试。我们通过McPat使用32nm低功耗库对ARM内核的功率进行建模。为了评估FPGA，我们综合了启用所有优化指令的基准电路。接下来，我们尝试实例化基准IP的256个副本，以反映最大的数据并行性。如果所有副本都不适合，那么我们对工作负载进行批处理，并相应地缩放延迟。我们包括160 μs的DMA延迟和配置开销，还包括通过PCIe3.0 x16为ZCU102传输数据到FPGA的成本，以及在Ultra 96​​ (U96)中通过AXI总线传输的成本。然后，我们使用Xilinx功率估计器(XPE)来估计功率，并将电路板空闲和泄漏功率计为12W的ZCU102。FReaC Cache上的基准测试延迟由我们的Gem5模拟器提供。为了提供最佳性能并与我们的FPGA比较保持一致，我们将数据移入暂存器缓冲区。我们测量内核在FReaC Cache加速器中操作的延迟，以及将数据集传输到暂存缓冲区的延迟。在将数据加载到缓冲区时，我们并行加载LLC切片，从而充分利用LLC的带宽。内核延迟还包括写入配置数据的时间。我们通过考虑来自计算集群和暂存器的读取次数来估计FReaC Cache的能力。我们还假设开关盒之间的链路在100%负载下运行，每条链路消耗约9 mW，并添加泄漏功率。我们展示了与A15主机的单个线程相关的所有数据。<br>为了更好地理解FReaC Cache，我们首先检查单个缓存切片和加速器切片大小的影响。我们考虑一个具有32MCC-256KB分区的切片，因此消耗了切片的所有20路。然后，我们扫描加速器tile大小，为每个加速器分配1、8和16个MCC，并测量内核在单个主机内核(A15)上的执行速度。我们还使用每个切片的最大加速器数量来限制我们的探索，如图9所示。在图10中，除了AES，我们看到增加切片大小可以提高性能。然而，我们看到tile大小为16时性能有所下降，因为16个或更多MCC的tile需要降低时钟速度。正如我们在图8和图9中看到的，AES具有非常高的折叠开销，但可以在单个切片中容纳多个副本。因此，它更适合每个切片有多个切片，每个切片的MCC很少。正如我们之前提到的，将LLC分配到内存与计算之间存在权衡。我们在图11中更仔细地检查了这一点。我们展示了单个切片中两个不同的计算到内存分区在所有加速器切片大小中可能的最佳性能。再一次，我们发现AES比缓冲存储器更喜欢更多的计算集群，以及其他计算内核，如点积引擎、全连接层和GEMM。但是请注意，这里我们仅限于单个切片。最佳的计算到内存权衡也是切片总数的函数，我们观察到，随着参与加速的切片数量的增加，16MCC-768KB拆分被证明更有用。<br>接下来，我们将在我们的评估系统中考虑FReaC Cache的端到端性能。在实践中，消耗整个LLC可能是不可行的，因此我们保留了两种方式，每个切片128KB作为缓存。这留下了10%或1MB的LLC，同时将剩余的18路分配给计算和暂存器。我们考虑每个切片16MCC-640KB计算暂存器拆分，并扫描所有可能的加速器切片大小和缓存切片。为简洁起见，我们报告了给定切片数量的最佳性能（加速），并报告了相应的每瓦性能（每瓦吞吐量）和功率。我们在图12中以对数刻度呈现我们的数据。加速是通过应用程序的端到端延迟来衡量的，我们使用单个A15线程作为基准。端到端延迟包括初始化阵列、将它们移动到暂存器缓冲区以及返回核心的成本。为了进行比较，我们包括完全并行的八线程A15实现，以及ZCU102和Ultra96 (U96) FPGA。对于FGPA，我们还包括将数据移动到其缓冲区的成本。<br>正如我们所见，随着缓存切片数量的增加，FReaC Cache的端到端性能也随之提高。在各项基准测试中，FReaC Cache的性能比ARM内核低一小部分。平均而言，当使用所有八个切片时，FReaC Cache分别比单线程和多线程实现快8.2倍和3倍。此外，FReaC Cache的效率（Perf/Watt）平均比多核CPU高6.1倍。事实证明，FReaC Cache尤其适用于内存受限和计算内核，例如卷积、点积、向量加/乘、全连接层和GEMM，与单线程实现相比，速度提高了14.5倍。由于折叠，诸如AES和排序(SRT)之类的逻辑繁重的应用程序会受到更高的惩罚。因此，虽然它们比单个CPU线程快，但多线程实现超过它们，但功率几乎是其两倍。然而，在大多数基准测试中，大型ZCU102 FPGA的性能优于FReaC Cache、A15和U96。这是以功耗大幅增加为代价的，我们注意到ZCU102芯片比LLC以及整个A15芯片大得多。以边缘为中心的低功耗Ultra 96​​在计算和内存敏感基准测试中均被FReaC Cache击败。事实证明，FReaC Cache也比两种FPGA解决方案更节能。因此，FReaC Cache在各种基准测试和领域证明了自己的高性能、灵活和高效。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152729.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152741.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152752.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/freac-cache-folded-logic-reconfigurable-computing-in-the-last-level-cache/2021910-152810.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>最后，将数据移入和移出加速器可能会花费时间和精力。在NMA和PIM的情况下，这可能还需要核心和主机操作系统中的其他机制。为了降低将数据复制到缓冲区和从缓冲区复制数据的成本、提高性能并避免将页面固定到物理地址，FReaC Cache使用内核将数据直接初始化到暂存器缓冲区中。这有效地消除了复制操作，但这样做仍然需要时间。在我们对图12的评估中，我们考虑了应用程序的端到端延迟，包括初始化和复制数据的成本。在图13中，我们在对数尺度上展示了端到端加速与仅内核加速的对比。作为参考，我们还提供了多线程实现。我们观察到，根据基准测试，复制和初始化的开销可以忽略不计到60%。因此，在某些情况下，我们的端到端加速比峰值内核加速的一小部分。这部分是由于工作集的大小，甚至CPU也会因此而降低端到端性能。FReaC Cache的性能仍然优于CPU甚至FPGA。请注意，尽管LLC具有巨大的带宽并直接在缓冲区中初始化数据，但我们仍会受到内存初始化延迟的影响。然而，像ZCU102和U96这样的片外加速器需要在更慢的通道上进行完整复制，初始化完成后，会增加更多的开销。因此，FReaC Cache提供经济高效、节能且灵活的加速，以及通往用户工作集的高带宽和低延迟路径，这使FReaC Cache处于非常独特的位置。</p><h2 id="DISCUSSION"><a href="#DISCUSSION" class="headerlink" title="DISCUSSION"></a>DISCUSSION</h2><p>在本节中，我们将进行讨论以阐明 FReaC Cache 的动机、定位和潜在限制。</p><h3 id="可移植性"><a href="#可移植性" class="headerlink" title="可移植性"></a>可移植性</h3><p>在这项工作中，我们通过将FreaC Cache合并到现有架构中来说明FreaC Cache的思想和原则。虽然我们使用Huang等人提供的Intel Xeon LLC的详细描述作为示例FReac Cache设计的基础，FReaC Cache不限于英特尔LLC架构，也不依赖于任何特殊的英特尔企业功能。相反，在这项工作中，我们的重点是用于边缘计算的处理器。改变底层缓存切片架构可能会影响每个周期的有效LUT数量、微计算集群的大小、集群数量和跨路分组的集群数量等。 例如，如果一个缓存路由两倍作为许多子阵列，我们可以拥有两倍多的微计算集群，或相同数量的集群，每个周期可用的 LUT 数量增加一倍。为了一致性，我们使用了 Huang 等人描述的架构贯穿本文。总内存容量仅限制暂存器大小和我们可以存储的配置数量，但不限制性能。</p><h3 id="基于-FPGA-的架构"><a href="#基于-FPGA-的架构" class="headerlink" title="基于 FPGA 的架构"></a>基于 FPGA 的架构</h3><p>FReC Cache不是一种新的FPGA架构。相反，它是一种适用于边缘场景的极具成本效益和能效的解决方案，在这些场景中，小吞吐量或内存带宽密集型内核可以偶尔卸载。我们的重点不是重新设计可重新配置的计算逻辑，而是专注于重新配置LLC并将其转换为可以利用近内存计算的定制加速器的最佳方式。它不是为处理通用可重配置计算或提供一般FPGA设备通常针对的胶合逻辑而设计的。虽然我们确实使用LUT，就像FPGA，但我们的设计和组织与FPGA有很大不同，我们没有考虑通用FPGA的许多特性，包括嵌入式BRAM、丰富的基于FF的控制逻辑、高I/O能力、多-clock域等。因此，FReaC Cache不是每个应用程序的完美解决方案。如果应用程序易于理解且任务关键，则FPGA可能是更好的选择。例如，具有大型复杂控制电路的电路将更适合FPGA，在这种情况下，对数千个LUT的即时访问更为关键。但是，FReaC Cache比FPGA具有显着的面积优势，因为：（1）LLC子阵列占据了大部分面积，并且附加逻辑具有面积分数开销，以及（2）80%的FPGA面积用于布线结构及其配置位，FReaC缓存避免了这个问题。此外，FPGA的配置带宽有限，仅为400MB/s。FReaC缓存配置受LLC-DRAM带宽和LLC内部带宽（10到100GB/s）的限制。</p><h3 id="替代的-Near-和-In-Cache计算方法"><a href="#替代的-Near-和-In-Cache计算方法" class="headerlink" title="替代的 Near 和 In-Cache计算方法"></a>替代的 Near 和 In-Cache计算方法</h3><p>我们首先考虑Compute Caches，其中作者提出利用位线计算来实现向量计算。由于计算的性质，这种方法受到子阵列间距的限制，因此作者仅限于一组简单的位运算——AND、OR、XOR、复制和比较——它们对以下情况有效作者针对的数据操作域，例如字符串匹配、位图索引等。至关重要的是，这种方法需要对缓存和子阵列进行大量重新设计，并添加新的ISA指令，这会增加大量的设计和验证成本。此外，operands must be placed for sufficient locality in order to perform in-situ processing。 Compute Cache 中计算、ISA、基准测试和模拟基础设施的深奥性质使得很难与FReaC Cache进行一对一的比较。但是，我们注意到FReaC Cache的侵入性要小得多。所有新逻辑都放置在子阵列之外，重新使用现有总线，并且不使用自定义ISA。因此，我们最大限度地减少了对LLC和内核的面积、时序、能量和设计的影响。最重要的是，我们不限于位级操作或受限的应用领域。虽然FReaC Cache是通用的，但它最适合主机需要加速内存绑定计算内核的情况。Compute Cache在数据操作工作负载上提供了1.9倍的平均加速，而FReaC Cache在不同的工作负载上展示了3倍的平均加速。<br>接下来，我们考虑近缓存计算，例如BSSync，它将计算放置在缓存附近，而不是在数组内部。我们考虑在LLC中放置轻量级嵌入式内核(EC)，例如ARM A7，而不是在LLC中放置ALU并添加新的ISA指令。与FReaC Cache一样，它提供了类似的通用功能，独立于主机内核运行，加速器内核和主机内核之间的通信仍然可以通过LD/ST完成。每个A7内核的面积约为0.49 mm2，与FReaC Cache的per-slice开销类似。因此，我们考虑两种情况：（1）iso-area，每个切片放置一个EC，以及（2）每个切片放置两个EC。这些分别在LLC中提供总共八个和十六个内核。为了公平比较，我们分配了LLC的16 way作为暂存器供内核使用。正如我们在图14中看到的，基于FReaC Cache的加速器的定制电路和有效的内存带宽利用率使其显着优于iso-area 8 EC解决方案的平均4倍，以及16 EC设置的平均2倍。因此，与这种近缓存解决方案相比，FReaC Cache的面积和计算效率要高得多。请注意，图14中的加速是相对于单个A15线程显示的，该图包括所有八个A15内核的性能。</p><h3 id="干扰主机性能"><a href="#干扰主机性能" class="headerlink" title="干扰主机性能"></a>干扰主机性能</h3><p>由于LLC的一部分专用于计算，因此在CPU和FReaC Cache中的加速器性能之间存在潜在的权衡。解决方案取决于应用程序，以及CPU和加速器是否协同工作。然而，这个问题类似于在芯片多处理器和多租户云场景中看到的缓存干扰和性能隔离问题。特别是，先前的工作表明，在这种混合工作负载和多应用场景中，对LLC进行分区是一种有效的解决方案。将LLC的一部分专用于进程的加速器会对其他正在运行的进程的性能产生影响，这与将LLC的分区专用于该进程的效果类似。更好地理解为计算分配多少缓存需要详细研究以明确定义多租户级别和并发进程之间的交互，而先前关于缓存QoS和干扰的工作为此提供了良好的基础。<br>作为一阶分析，我们考虑两组应用程序：{AES、NW、STN2和STN3}和{CONV、FC、KMP和SRT}。每个组都包含混合了计算和内存绑定内核的应用程序，以及逻辑/分支繁重的特征。然后我们考虑两种情况 - 保留1MB和4MB的LLC用于缓存，而其余部分用于加速组中的应用程序之一。其余三个应用程序分别分配了两个CPU线程。图15展示了我们的分析，所有数据都标准化为单线程基线，如前几张图所示。由于四个应用程序中的三个应用程序在CPU复合体上运行，因此每个应用程序总共将运行3次。因此，我们考虑每个LLC容量的三个运行时间的平均值。我们的研究揭示了两个关键点：首先，我们注意到基准测试对LLC的总容量不敏感。这主要是因为内核的L1和L2缓存能够保存每个线程的工作集。我们的基准测试以批处理和数据并行的方式运行。因此，虽然总应用程序工作集可以高达32MB，这大于LLC容量，但每线程工作集（批处理的一个元素）不会超过128KB。其次，我们看到为加速分配更多LLC资源可以提高加速器的性能。这是预期的行为。但是，我们注意到这在很大程度上与可以分配多少方式作为暂存空间有关，以便加速器发挥作用。因此，我们观察到，对于我们给定的一组基准测试，将最多90%的LLC(9MB)分配给计算/暂存器以加速一个应用程序不会损害其余三个应用程序的性能，因为剩余的1MB足以支持L1和L2缓存中的每线程工作集。在这里，我们看到基于FReaC Cache的加速器可以提供1.8倍到9倍的CPU运行速度。请注意，虽然在图12、13和14中我们考虑了每个应用程序最多八个主机CPU的线程，但这里每个应用程序仅限于两个线程，而加速器利用LLC的所有八个切片。<br>因此，在这种情况下，将计算或内存受限的应用程序卸载到LLC将提供最佳的整体性能，并且对CPU内核的影响有限。如果一个或多个应用程序对LLC容量敏感，那么用户将需要缩减用于计算的LLC分配和/或考虑将LLC分区和分配给特定应用程序。正如我们的结果所示，FReaC Cache仍然能够以60%的LLC(6MB)提供加速。减少分配给计算的LLC数量将按比例减少加速度。因此，在可能的情况下，FReaC Cache将多余的LLC容量转换为计算，从而提供节能、定制且廉价的加速。</p><h2 id="CONCLUSION"><a href="#CONCLUSION" class="headerlink" title="CONCLUSION"></a>CONCLUSION</h2><p>在这项工作中，我们提出了一种新颖的架构，FReaC Cache，它利用了LLC的现有子阵列，并且在不改变子阵列的情况下，能够创建密集的可重构计算集群。FReaC Cache可以以3.5%到15.3%的最小面积开销实现，并且当消耗90%的LLC时，与边缘级多核处理器相比，平均加速提高了3倍，Perf/W平均提高了6.1倍加速。我们还展示了FReaC Cache相对于现代FPGA的竞争优势，在现代FPGA中，FReaC Cache的面积和功率效率更高。最后，我们承认使用LLC进行计算会降低缓存性能，但某些应用程序不会用完整个LLC。通过转换LLC进行计算，我们实现了两个目标：（1）避免浪费LLC容量，以及（2）近数据计算。因此，FReaC Cache为边缘设备的加速提供了一种经济高效的解决方案。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Recryptor: A Reconfigurable Cryptographic Cortex-M0 Processor With In-Memory and Near-Memory Computing for IoT Security</title>
      <link href="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/"/>
      <url>/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/</url>
      
        <content type="html"><![CDATA[<h1 id="Recryptor-A-Reconfigurable-Cryptographic-Cortex-M0-Processor-With-In-Memory-and-Near-Memory-Computing-for-IoT-Security"><a href="#Recryptor-A-Reconfigurable-Cryptographic-Cortex-M0-Processor-With-In-Memory-and-Near-Memory-Computing-for-IoT-Security" class="headerlink" title="Recryptor: A Reconfigurable Cryptographic Cortex-M0 Processor With In-Memory and Near-Memory Computing for IoT Security"></a>Recryptor: A Reconfigurable Cryptographic Cortex-M0 Processor With In-Memory and Near-Memory Computing for IoT Security</h1><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>这篇论文并没有提出新的SRAM计算电路，属于是将10T SRAM计算电路在架构级进行了应用，加速加密算法。这篇论文给我们的一个启发是：我们并不一定受限于传统SRAM的push rule结构，担心影响其他操作的性能。这篇论文就是3/4的SRAM属于传统Cache应用，1/4的SRAM用于存算一体，这其实和谢源老师的Prime架构思路类似，比Prime有优势的地方在于存/算模式切换没有开销。</p><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>加密函数通常需要高带宽计算(64-512 bits)，但是嵌入式处理器的数据通路只有32-bit宽度。<br>现有架构，无论是CPU还是ASIC，加密算法的运行效率不高。</p><h2 id="Target-of-This-Work"><a href="#Target-of-This-Work" class="headerlink" title="Target of This Work"></a>Target of This Work</h2><p>本文提出了 Recryptor，这是一种可重构的加密处理器，可通过增强商业通用处理器的现有Cache以增强计算能力。它支持使用10晶体管位单元的Cache中位线计算，以支持高达512位宽的不同按位运算。定制设计的移位器、旋转器和S-box模块位于内存附近，提供高吞吐量的近内存计算能力。</p><h2 id="架构介绍"><a href="#架构介绍" class="headerlink" title="架构介绍"></a>架构介绍</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-160115.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Recryptor 包含一个标准 ARM Cortex-M0 微控制器和 32-kB 存储器、一个用于访问片外数据的低功耗串行总线和一个仲裁器作为其内部总线，以及可选的有限状态机 (FSM)，如图 1 所示。32-kB存储器由四个8-kB Banks组成。三个是使用标准存储器编译器实现的，而第四个是定制设计的crypto-SRAM Bank(CSB)。</p><h2 id="RECRYPTOR’S-IN-MEMORY-COMPUTING"><a href="#RECRYPTOR’S-IN-MEMORY-COMPUTING" class="headerlink" title="RECRYPTOR’S IN-MEMORY COMPUTING"></a>RECRYPTOR’S IN-MEMORY COMPUTING</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-160127.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>CSB不仅能够当作常规的存储器进行32-bit的读写，而且支持大带宽存内/近存计算。如图2所示，CSB的存储单元使用的10T SRAM结构，读写路径分离，能够同时激活多行而不会对存储的值产生干扰。通过偏斜的两个SA分别实现OR/NAND/XOR/NOT/COPY操作(NOT/COPY是如何实现的？)。运算结果可以通过移位器进行得到移位之后的结果，并将结果锁存到Write FF中等待Write Buffer写回。此外，Write FF里的结果还可以通过64-bit Rotator或SBOX进行近存计算。最后，还有一路DIN用于支持标准memory的写操作。</p><h3 id="Bank分块的配置"><a href="#Bank分块的配置" class="headerlink" title="Bank分块的配置"></a>Bank分块的配置</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-163634.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>如图4所示，8-kB CSB分为16个slices，每个slice包含128个32-bit words。进行标准memory读写时，只激活一个slice。进行存内计算时，可以通过控制同时激活多个slices，即图4(b)中的Sub-Bank，以支持不同宽度的存内计算。</p><h2 id="RECRYPTOR’S-NEAR-MEMORY-COMPUTING"><a href="#RECRYPTOR’S-NEAR-MEMORY-COMPUTING" class="headerlink" title="RECRYPTOR’S NEAR-MEMORY COMPUTING"></a>RECRYPTOR’S NEAR-MEMORY COMPUTING</h2><h3 id="Shifter"><a href="#Shifter" class="headerlink" title="Shifter"></a>Shifter</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-165714.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Recryptor支持的近存shifter操作如表1所示。图5显示了一个简单的Shifter的草图及其wiring intensive版图设计。</p><h3 id="Rotator"><a href="#Rotator" class="headerlink" title="Rotator"></a>Rotator</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-170619.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Rotator是用于任意64位旋转的自定义两级设计，如图6所示，第一级可移动0-7 bits，第二级移动8x bits，从而可以实现0-63 bits的任意移位。</p><h3 id="SBOX"><a href="#SBOX" class="headerlink" title="SBOX"></a>SBOX</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-171214.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>S-box是用于字节替换的分组密码中的常用组件。它是一个非线性函数，对伽罗华域执行乘法反演，然后是仿射变换。该算法在转换为复合域GF(2<sup>4</sup>)<sup>2</sup>时更有效。电路实现如图7所示。</p><h2 id="可编程性和优化的算法实现"><a href="#可编程性和优化的算法实现" class="headerlink" title="可编程性和优化的算法实现"></a>可编程性和优化的算法实现</h2><p>该段对FFMR，AES，Keccak-f算法进行了优化，并介绍了图2中提及的可选的密码有限状态机，暂时跳过。</p><h2 id="RECRYPTOR-测试芯片设计和实验结果"><a href="#RECRYPTOR-测试芯片设计和实验结果" class="headerlink" title="RECRYPTOR 测试芯片设计和实验结果"></a>RECRYPTOR 测试芯片设计和实验结果</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-171647.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Baseline和Recryptor都是基于ARM Cortex-M0处理器，测试芯片的工艺节点为40nm，如图9所示。</p><p>我们可以看出Recryptor与baseline相比，存在36%的面积开销，如果使用push rule设计，面积开销降低至18%。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-172057.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图10显示的时10T SRAM的最高工作频率。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-172109.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图11显示的时不同温度下正常CSB读操作的最低工作电压。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-172122.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图12可以看出Recryptor与baseline的性能相当接近。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-172135.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图13可以看出Recryptor的功率超过base 30%，但是这一开销可以被速度优势弥补。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-173009.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图14显示了CSB仿真的能耗分布。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-173031.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>表4显示了Recryptor与其他处理器的性能对比：</p><ul><li>对于FFMR，Recryptor支持163-409 bits的字长，速度提升大于11倍，能效提升大于6.7倍。</li><li>对于Keccak，没有任何的协处理器实现的工作，因此选用了参考文献[12]中的ASIC实现进行对比。速度提升超过8倍，能效提升超过4.8倍。</li><li>对于AES，速度和能效提升9倍。(这边参考文献[18]中的工作速度会快很多，一部分时频率优势，另一部分可能是处理器的微架构优势，这需要看原文才能知道。)</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/08/recryptor-a-reconfigurable-cryptographic-cortex-m0-processor-with-in-memory-and-near-memory-computing-for-iot-security/202198-173119.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图15进一步与ASIC和加密协处理器进行了对比，可以看出：在面积、吞吐量、能源和可编程性方面，Recryptor 作为比较架构之间的中间解决方案。</p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p>暂时跳过</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>i-SRAM: Interleaved Wordlines for Vector Boolean Operations Using SRAMs</title>
      <link href="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/"/>
      <url>/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/</url>
      
        <content type="html"><![CDATA[<h1 id="i-SRAM-Interleaved-Wordlines-for-Vector-Boolean-Operations-Using-SRAMs"><a href="#i-SRAM-Interleaved-Wordlines-for-Vector-Boolean-Operations-Using-SRAMs" class="headerlink" title="i-SRAM: Interleaved Wordlines for Vector Boolean Operations Using SRAMs"></a>i-SRAM: Interleaved Wordlines for Vector Boolean Operations Using SRAMs</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>之前基于SRAM的存内计算的工作需要对正常的 SRAM 读取操作进行修改，从而导致读取稳定性下降或感测裕度降低。</p><p>该论文所提出工作的一个关键亮点是，所提出的读取操作与正常的内存读取操作完全相同，因此不会导致读取鲁棒性或检测裕度的任何损失。</p><h2 id="INTERLEAVED-WLS-FOR-6T-SRAM-i-SRAM-6T"><a href="#INTERLEAVED-WLS-FOR-6T-SRAM-i-SRAM-6T" class="headerlink" title="INTERLEAVED WLS FOR 6T-SRAM: i-SRAM-6T"></a>INTERLEAVED WLS FOR 6T-SRAM: i-SRAM-6T</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202197-221316.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>交错WL技术如图1(a)所示，每一行由两根WL(O-WL和E-WL)控制，分别控制odd bit和even bit。计算电路如图1(b)所示，相邻的奇偶BL对应的SA测量结果输入到同一个计算电路中进行计算，这样任意连个奇偶word进行逻辑计算不需要同时打开多行，消除了传统6T SRAM的读取不稳定性。同时，与某些单端的SA相比，该工作与传统SA一样，采用差分的SA，能够提供更高的感测性能。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202197-231528.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>计算单元如图2所示，采用传统的CMOS逻辑实现NAND/NOR/XOR等操作。</p><p>针对这一方案，有两个关注点：</p><ol><li>该方案能且只能在任意的奇偶两个set之间进行逻辑操作，这在某些应用中非常适合，如CNN中Activation和Weight的VMM操作。</li><li>该方案没有对传统的6T SRAM的bit-cell电路和驱动电压进行任何更改。</li></ol><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202197-232338.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该方案的开销：由于采用双倍的WL，面积开销增加11%，此外还需要增加一层金属布线层。版图如图3所示。</p><h2 id="INTERLEAVED-WLS-FOR-8T-CELL-i-SRAM-8T"><a href="#INTERLEAVED-WLS-FOR-8T-CELL-i-SRAM-8T" class="headerlink" title="INTERLEAVED WLS FOR 8T CELL: i-SRAM-8T"></a>INTERLEAVED WLS FOR 8T CELL: i-SRAM-8T</h2><p>虽然交叉WL结构消除了同时激活多行带来的问题，但是8T SRAM相较于6T SRAM的优势在于读写路径解耦，非常适合进行低电压设计。在该论文中采用的是0.8V电压供电，而在65nm工艺下，标准供电电压为1.2V。8T SRAM相比于传统的6T SRAM，面积增加30%。cell结构及版图如图4所示，计算电路如图5所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-13643.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-13709.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="系统设置和评估框架"><a href="#系统设置和评估框架" class="headerlink" title="系统设置和评估框架"></a>系统设置和评估框架</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-14233.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>仿真采用的是一个简单的冯诺依曼架构，主机位Nios-II处理器，多个SRAM banks通过总线连接到主机，系统架构如图8(a)所示，针对iSRAM的指令扩展如图8(b)所示。系统仿真相关参数如表2所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-15427.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h3 id="BNN-加速"><a href="#BNN-加速" class="headerlink" title="BNN 加速"></a>BNN 加速</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-14251.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>BNN的加速方式如图7所示</p><h3 id="AES-加速"><a href="#AES-加速" class="headerlink" title="AES 加速"></a>AES 加速</h3><p>AES 加密算法严重依赖于使用逐位布尔运算（例如 XOR）的替换和置换操作。整个 AES 运行时高达 67% 的操作可以映射到上述 iSRAM-XOR 指令。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="CNN加速结果"><a href="#CNN加速结果" class="headerlink" title="CNN加速结果"></a>CNN加速结果</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-21155.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ul><li>与baseline(CPU)相比，i-SRAM-6T和8T能效提升分别位2.16x和2.4x；</li><li>i-SRAM-8T的能效最优，这是由于其供电电压低；</li><li>i-SRAM速度提升8.1x。</li></ul><h3 id="AES加速结果"><a href="#AES加速结果" class="headerlink" title="AES加速结果"></a>AES加速结果</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-21207.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/i-sram-interleaved-wordlines-for-vector-boolean-operations-using-srams/202198-21221.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ul><li>i-SRAM-6T和i-SRAM-8T能效提升分别为3.6x和3.5x；</li><li>运行时间提速3x；</li><li>从64KB memory中读取64-bit数据能耗为19.36pJ，对两个64-bit数据进行计算能耗为25.83pJ。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>X-SRAM: Enabling In-Memory Boolean Computations in CMOS Static Random Access Memories</title>
      <link href="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/"/>
      <url>/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/</url>
      
        <content type="html"><![CDATA[<h1 id="X-SRAM-Enabling-In-Memory-Boolean-Computations-in-CMOS-Static-Random-Access-Memories"><a href="#X-SRAM-Enabling-In-Memory-Boolean-Computations-in-CMOS-Static-Random-Access-Memories" class="headerlink" title="X-SRAM: Enabling In-Memory Boolean Computations in CMOS Static Random Access Memories"></a>X-SRAM: Enabling In-Memory Boolean Computations in CMOS Static Random Access Memories</h1><!-- TOC --><ul><li><a href="#x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories">X-SRAM: Enabling In-Memory Boolean Computations in CMOS Static Random Access Memories</a><ul><li><a href="#motivation">Motivation</a></li><li><a href="#x-sram%E6%94%AF%E6%8C%81%E7%9A%84%E6%93%8D%E4%BD%9C">X-SRAM支持的操作</a><ul><li><a href="#nor">NOR</a></li><li><a href="#nand%E6%93%8D%E4%BD%9C">NAND操作</a></li><li><a href="#%E5%88%86%E5%8E%8B%E5%AE%9E%E7%8E%B0imp%E5%92%8Cxor%E9%80%BB%E8%BE%91%E6%93%8D%E4%BD%9C">分压实现IMP和XOR逻辑操作</a></li><li><a href="#read-compute-store%E6%93%8D%E4%BD%9C">Read-Compute-Store操作</a></li><li><a href="#8supsup-%E6%99%B6%E4%BD%93%E7%AE%A1%E5%B7%AE%E5%88%86%E8%AF%BBsram">8<sup>+</sup> 晶体管差分读SRAM</a></li></ul></li><li><a href="#%E8%AF%84%E4%BC%B0%E7%BB%93%E6%9E%9C">评估结果</a></li></ul></li></ul><!-- /TOC --><!-- ## 总结<font color=red size=4>这是一篇没有价值的工作，虽然能够实现所说的操作，但是开销大，操作复杂，而且稳定性差。</font><font color=blue>不要往下看，浪费时间！！！不要往下看，浪费时间！！！不要往下看，浪费时间！！！</font> --><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>之前的基于SRAM的存内计算方案需要锁存计算结果，并需要额外的周期写回结果。</p><h2 id="X-SRAM支持的操作"><a href="#X-SRAM支持的操作" class="headerlink" title="X-SRAM支持的操作"></a>X-SRAM支持的操作</h2><h3 id="NOR"><a href="#NOR" class="headerlink" title="NOR"></a>NOR</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-133447.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>8T SRAM的单元结构如图3(a)所示，在传统6T SRAM上增加了M1和M2形成单独的read通路。</p><p>NOR操作如图3(b)所示，首先预充RBL，然后通过RWL开启M2。如果Q为1(图3(a)中Q和QB的位置需要互换一下才正确)，则M1也开启，RBL通过M2和M1放电，否则，RBL保持高电平。NOR操作的波形如图3(c)所示。</p><h3 id="NAND操作"><a href="#NAND操作" class="headerlink" title="NAND操作"></a>NAND操作</h3><p>NAND逻辑的实现是利用的单行漏电和多行漏电，RBL电压下降的速度不同来实现的。需要合适的RWL脉冲宽度控制，使得两行同时漏电（Case 11）可以将RBL拉低到反相器阈值以下，而单行打开（Case 01/10）在这段时间里无法将RBL拉低到反相器阈值以下，如图3(d)所示。这种脉宽调制的方法我是不太看好的，控制难度太高，速度和精度都无法做到很高，虽然本文中作者做了一些monte carlo的仿真(图4和图5)，但是与实际情况相差较大。还不如增加两个晶体管做成差分的读取通路，还可以实现XOR逻辑，面积可能并不会比这种大，因为M1/M2的管子不再受放电速度限制可以做到最小尺寸，整体来说这个方案面积开销会比较大。NAND的工作波形如图3(d)所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-153145.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-153200.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h3 id="分压实现IMP和XOR逻辑操作"><a href="#分压实现IMP和XOR逻辑操作" class="headerlink" title="分压实现IMP和XOR逻辑操作"></a>分压实现IMP和XOR逻辑操作</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-154913.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>IMP和XOR逻辑如图6(a)所示。cell 1对应的SL1驱动到VDD，cell 2对应的SL2接到GND。计算时将RWL1和RWL2打开，从而M1-&gt;M2-&gt;M3-&gt;M4实现了从VDD到GND的通路，由于M2和M3开启，RDBL处的电压可以看作M1和M4的分压。Case 00，M1和M4都关断，RDBL保持预充电压，Case 11，M1和M4都开启，RDBL是两者沟道电阻的分压，仍然接近预充电压。Case 01，M4将RDBL下拉到GND。Case 10，M1将RDBL上拉到VDD。通过控制反相器的PU/PD的驱动能力，可以使得INV2在RDBL电压远低于$V_{pre}$，接近0V时输出才翻转到1；INV1在RDBL电压远高于$V_{pre}$，接近VDD时，输出才翻转到0。因此，INV2输出高电平表明数据为(0,1)，INV3输出高电平时，数据为(1,0)。此时INV1实现了”A IMP B”蕴含逻辑，通过对INV2和INV3的输出做或操作，可以得到XOR逻辑。<font color="red">此处的反相器与执行NOR/NAND时的反相器不同，而且不能使用最小尺寸。</font></p><h3 id="Read-Compute-Store操作"><a href="#Read-Compute-Store操作" class="headerlink" title="Read-Compute-Store操作"></a>Read-Compute-Store操作</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-191805.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>RCS可以在一个周期内进行计算，并将计算结果写到目的地址，不需要锁存计算结果。读取/写入路径解耦使得同一个周期完成计算和存储可能。从图8(a)种可以看到：首先激活RWL1和RWL2进行计算，计算结果通过多路选择器控制Write Driver写入WWL3对应行种。</p><p><font color="blue">这个操作还比较有优势，在一个周期内完成Load/Commpute/Store，这跟无线项目的想法一致。此外，这一功能还能实现memory copy操作。但是存在两点挑战：（1）这个电路还是比较复杂，能不能在<a href="https://zongwuwang.github.io/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/">4+2T SRAM</a>方案或者Local Bitline方案上进行改进；（2）如何将数据对齐仍相当有挑战。</font></p><h3 id="8-晶体管差分读SRAM"><a href="#8-晶体管差分读SRAM" class="headerlink" title="8+ 晶体管差分读SRAM"></a>8<sup>+</sup> 晶体管差分读SRAM</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-200806.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>这个就是我在之前提到的使用差分读通路，如图9(a)所示，使用9T实现。图9(b)显示的是9T SRAM实现NOR和NAND的波形，这与6T SRAM一摸一样。</p><p>为了感测bit-wise NAND和NOR操作的结果，图9(c)也展示了通过偏斜某一晶体管实现的非对称SA结构。偏斜晶体管可以通过多种途径实现，如晶体管尺寸，阈值电压和体偏电压等。如图9(c)所示，如果晶体管$M_{BL}$的尺寸大于$M_{BLB}$，其载流能力增加。对于“01”和“10”的情形，RBL和RBLB同时放电。但是由于$M_{BL}$的载流能力大于$M_{BLB}$，因此$SA_{out}$节点放过点更快，交叉耦合的反相器对最终会使得$SA_{out}$稳定在“0”。对于“11”的情形，RBL放电，RBLB保持为VDD，SA放大RBL和RBLB之间的电压差，最终导致$SA_{out}$稳定在“1”。对于“00”的情形，与“11”情形相反，最终$SA_{out}=1$。综上，$SA_{out}$实现了AND操作，$SA_{outb}$输出NAND操作结果。<br>同理，我们也可以设计$M_{BLB}$的尺寸大于$M_{BL}$，最终SA实现OR/NOR操作。<br>两个SA并行工作，实现AND/NAND/OR/NOR/XOR操作。</p><p>Monte Carlo仿真结果：</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-203034.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>工艺角仿真结果：</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-203048.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="评估结果"><a href="#评估结果" class="headerlink" title="评估结果"></a>评估结果</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-203523.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>表1展示了SRAM支持的各种操作的延迟和能耗，并且分析了各类操作的优缺点。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-204520.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图13显示了整个仿真的系统架构，采用的是Intel Nios-II处理器和Avalon总线，X-SRAM作为总线连接的协处理器，一共处理两条包含三个地址的指令。<br>仿真所用的Benchmark为AES加解密，其中可用于RCS-XOR和RCS-Copy加速的部分占整体运行时间的92%。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/x-sram-enabling-in-memory-boolean-computations-in-cmos-static-random-access-memories/202197-204547.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>实验结果如图14所示，在128b和256b 密钥的ECB模式下，访存分别减少74.7%和74.6%。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin</title>
      <link href="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/"/>
      <url>/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/</url>
      
        <content type="html"><![CDATA[<h1 id="A-4-2T-SRAM-for-Searching-and-In-Memory-Computing-With-0-3-V-VDDmin"><a href="#A-4-2T-SRAM-for-Searching-and-In-Memory-Computing-With-0-3-V-VDDmin" class="headerlink" title="A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin"></a>A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin</h1><!-- TOC --><ul><li><a href="#a-4--2t-sram-for-searching-and-in-memory-computing-with-03-v-vddmin">A 4 + 2T SRAM for Searching and In-Memory Computing With 0.3-V VDDmin</a><ul><li><a href="#%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D">背景介绍</a></li><li><a href="#%E7%8E%B0%E6%9C%89%E5%B7%A5%E4%BD%9C%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98">现有工作存在的问题</a></li><li><a href="#%E6%9C%AC%E6%96%87%E7%9A%84%E7%9B%AE%E6%A0%87">本文的目标</a></li><li><a href="#%E6%9C%AC%E6%96%87%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82">本文工作细节</a><ul><li><a href="#4--2t-sram-cell-%E7%BB%93%E6%9E%84">4 + 2T SRAM Cell 结构</a></li><li><a href="#sram%E6%94%AF%E6%8C%81%E7%9A%84%E6%93%8D%E4%BD%9C%E6%A8%A1%E5%BC%8F">SRAM支持的操作模式</a></li></ul></li><li><a href="#%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C">测试结果</a></li><li><a href="#%E6%80%BB%E7%BB%93">总结</a></li></ul></li></ul><!-- /TOC --><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-14056.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>传统的冯诺依曼 (CVN) 架构在memory bank和计算元素之间持续传输数据，会产生大量的能源和延迟成本，这些成本可能会影响系统功率和性能，如图1所示。为了最小化能耗和延迟，最近提出了IMC(In-Memory Computing)。IMC同时激活多行，直接在BL上进行逻辑操作。IMC不仅减少了数据移动以及操作的延迟，而且受益于memory bank的高带宽，有可能实现高并行计算。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-14602.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>如图2所示，基于6T SRAM的IMC相比于传统冯诺依曼（CVN）显示出比较大的能效和速度优势。</p><h2 id="现有工作存在的问题"><a href="#现有工作存在的问题" class="headerlink" title="现有工作存在的问题"></a>现有工作存在的问题</h2><p>但是SRAM-based IMC仍存在一下问题：</p><ul><li>当多行同时激活时，传统的6T SRAM的读取噪声容限会降低。因此需要WL欠驱动来改善噪声容限，这会大幅度降低读取速度。此外，由于读取噪声容限下降，$VDD_{min}$被限制在大约0.7V。因此整体功耗很高。（memory access和leakage仍然主导IMC的系统能耗，如图2b所示。）</li><li>8T SRAM通过隔离SRAM的读取路径和编程路径，能够有效的提高读取的噪声容限，但是面积开销会增加30%。同时由于只有一根BL用于读取，8T SRAM只能实现AND逻辑。</li><li>10T SRAM能够克服8T SRAM的不足，但是会带来更大的面积开销。</li></ul><h2 id="本文的目标"><a href="#本文的目标" class="headerlink" title="本文的目标"></a>本文的目标</h2><p>因此，本文的目标是：<font color="blue">提出4 + 2T SRAM单元的方案，能够实现比传统6T SRAM更好的读取噪声容限，同时带来较小的面积开销，以及以较小的能耗支持更多的计算。</font></p><h2 id="本文工作细节"><a href="#本文工作细节" class="headerlink" title="本文工作细节"></a>本文工作细节</h2><h3 id="4-2T-SRAM-Cell-结构"><a href="#4-2T-SRAM-Cell-结构" class="headerlink" title="4 + 2T SRAM Cell 结构"></a>4 + 2T SRAM Cell 结构</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-15742.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该论文提出的4 + 2T SRAM结构如图3(a)所示。该SRAM中PU是使用DNW制作的深耗尽PMOS，能够通过体偏效应控制PMOS的阈值电压，从而不需要PG，只需要四个管子即可进行SRAM的编程。同时，读取BL也通过栅控晶体管与SRAM cell进行隔离，cell的电位能够通过栅控晶体管控制BL的放电与否，但是BL上的电压无法反向传播改写SRAM的值，因此可以同时打开多行SRAM进行计算。此外，互补的RBL和RBLB可以实现更多的逻辑操作。</p><h3 id="SRAM支持的操作模式"><a href="#SRAM支持的操作模式" class="headerlink" title="SRAM支持的操作模式"></a>SRAM支持的操作模式</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-21449.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>4 + 2T SRAM支持的所有操作以及各端口电压配置如表1所示。</p><ol><li><p>Write</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-21738.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图5展示了对2x2 SRAM阵列进行写操作。在Standby模式下，WBL和WBLB都处于高电平$VDD_H$，其中$VDD_H$高于$VDD$。对SRAM单元进行写操作时，以写”0”为例，先将WBL拉低至GND，此时节点n1从$VDD$降低至$V_{thp}$。然后拉低WWL，以降低PU的阈值电压，n1对应的PU导通，将n1拉低到0，同时n2对应的PU开启，PD关断，n2被上拉到1，WBL/WBLB上的输入会被写入SRAM单元中。</p></li><li><p>Read</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-24145.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>正常读操作如图9(a)所示，读操作时，某一行对应的RWL/RWLB被拉低到GND以激活读操作，SRAM cell保存的值决定两个栅控晶体管的开关，从而导致RBL或RBLB连通到RWL或RWLB放电，通过两个差分SA可以检测出RBL和RBLB上的电压。这边存在两点考虑：(1) 使用差分SA代替单端反相器，以提高感测速度；(2) 如果未选择行保存的值为1，则会导致RWL向RBL漏电，RBL无法下拉到GND，因此使用差分交叉耦合SA，能够检测RBL上很小的电压下降。</p></li><li><p>In-Memory-Logic operations</p><p>如图9(b)所示，该电路支持AND, NOR和XOR逻辑操作，所有的逻辑操作都在一个周期内完成。</p></li><li><p>BCAM</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-24717.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>BCAM操作如图11(a)所示，此时RBL和RBLB复用为SL和SLB，作为搜索的输入。RWL复用为ML。如果搜索的属于与该行保存的数据完全匹配，则不存在任何的ML不存在任何的放电通路。否则，SL或SLB将ML拉低，行方向的SA用于BCAM的检测。<br>该方案于传统的6T SRAM-based BCAM的优势在于：(1) 搜索仍是按行进行，因此保存的数据不需要转置（按列保存）；(2) 多行同时激活，数据不会被改写。图12展示的是一个BCAM搜索的例子。<br><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-25515.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p></li><li><p>TCAM</p><p>TCAM操作原理如图11(b)所示，操作于BCAM类似，区别在于使用2个cell保存三种状态。图13展示的是一个TCAM搜索的例子。<br><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-25525.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p></li></ol><h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95055.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95240.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95317.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图16显示了测量单元的write margin，绿色区域表明超过5$\sigma$的write margin，其中标注的balanced green region至少存在200mV margin。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95331.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图17显示：</p><ul><li>0.8V VDD下，写频率达到600MHz；</li><li>最小供电电压为VDD/VDDH=0.25/0.30V；</li><li>最优的写能效为4.02 fJ/bit，对应VDD=0.35V.</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-95920.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图18是在1-bit mismatch下测量，结果表明：</p><ul><li>BCAM操作的$VDD_{min}=0.35V$，此时对应最优的BCAM搜索能效0.13 fJ/bit。</li><li>TCAM和TCAM实现的频率相同，在VDD=0.8V时达到225MHz。</li><li>TCAM的搜索能耗是BCAM的2倍。</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-100412.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图19表明：</p><ul><li>read $VDD_{min}=0.25V$;</li><li>logic operation $VDD_{min}=0.35V$（emploing single-port sensing and half-strength SA）;</li><li>最优读能效为3.96 fJ/bit，对应VDD=0.35V；</li><li>最优逻辑操作能效为6.57 fJ/bit，对应VDD=0.35V；</li><li>最高读频率350 MHz;</li><li>最高逻辑操作频率270 MHz。</li></ul><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-100427.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>与近存计算相比，总延迟降低35%，总能耗降低25%。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-103838.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>实现最低的访问能耗和比较好的$VDD_{min}$</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-103854.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>我们以最小的面积开销实现了可比的$VDD_{min}$和最低的读取能量。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/07/a-4-2t-sram-for-searching-and-in-memory-computing-with-0-3-v-vddmin/202197-103908.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>4 + 2T SRAM方案：</p><ul><li>相比于8T SRAM方案，面积节省15%。</li><li>差分解耦读取路径可实现可靠的多字同时激活以执行布尔逻辑功能。</li><li>与近内存计算相比，IMC 分别节省了 35% 和 25% 的延迟和能源。</li><li>BCAM 在 0.35 V 下达到 0.13 fJ/search/bit。</li><li>工艺角仿真实现0.3V读/写$VDD_{min}$。</li><li>该工作需要额外的电压供电。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Survey of SRAM-based Processing-in-Memory Techniques and Applications</title>
      <link href="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/"/>
      <url>/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/</url>
      
        <content type="html"><![CDATA[<h1 id="A-Survey-of-SRAM-based-Processing-in-Memory-Techniques-and-Applications"><a href="#A-Survey-of-SRAM-based-Processing-in-Memory-Techniques-and-Applications" class="headerlink" title="A Survey of SRAM-based Processing-in-Memory Techniques and Applications"></a>A Survey of SRAM-based Processing-in-Memory Techniques and Applications</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>随着冯诺依曼计算架构越来越受到数据移动开销的限制，研究人员开始探索内存处理(PIM)技术来抵消数据移动开销。由于SRAM的广泛使用，用于SRAM的PIM技术有望加速广泛的计算系统和应用程序。在本文中，我们对使用SRAM存储器进行内存处理的技术进行了调查。我们回顾了使用SRAM-PIM来实现布尔运算、搜索和算术运算，以及用于机器学习（尤其是神经网络）和自动机计算的加速器。本文旨在通过向算法和硬件架构领域的研究人员介绍基于SRAM的PIM技术的最新发展来加速协同设计工作。</p><h2 id="索引词"><a href="#索引词" class="headerlink" title="索引词"></a>索引词</h2><p>Review, deep neural networks, SRAM, cache, computing in memory, neural network, automata computing</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>数据传输产生的能量比算术运算高一百多倍。因此，传统的“冯诺依曼式”以计算为中心的处理器受到数据移动开销的严重限制。“内存处理”（PIM）是一种避免数据移动惩罚的有前途的方法。由于SRAM是一种商业成熟的技术，并且已经可用于各种规模和形状的计算系统，因此SRAM-PIM方法可以对计算行业的格局产生革命性的影响。</p><p>要了解SRAM-PIM的潜力，以具有多级缓存的CPU为例。在缓存子系统中，数据移动以两种方式发生。首先，数据传输发生在缓存级别之间。例如，数据从LLC移至L1，然后移至寄存器，最后移至功能单元。启用PIM的LLC可以避免这些开销。此外，共享LLC可以降低两个内核之间共享数据的开销，因为可以避免通过共享LLC在不同内核的私有L1缓存之间传输块。其次，由于H树互连上的数据传输和控制结构，缓存内部会产生延迟。在4GHz频率下，SRAM访问和LLC访问延迟分别为1个周期和30个周期。由于PIM方案仅访问SRAM阵列，因此它们产生的延迟可以忽略不计。</p><p>SRAM-PIM可以极大地有益于数据密集型应用，例如神经网络和模式匹配。例如，神经网络训练在大型数据集上运行，推理涉及对不同层的权重的计算。完全在SRAM中执行布尔运算和算术运算可以提高它们的效率。类似地，基因组学和自然语言处理中的许多模式匹配应用程序执行有限自动机式处理。在模式匹配应用中使用SRAM-PIM时，自动机状态转换完全发生在存储器内部。这避免了在基于CPU的处理中产生的分支错误预测和不规则内存访问的开销。此外，使用具有高扇入和扇出的互连可以将输入序列与许多候选序列相匹配。因此，SRAM-PIM可以提供大量的并行性。同样，在内存中执行搜索和比较操作可以提升压缩、编码和搜索引擎的性能。基于PIM的逻辑操作可以加速加密、图形索引和数据库应用程序。</p><p>然而，SRAM-PIM的使用也带来了许多挑战。在6T SRAM中，PIM的使用会导致严重的可靠性问题，例如读取干扰和读取噪声容限下降。虽然使用8T或10T单元减轻了这些限制，但它们也会导致更高的面积开销。此外，为大规模DNN设计加速器会带来诸如大列电流等挑战，这会导致供电问题和传感故障。最后，模拟域操作需要消耗大量面积和能量的ADC/DAC。显然，实现SRAM-PIM的全部潜力需要新颖和智能的技术。</p><p>在本文中，我们对基于SRAM的PIM技术进行了调研。图1显示了该论文的概述。第2节提供了动机和分类。第3节介绍了基于SRAM-PIM的逻辑、搜索和算术运算的实现。第4节展示了使用SRAM-PIM来加速神经网络应用。第5节展示了它在加速机器学习、自动机处理和偏微分方程求解方面的用途。第6节总结了论文，并简要提及了未来的研究挑战。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-112116.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>本文中经常使用以下缩写词：位线（BL）、位线条（BLB）、二元/-卷积/深度神经网络（BNN/CNN/DNN）、反向传播（BWP）、二元/三元内容可寻址存储器 (BCAM/TCAM)、缓存自动化 (CA)、卷积 (CONV)、数模转换器 (DAC)、双端口互锁存储单元 (DPDICE)、确定性下推自动机 (DPDA)、特征图 (fmap)、完全连接（FC）、指令集架构（ISA）、反相器（INV）、最近邻（kNN）、末级缓存（LLC）、查找表（LUT）、本地位线（LBL）、乘法和累加（MAC）、单片 3 维 (M3D)、矩阵向量乘法 (MVM)、非确定性有限自动机 (NFA)、感测放大器 (SA)、单指令多线程/数据 (SIMT/SIMD)、源代码行 (SL)、“连续-近似寄存器-模数转换器”（SAR-ADC）、支持向量机（SVM）、硅通孔（TSV）、“超大指令字”（VLIW）、字线(WL)、写 WL (WWL)、xnor 和累加 (XAC)</p><h2 id="动机和概述"><a href="#动机和概述" class="headerlink" title="动机和概述"></a>动机和概述</h2><p>在本节中，我们首先讨论实现基于SRAM的PIM（第2.1节）的挑战。为了正确看待事情，我们将SRAM-PIM方法与DRAM和RRAM中的PIM方法进行比较（第2.2节）。然后，我们提供了基于几个类别的研究工作分类（第2.3节）。</p><h3 id="基于SRAM的PIM的挑战"><a href="#基于SRAM的PIM的挑战" class="headerlink" title="基于SRAM的PIM的挑战"></a>基于SRAM的PIM的挑战</h3><ul><li><strong>SRAM密度低:</strong> SRAM具有低密度和高泄漏能量。因此，SRAM-PIM更适合小规模数据集。</li><li><strong>6T SRAM的局限性:</strong> 使用6T SRAM更适合设计最后一级缓存，因为它们已针对该区域进行了优化。在6T SRAM中，激活多行会降低读取噪声容限。它可以创建短路路径，可以随机翻转单元状态。此外，在BL放电后，由于6T SRAM的读写路径是共享的，因此激活下一个WL会导致伪写操作。<br>为避免数据损坏，可以调整WL电压。这严重限制了操作频率，例如Jeloka等人在1V下使用800 MHz频率，Wang等人在1.1V时使用475 MHz频率。此外，由于工作裕度小，Vdd不能低于0.7V。这导致高动态和泄漏能量消耗。为了提高噪声容限，需要进行WL欠驱动，这会增加读取延迟。作为避免6T SRAM数据损坏问题的另一种解决方案，可以使用脉宽调制WL。该解决方案避免了同时激活两个WL，但将外围电路的面积增加了2倍以上。<font color="blue">这边可以加上BLADE的local bitline</font></li><li><strong>8T/10T SRAM的局限性：</strong> 为了克服6T SRAM的限制，可以使用8T或10Tbitcell。8T SRAM将读和写路径解耦，这允许独立优化它们的读/写操作。这提高了裕度并允许降低最小Vdd，这降低了功耗。然而，与6T SRAM相比，8T SRAM会导致30%的面积损失。此外，由于8T SRAM使用单个读取BL，因此它仅计算AND运算。需要特殊的架构来支持其他逻辑功能。10T SRAM克服了这个问题，但会导致更高的面积损失。</li><li><strong>模拟域的限制：</strong> 模拟域操作更容易受到工艺变化、噪声、非线性I-V特性和老化的影响。此外，使用ADC/DAC会降低信号精度并造成能量/面积损失。</li><li><strong>映射大型DNN的挑战：</strong> 大规模DNN具有数千个量级的权重矩阵。然而，由于以下原因，无法在SRAM中实现如此大的矩阵：(1) 多个WL的激活需要高列电流。这会导致大量的瞬时功率，从而产生热和功率传输问题。(2) 工艺变化会使SA产生偏移。随着列电流的上升，感测失败的可能性更高。(3) 长导线具有高阻容(RC)延迟。这些挑战可以通过对SRAM阵列进行分区来缓解，该阵列将大矩阵拆分为多个较小的矩阵。但是，如果使用二元神经元累积来自不同子阵列的部分和，则此方法可能会影响分类精度。</li></ul><h3 id="在不同内存中处理内存中-近内存方法"><a href="#在不同内存中处理内存中-近内存方法" class="headerlink" title="在不同内存中处理内存中/近内存方法"></a>在不同内存中处理内存中/近内存方法</h3><p>比较不同内存技术中的 PIM 方法是很有见地的。</p><ul><li><strong>DRAM:</strong> 基于DRAM的内存处理提出了至关重要的挑战。(1) 由于DRAM读取是破坏性的，PIM计算破坏了原始数据。为了避免数据丢失，需要复制到别处，这会导致很大的开销。(2) 感测DRAM电容的余量小，导致模拟计算错误。修改单元设计的技术会导致大量的面积损失。(3) 技术差异阻碍了PIM所需的外围逻辑与DRAM的轻松集成。(4) DRAM中使用的数据/地址加扰技术对将其用于PIM操作提出了挑战。基于DRAM的近数据计算技术利用芯片堆叠将逻辑芯片与DRAM芯片集成在一起。然而，这会在制造和操作期间产生问题。</li><li><strong>RRAM:</strong> RRAM的优点是单元面积小。然而，RRAM设备具有非常低的耐用性和较大的写入延迟/能量。因此，频繁的重量更新可能会导致达到耐力极限。此外，基于RRAM的PIM在支持浮点计算方面面临着严峻的挑战。这是因为RRAM单元和ADC的分辨率有限。这需要使用多个单元格来表示浮点值。此外，指数归一化需要多次操作，由于RRAM的高延迟和低写耐久性，这尤其昂贵。事实上，范伯格等人使用128个RRAM单元来存储双精度 (64b) 数，其中64个单元仅用于执行归一化和对齐。相比之下，SRAM-PIM技术完全在SRAM阵列内部执行数字浮点计算。此外，在BWP阶段，使用转置权重矩阵执行CONV。为此，执行逐列读取操作，这会降低吞吐量和能源效率。</li></ul><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p>表 1 根据架构和实验参数对作品进行分类。如表 1 所示，大多数工作仅进行了电路或架构级评估。只有少数作品对从电路到系统的整个堆栈进行了评估。<br>表 2 根据它们的优化策略对作品进行分类。<br>表3根据实验平台和参数对作品进行分类。<br>表 4 根据实验结果对作品进行分类，例如它们的吞吐量和能效值。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114508.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114532.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114715.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114730.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-114746.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="基于-SRAM-PIM-的搜索、逻辑和算术运算"><a href="#基于-SRAM-PIM-的搜索、逻辑和算术运算" class="headerlink" title="基于 SRAM-PIM 的搜索、逻辑和算术运算"></a>基于 SRAM-PIM 的搜索、逻辑和算术运算</h2><p>在本节中，我们将讨论基于SRAM-PIM的搜索操作（第3.1节）、逻辑运算（第3.2节）和算术运算（第3.3节）的实现。表5显示了由各种技术执行的基本操作。在BNN中，CONV操作被简单地计算为按位XNOR和population-count操作。因此，基于SRAM-PIM的XNOR实现可以加速BNN。<br>XOR运算可以使用NOR和AND运算来实现，如下所示： A XOR B = (A AND B) OR (A AND B)。大于/小于操作是通过减去操作数并读取MSB来执行的。大多数作品通过使用移位加法来执行乘法。对于有符号数的乘法，乘积的符号位是通过计算操作数的符号位的异或来获得的。</p><h3 id="搜索操作"><a href="#搜索操作" class="headerlink" title="搜索操作"></a>搜索操作</h3><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-161130.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>通常，BCAM使用10T SRAM，TCAM使用16T SRAM。然而，非推规则CAM位单元比推规则6T SRAM大得多，这使得CAM区域非常大。杰洛卡等人提出了一种使用推式6T SRAM位单元设计的CAM电路。它们以列方式存储单词，如图 2(a)所示。它们的电路设计如图 2(b)所示。WL分为WL-right和WL-left，它们创建了两个独立的存取晶体管。搜索查询及其互补分别应用于WL-right和WL-left。如果匹配，BL和BLB都保持在Vdd。在不匹配的情况下，它们中的一个或两个放电。使用两个单端SA分别读取它们。它们之间的AND运算显示列中的匹配项。该过程对所有列并行完成。总体而言，他们的技术将搜索数据与存取晶体管中存储的数据执行XNOR，然后在BL SA上执行AND运算。</p><p>TCAM需要为每个单词使用两列，这将其容量减少了一半。在TCAM中，0和1分别对应组合“00”和“11”，而X对应组合“01”。屏蔽位(X)不会拉低BL或BLB，因为它在两个位置都存储了1。因此，它匹配搜索查询的0和1。要写入CAM，可以在内存模式下以行方式写入数据的转置。但是，这只执行批量写入，不允许写入特定元素。为了允许逐列写入操作，他们提出了一种写入策略，该策略在BCAM的两个周期和TCAM的三个周期内完成。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-161206.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>SRAM可以在三种模式下运行：内存、BCAM或TCAM。在传统存储模式中，字按行存储，地址应用于WL，正在读取的数据在BL上可用。他们提出的存储器可以对以行方式存储的多个字执行AND和NOR运算。例如，要实现与运算，就使用了BCAM模式。在这里，通过向WL-left和WL-right都提供0来屏蔽搜索字符串的输入位（在图 3中显示为M）。使用它，可以激活多行的WL。在图 3中，搜索查询是(1,M,1,M)，它为第1行和第3行启用WL-right。如果第1行或第3行中的任何位为0，则预充电的BL被下拉。此外，所有WL左晶体管都被停用，所有BLB保持高电平。这计算第1行和第3行的按位与。</p><p>为了执行NOR操作，只有WL左存取晶体管被激活，并且在搜索查询中应用0。“01”模式激活A行的WL-left和B行的WL-right。这读取BLB SA上的A和BL SA上的B。这些的AND运算提供了输出。他们的CAM实现了比传统CAM设计高四倍的密度。然而，在CAM模式下，他们的技术以比内存模式低的速度运行。此外，实现可重构功能所需的额外外设会导致较小的面积开销。</p><p>位线计算方法基于以下观察：在同时激活多个（例如，高达64个）WL时，共享BL提供存储在这两个激活行中的数据之间的NOR和AND运算的结果。为了防止由于多行访问而导致数据退化，降低WL电压以偏置SRAM阵列上的写入。通过进一步降低WL电压，可以增强鲁棒性，但也会增加延迟。</p><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-161222.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>董等人提出了一种基于“深耗尽沟道”技术的4+2T SRAM单元。它可以执行逻辑操作并充当BCAM/TCAM。单元设计如图 4(a)所示。它具有解耦读写路径。该单元有6个晶体管，其中4个晶体管形成交叉耦合反相器对。这些逆变器具有不同的Vdd端子，用作WBL/WBLB。另外两个晶体管用作允许差分读取的存取晶体管。他们的单元有两个“栅极连接的差分读取端口”。这将存储节点与RWL和RBL/RBLB隔离。这提高了“读取噪声容限”并提高了激活多个字时的电路可靠性。该单元将n阱用作WWL，从而无需写存取晶体管。</p><p>他们使用差分RBL和RBLB来实现PIM操作。PIM操作的工作原理如图 4(b)所示。对于PIM，最初，RBLB和RBL都预充电到Vdd。此后，同时启用两对WL。如果A或B等于1，则RBL放电，因此，RBL计算(A NOR B)。如果A和B都等于1，则RBLB变高，因此，RBLB计算(A AND B)。他们用两个微小的差分SA评估RBLB和RBL。在通过来自Vdd的小电压降低RBL/RBLB时，SA在潜行电流消失之前将RBL/RBLB上的电压与参考电压(Vref)进行比较。由于SA的不同操作，AND/NAND和OR/NOR是同时计算的。两个SA结果之间的NOR门计算A XOR B。</p><p>对于CAM功能，RBL/RBLB提供搜索数据SL/SLB。此外，两个存取晶体管的RWL被分成ML/MLB。对于BCAM，一行的MLB和ML短接为一个ML。如果一行中的整个输入与存储的数据相同，ML保持高电平，否则它会被释放。每个ML都包含一个行级SA，其一端连接到Vref以评估结果。TCAM需要两个单元格。这里，ML[0]和MLB[1]相连，将单元A和B组合为一个TCAM单元。当AB单元格的值分别为00/11/01时，它表示1/0/X。他们的“4+2T单元”具有比6T SRAM更好的噪声容限和比8T SRAM更小的面积。此外，BCAM可以在0.3V的最小Vdd下运行。他们设计的局限性在于它依赖于一个不常见的4T位单元，该位单元面临不稳定和读取干扰问题。此外，它具有较差的性能/电压缩放（0.6V 时为 100Mhz）。</p><h3 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h3><h4 id="使用-2D-SRAM-对两个操作数的操作"><a href="#使用-2D-SRAM-对两个操作数的操作" class="headerlink" title="使用 2D SRAM 对两个操作数的操作"></a>使用 2D SRAM 对两个操作数的操作</h4><p><img "" class="lazyload placeholder" data-original="/2021/09/01/a-survey-of-sram-based-processing-in-memory-techniques-and-applications/202191-162315.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>阿加等人通过修改Jeloka等人提出的位线计算电路，提出了一种in-SRAM计算技术。他们添加了一个解码器来缓存子数组，这会激活两个WL，每个操作数一个。差分SA被重新配置以获得两个单端SA。它们用于分别感测绑定到位单元的两个BL。它们通过对BL和BLB进行NOR运算来扩展用于实现XOR运算的电路。为了比较两个字，他们使用有线NOR组合按位异或结果。搜索是通过与存储在子数组中的缓存块重复比较来执行的。为了将一个WL复制到另一个WL，SA的输出被反馈到BL。由于最后一个读取值要在下一个周期写入，因此“读写操作”合并以有效复制数据，如图5（a）所示。为了清零缓存块，在写操作之前，输入数据锁存器被复位。为了实现“无进位乘法”，首先将两个子阵列行进行“与”运算。然后，使用“XOR减少树”减少结果位。</p><p>PIM操作需要“操作数局部性”，即操作数必须映射到共享相同BL的子数组。他们将“块分区”定义为共享相同BL的子阵列中缓存块的集合。块分区中保存的任何两个缓存块之间都可以进行就地计算。考虑图 5(b)，它显示了一个带有四个子阵列的组。这里，子阵列中的每一行都有两个缓存块，因此每个子阵列都有两个块分区。就地计算可以发生在映射到相同“块分区”的块之间，例如，集合S1和S3中的块。如图 5(b)所示，他们的技术将集合的所有方式映射到相同的“块分区”，无论缓存块的存储方式如何，它都保留了操作数的局部性。此外，如图 5(c)所示，一些设置索引位（称为OLbits）用于决定块的存储体和分区。如果两个操作数的这些位相同，则将它们映射到同一分区。将集合的所有方式映射到同一分区的局限性在于它禁止并行标记数据访问。这种优化一般用在L1缓存中，以牺牲能量开销为代价来提高速度。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Chronos: Efcient Speculative Parallelism for Accelerators</title>
      <link href="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/"/>
      <url>/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/</url>
      
        <content type="html"><![CDATA[<p>ASPLOS-2020<br>Author: Maleen Abeydeera, Daniel Sanchez<br>Affiliations: MIT</p><!-- TOC --><ul><li><a href="#motivation">Motivation</a></li><li><a href="#target">Target</a></li><li><a href="#introduction">Introduction</a><ul><li><a href="#%E5%85%88%E5%89%8D%E5%8A%A0%E9%80%9F%E5%99%A8%E4%B8%AD%E7%9A%84%E5%B9%B6%E8%A1%8C%E7%B1%BB%E5%9E%8B">先前加速器中的并行类型</a></li><li><a href="#%E5%85%88%E5%89%8D%E7%9A%84%E6%8E%A8%E6%B5%8B%E6%9E%B6%E6%9E%84%E4%BE%9D%E8%B5%96%E4%BA%8E%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7">先前的推测架构依赖于缓存一致性</a></li><li><a href="#%E6%8A%95%E6%9C%BA%E6%89%A7%E8%A1%8C%E7%9A%84%E5%8E%9F%E5%9B%A0">投机执行的原因</a></li></ul></li><li><a href="#slot%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B">SLOT执行模型</a><ul><li><a href="#slot">SLOT</a></li><li><a href="#%E5%B0%86%E5%A4%9A%E5%AF%B9%E8%B1%A1%E8%AE%A1%E7%AE%97%E6%98%A0%E5%B0%84%E5%88%B0slot">将多对象计算映射到SLOT</a></li><li><a href="#discussion">Discussion</a></li></ul></li><li><a href="#chronos%E7%B3%BB%E7%BB%9F">Chronos系统</a><ul><li><a href="#%E8%AE%BE%E8%AE%A1%E8%A6%81%E6%B1%82%E5%92%8C%E6%8A%80%E6%9C%AF">设计要求和技术</a></li><li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%89%E5%BA%8F%E6%8E%A8%E6%B5%8B">分布式有序推测</a></li><li><a href="#%E4%BB%BB%E5%8A%A1%E5%8D%95%E5%85%83%E8%AE%BE%E8%AE%A1">任务单元设计</a><ul><li><a href="#%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97">任务队列</a></li><li><a href="#%E6%8F%90%E4%BA%A4%E9%98%9F%E5%88%97">提交队列</a></li></ul></li></ul></li></ul><!-- /TOC --><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>先前的加速器专注于易于利用并行性的领域，例如深度学习，并依赖于传统的并行化技术，如数据并行或数据流执行。</p><h2 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h2><p>在本文中，作者专注于为需要推测执行来提取并行性的应用程序构建加速器。这些应用程序由动态创建并对共享数据进行操作的任务组成，其中对共享数据的操作必须按特定顺序发生才能正确执行。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>之前支持推测的硬件包括TLS (Thread-Level Speculation)和HTM (Hardware Transactional Memory)，这些推测架构依赖于Cache一致性，通过修改一致性协议来检测任务之间的冲突，这在通用处理器中开销不算大，但是对于小型专用加速器来说是大的开销。</p><p>这篇论文的作者提出了一种新的硬件解决方案，不需要使用一致性，共享的数据映射到整个系统中，工作负载被划分成小的task，这些task有一个属性就是最多访存一个共享数据对象。此外，该架构是以数据为中心，task发送到需要操作的数据所在位置。最后，这些task通过时间戳顺序执行。==这一段对于工作的总结是对introduction的翻译，没法充分理解，在理解全文之后再进行凝练。==</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/2021831-215733.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>例如，考虑离散事件模拟(des)，它在模拟数字电路、网络系统和物理过程方面具有广泛的适用性。离散事件模拟由动态创建的任务组成，这些任务可以在同一个模拟对象上运行，并且必须以正确的模拟时间顺序运行。非推测地运行这些任务需要过多的同步并限制并行性。推测性地运行任务更有利可图。</p><p>如Listing 1所示，每个des任务在特定时间处理一个门输入切换。如果此输入切换导致门的输出切换，则任务会在适当的时间将所有连接到该输出的输入的事件排入队列。顺序实现以模拟时间顺序一次处理一个任务，并在优先级队列中维护要处理的任务集。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/2021831-220352.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>以数字电路模拟为例，如Figure 1所示。Figure 1(a) 显示了具有输入波形和传播延迟的电路，Figure 1(b) 显示了在该电路上执行 des 的任务图。任务之间的箭头表示父子依赖关系（例如，任务O1创建任务A4和X6）。x轴显示任务顺序，y轴中任务的位置代表它操作的门。</p><p>在这个des中，我们可以发现一个很重要的现象：只有在同一门上操作的任务才具有数据依赖性；其他（例如，O1 和 N2）可能会在不违反正确性的情况下运行失序。但是任务和依赖项是未知的，因此乱序运行任务并不简单。虽然在des中，每个任务对单个对象（一个门）进行操作，并且这个对象是预先知道的。但这不足以确定哪些任务可以安全运行，因为一个任务可能与另一个在程序顺序中较早出现但尚不存在的任务相关。假设首先执行任务O1，产生任务X6。此时X6是系统中最早对XOR门进行操作的任务。但是执行X6会产生不正确的结果，因为X6必须遵循较早的依赖数据的任务X3，该任务尚不存在（因为N2尚未运行）。</p><h3 id="先前加速器中的并行类型"><a href="#先前加速器中的并行类型" class="headerlink" title="先前加速器中的并行类型"></a>先前加速器中的并行类型</h3><p>本文通过两个因素对并行类型进行分类：（1）任务是预先知道的还是动态创建的？（2）如果任务对共享数据进行操作，它们应该如何同步以应对算法的数据依赖性并产生正确的结果？<br>按此标准可以分为四类：</p><ul><li><strong>Static parallelism:</strong> 如果预先知道任务及其数据依赖性，则调度可以静态完成，不需要或需要非常简单的运行时机制。在对常规数据结构（例如密集矩阵）进行操作时会出现静态并行性。大多数先前的加速器都专注于静态并行性，如通过构建深度流水线和数据并行硬件，例如DaDianNao和Google的TPU。</li><li><strong>Dynamic parallelism with independent tasks:</strong> 某些算法，例如对树或图形进行操作的算法，必须动态创建任务，因为它们需要做更多的工作。在最简单的情况下，任务对不相交的数据进行操作，并且共享数据访问不需要同步。他们采用了由ESL和Cilk开创的fork-join模型。ParallelXL和TAPAS加速器针对这种动态并行性。它们的关键组成部分是对任务创建和负载平衡的硬件支持。</li><li><strong>Non-speculative synchronization of dependent tasks:</strong> 先前的工作已经展示了加速器，其中任务对共享数据进行操作，但大多数同步是通过停止而不是推测来实现的。</li><li><strong>Speculative synchronization of dependent tasks:</strong> 最后，Ma等人在FPGA上为图形分析应用程序构建加速器。它们支持原子任务，每个任务可以访问多个地址，冲突检测是使用全局共享的地址跟踪结构实现的，类似于一致性目录。因此，这种方法类似于基于一致性的冲突检测，并受到额外开销的影响。</li></ul><h3 id="先前的推测架构依赖于缓存一致性"><a href="#先前的推测架构依赖于缓存一致性" class="headerlink" title="先前的推测架构依赖于缓存一致性"></a>先前的推测架构依赖于缓存一致性</h3><p>先前的推测架构很难应用于加速器，因为它们都依赖于一致的缓存层次结构来执行推测执行，通过一致性协议检测任务之间的冲突。它需要实现一致的缓存和推测跟踪结构，虽然对于通用内核来说开销很小，但对于小型专用内核来说太昂贵了。(虽然依赖一致性对于多核来说是合理的，但对于加速器来说却是昂贵的。 一般的加速器和特别是可重新配置的硬件没有支持基于失效的冲突检测的一致缓存层次结构。实现一致性会增加复杂性、延迟和重要的片上 SRAM 以实现跟踪共享者的目录。除了一致性之外，对具有任意读写集的任务执行冲突检测会增加额外的开销，例如，每个核心价值几千字节的 Bloom 过滤器，这对于专门的处理核心来说太繁重了。)</p><h3 id="投机执行的原因"><a href="#投机执行的原因" class="headerlink" title="投机执行的原因"></a>投机执行的原因</h3><p>通常，当任务具有未知的读写集或任务间顺序约束时，需要进行推测。<br>为了应对这一挑战，在本文中，我们提出了一个硬件系统，该系统在不使用一致性的情况下实现推测执行。 相反，该系统遵循以数据为中心的方法，其中共享数据映射到整个系统； 工作被分成小任务，每个任务最多访问一个共享对象； 并且任务总是被发送到它们的数据被映射的地方运行。 为了强制跨任务组或其他顺序约束的原子性，任务通过时间戳排序（这些是完全与物理时间分离的程序指定的逻辑时间戳）。</p><p>通过SLOT (Spatially Located Ordered Tasks) 执行模型将这些语义形式化。在 SLOT 中，所有工作都通过使用时间戳排序的任务进行。一个任务可以创建在它们之后排序的子任务，并且父任务直接将输入值传递给子任务。==每个任务必须对单个读写对象进行操作，该对象必须在创建任务时声明（除此限制外，任务可以访问任意数量的只读数据）==</p><p>而本文提出的架构就是针对SLOT执行模型的实现，这可以在没有缓存一致性协议的情况下实现完全分布式操作。</p><h2 id="SLOT执行模型"><a href="#SLOT执行模型" class="headerlink" title="SLOT执行模型"></a>SLOT执行模型</h2><p>SLOT 限制每个任务访问单个读写对象，这在创建任务时必须知道。</p><h3 id="SLOT"><a href="#SLOT" class="headerlink" title="SLOT"></a>SLOT</h3><p>SLOT 应用程序由有序的、动态创建的任务组成。 每个任务都可以用软件或硬件来实现。 我们独立于实现来描述执行模型，并使用软件 API 对其进行说明。</p><p>每个任务在创建时都有两个属性：时间戳和对象ID。时间戳指定顺序约束：系统保证任务似乎按时间戳顺序执行。 具有相同时间戳的任务可以以任何顺序运行，但都是原子的（即它们不交错）。<br>对象id是指定任务之间数据依赖性的整数：当且仅当两个任务具有相同的对象id时，它们才被视为数据相关。对象ID限制每个任务最多访问共享内存中的一个读写对象。请注意，此限制仅适用于读写数据。一个任务可以访问任意数量的只读数据。<br>SLOT任务可以通过指定子任务的类型、时间戳、对象ID和它可能需要的任何输入数据值，在发现更多工作时创建子任务。每个子任务可能有任何大于或等于其父任务的时间戳。</p><p>在SLOT中，父子关系是单向的：父任务可以创建值并将值传递给它的子任务，但父任务在子任务之前被排序，因此在子任务执行之前完成。子任务不能返回值或与其父母通信。这与像Cilk这样的fork-join执行模型不同，在这种模型中，父母等待他们的孩子完成。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-10208.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ul><li><strong>API:</strong> Listing 2通过显示des任务的实现来说明SLOT软件API。在软件中，每个任务都由一个函数实现。该实现与Listing 1中的顺序实现几乎相同：每个任务模拟特定门的输入切换。这段代码通过调用slot::enqueue创建新任务，而不是将任务排入优先级队列，它指定了子任务的类型（它的函数指针，因为它是一个软件任务）、时间戳、对象ID和任何附加参数（门在这种情况下输入）。</li><li><strong>SLOT enables coherence-free conﬂict detection:</strong> 通过限制每个任务最多访问一个读写对象，SLOT的实现可以在没有复杂跟踪结构的情况下执行分布式冲突检测。如果实现将对象id映射到核心或区块，并将每个任务发送到其对象id映射的位置，那么查找冲突就成为本地操作。<br>例如，如果Fig. 1在四核系统上运行，NAND、OR、XOR和AND门可以映射到内核1-4。然后，如果任务X3在X6已经运行后到达核心3，核心3可以通过将X3的对象ID与仍然推测的任务的对象ID进行比较，在本地确定X3的冲突（相同门和更高时间戳的任务，在本例中为{X6}）。</li></ul><h3 id="将多对象计算映射到SLOT"><a href="#将多对象计算映射到SLOT" class="headerlink" title="将多对象计算映射到SLOT"></a>将多对象计算映射到SLOT</h3><p>多对象事务也可以表示为SLOT任务，方法是将每个事务分解为多个单对象任务，每个任务访问一个对象，并为每个事务提供不相交的时间戳范围。这样，事务中的任务不会与其他事务中的任务重叠。</p><p>例如，考虑一个银行应用程序，其中交易在帐户之间转移资金。每笔交易都必须自动减少源帐户的余额并增加目标帐户的余额。每个帐户都应该是不同的对象，但由于账户余额是读写数据，单个任务不能访问两个账户。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-11826.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Fig. 3显示了任务顺序如何使这成为可能。我们使用两个SLOT任务实现每笔交易，每个任务操作一个帐户：第一个减少源的余额并创建第二个任务来增加目的地的余额。每个事务都有一个不相交的时间戳范围，因此来自不同事务的任务不会交错。</p><p>这种技术推广到读写操作的任意组合。例如，我们的maxflow实现（第5节）使用它在图顶点的邻域上执行复杂的原子操作。</p><p>虽然将每个事务分解为许多小任务可能会给软件运行时增加大量开销，但小任务是加速器的自然匹配，因为硬件执行任务管理，小任务需要简单的处理元素。</p><h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><ul><li><strong>SLOT细粒度任务的好处:</strong> SLOT与先前工作相比的主要优势是实现无相干冲突检测。此外，先前的工作表明，即使在支持具有任意读/写集的任务的系统中，这种划分通常也是可取的，主要有以下三个原因：</li></ul><ol><li>增加并行性：将长串行事务分解为短任务允许这些任务并行运行。</li><li>减少中止的影响：在误推测时，只有冲突的任务被中止，而不是整个事务。</li><li>增加数据重用：不是在事务运行的系统中共享数据，而是将任务发送到靠近它们的数据运行，避免缓存行乒乓。由于每个任务消息比缓存行小得多，这减少了流量；并且任务是异步发送和执行的，因此它们的延迟比同步内存访问更容易隐藏。</li></ol><ul><li><strong>SLOT的局限:</strong> 虽然将程序分成短的单对象任务通常是有益的，但在一种情况下，基于一致性的冲突检测会优于SLOT：如果应用程序由很少修改的读写数据主导，这些数据具有大量重用，则基于一致性的冲突检测将允许在整个系统中缓存这些数据，在本地的零星写入之间进行读取，而SLOT需要在单独的任务中隔离对这些数据的每次访问，并将它们发送到一个地方。<br>我们在目标应用程序中没有发现这种行为，因此我们没有针对这种情况优化SLOT。SLOT的一个简单扩展可以通过让任务写入其对象ID未涵盖的地址来解决此问题。然后，系统可以将很少修改的数据视为只读数据，并允许将它们私下缓存。在写入时（这种情况很少见），一个简单的实现可以刷新所有缓存并中止所有未来任务；更复杂的实现可能会执行更精确的刷新和冲突检测。我们将对这些实施选择的详细研究留给未来的工作。</li></ul><h2 id="Chronos系统"><a href="#Chronos系统" class="headerlink" title="Chronos系统"></a>Chronos系统</h2><p>Chronos是一个架构框架，可以轻松地为具有有序并行性的应用程序设计加速器。<br>Chronos通过提供有效实现SLOT执行模型的架构模板来实现这一点。然后加速器可以通过定义他们自己的任务处理引擎或配置Chronos的非核心组件来专门化这个模板。通过这种划分，创建Chronos加速器就像指定处理引擎一样简单；该框架负责处理有序任务管理和推测执行的复杂性。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-13713.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Fig. 4显示了Chronos的组织架构。Chronos是一种平铺设计，具有完全分布式的任务管理和推测机制。每个tile都有多个执行任务的处理元素(PE)、一个本地（非一致性）缓存和一个用于排队、分派和提交有序任务的任务单元。</p><p><font color="blue">即使我们无法使用这个架构来完全处理无线项目的通用程序，但是这个架构解决了一类任务，可以放置适量的PE来处理带有这种特性的部分代码。</font></p><h3 id="设计要求和技术"><a href="#设计要求和技术" class="headerlink" title="设计要求和技术"></a>设计要求和技术</h3><ul><li><strong>高吞吐量任务管理:</strong> 短任务对系统提出了高吞吐量要求。例如，如果每个任务需要20个周期来执行，那么具有200个PE的Chronos系统每个周期必须创建、分派、冲突检查和提交10个任务以保持PE忙碌。这迫使设计没有集中组件：所有任务管理和推测机制必须完全分布式。Chronos的平铺设计实现了这一点。此外，每个tile的任务单元也需要保持高吞吐量。</li><li><strong>大投机窗口:</strong> 为了防止顺序限制并行性，系统必须能够在最早的未完成任务之前进行推测。更具体地说，由于顺序限制，任务在提交之前可能会在很长一段时间内处于推测状态——远远超过它们执行所需的时间。因此，系统应该能够跟踪比运行任务更多的推测任务。例如，正如我们将在Sec.6中看到的那样，有些应用程序每个运行任务需要大约10个推测任务</li></ul><p>这些要求强制完全分布式、深度无序执行。</p><h3 id="分布式有序推测"><a href="#分布式有序推测" class="headerlink" title="分布式有序推测"></a>分布式有序推测</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-34155.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Chronos使用推测执行来消除顺序约束。<br>Chronos可以在创建后立即运行任何任务，即使它的祖先仍然是推测性的。图5显示了每个任务的执行流程。顶部水平箭头表示正确的推测。当一个任务被创建时，它被发送到一个tile，它在那里保持空闲，排队直到它准备好分派。tile按时间戳顺序将空闲任务分派给PE。正在运行的任务完成执行后，它会保持推测（处于完成状态），直到系统确定可以安全提交。</p><p>Fig. 5显示任务可以在提交之前的任何时候中止。由于任务可能会在其祖先仍处于推测状态时运行，因此中止任务需要中止并丢弃其所有后代。这些级联中止是发现并行性所必需的，并且是有选择性的：中止会撤消中止任务、其后代以及按程序顺序稍后出现的任何数据相关任务的影响。如图5所示，如果一个任务因为它的父任务被中止而被中止，那么它就被丢弃；否则，中止是由于数据依赖性，然后任务重新排队执行。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-34746.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Fig. 6显示了Chronos中的推测执行示例。<br>任务被创建并无序运行：在Fig. 6a中，任务20已经运行并完成，即使较早的任务仍在运行；特别是任务0，即20的父任务，仍在运行。在Fig. 6b中，任务0创建了一个时间戳为10的子任务，它与任务15发生冲突。这导致任务15及其子任务25被中止。虽然中止可能影响多个任务，但它们是有选择性的：独立任务，例如20不会中止。</p><ul><li><strong>任务映射和冲突检测:</strong> 为了廉价地执行推测执行，Chronos使用了第3节中概述的任务映射和冲突检测策略。Chronos将对象id映射到tile，然后将每个创建的任务发送到映射其对象id的tile。我们当前的Chronos实现使用静态对象到图块映射：对象id被简单地散列以生成图块id。我们发现这在我们的工作负载中实现了良好的负载平衡；Chronos还可以基于tile之间对象的动态重新映射采用更复杂的负载平衡。</li><li><strong>任务调度:</strong> 任务单元按时间戳顺序将任务分派给PE，以优先处理较早的任务。为了避免冲突，任务单元将具有相同对象ID的任务的执行序列化。因此，运行任务之间的冲突永远不会出现；只有无序到达tile的任务才能产生冲突。</li><li><strong>投机价值管理:</strong> Chronos采用Eager版本管理：推测性写入更新内存，旧值写入单独的撤消日志。提交很快，因为撤消日志被简单地丢弃；中止需要从撤消日志中恢复旧值。<br>Eager版本管理有助于运行依赖数据的任务链，而无需等待它们提交：如果任务A写入的值稍后由（相同对象）任务B读取，即使A尚未提交，B也会自然地使用A的值.这个过程被称为推测转发，对于有序推测很重要，但是对于懒惰的版本管理来说很难做到。</li><li><strong>高吞吐量提交:</strong> 为了确定任务何时可以提交，Chronos从之前的工作中借用了全局虚拟时间 (GVT) 协议。Tiles定期（例如，每32个周期）通信以找到最早未完成任务的时间戳，然后提交所有较早的任务。此过程利用大型提交队列一次提交多个任务，以很少的通信实现每个周期多个任务的提交吞吐量。</li></ul><h3 id="任务单元设计"><a href="#任务单元设计" class="headerlink" title="任务单元设计"></a>任务单元设计</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/31/chronos-efcient-speculative-parallelismfor-accelerators/202191-40232.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Chronos的任务单元由两个主要结构组成：一个任务队列(TQ)保存tile中的所有任务并将空闲任务分派到PE，以及一个提交队列(CQ)，保存正在运行或完成的任务的推测状态，并提交或中止他们根据需要。此外，一个小任务发送缓冲区(TSB)从PE接收新创建的任务并将它们发送到正确的tile。<br>Fig. 7详细说明了每个tile的微架构，并显示了这些结构，它们一起类似于任务级重新排序缓冲区。</p><h4 id="任务队列"><a href="#任务队列" class="headerlink" title="任务队列"></a>任务队列</h4><p>任务队列由两个主要结构组成：任务数组和顺序队列。任务数组是一个简单的内存，用于存储tile中每个任务的任务描述符。每个任务描述符包含运行任务所需的所有数据：其类型、时间戳、对象ID和参数。订单队列持有空闲任务并按时间戳顺序将它们分派给PE。<br>当任务到达tile时，任务会在任务数组和排序队列中分配条目。它们保留他们的订单队列条目，直到他们被分派到PE，但在他们的整个生命周期（即，直到他们提交或被丢弃）都保留他们的任务数组条目。这样，如果任务被中止，任务数组就有重新执行它所需的信息。当一个任务需要重新执行时，它被重新插入到订单队列中。<br><strong>任务溢出:</strong> 任务队列的容量有限，但SLOT程序可能会创建无限数量的任务。当任务队列快满时，Chronos通过将任务溢出到主内存来提供无限任务队列的假象。</p><h4 id="提交队列"><a href="#提交队列" class="headerlink" title="提交队列"></a>提交队列</h4><p>提交队列保存所有正在运行或已完成的任务的推测状态。在Chronos中，这种推测状态由任务的撤消日志（允许回滚任务的内存写入）和子指针（允许中止任务的后代）组成。<br>每个子指针跟踪子任务的tile和任务数组条目id。当一个孩子被创建时，它被发送到由其对象 id 指定的图块。 当接收 tile 将其排队时，它会回复子任务的指针。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ambit: In-Memory Accelerator for Bulk Bitwise Operations Using Commodity DRAM Technology</title>
      <link href="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/"/>
      <url>/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/</url>
      
        <content type="html"><![CDATA[<!-- 文章标题 --><!-- TOC --><ul><li><a href="#summary">Summary</a></li><li><a href="#research-objective">Research Objective</a></li><li><a href="#problem-statement">Problem Statement</a></li><li><a href="#methods">Method(s)</a><ul><li><a href="#detailed-design">Detailed Design</a><ul><li><a href="#ambit-and-or">Ambit-AND-OR</a></li><li><a href="#tra%E8%83%BD%E5%A4%9F%E5%B7%A5%E4%BD%9C%E9%9C%80%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98">TRA能够工作需要解决的问题</a></li><li><a href="#%E8%A7%A3%E5%86%B335%E7%9A%84ambit-and-or-flow">解决3~5的Ambit-AND-OR Flow</a></li><li><a href="#ambit-not">Ambit-NOT</a></li></ul></li><li><a href="#ambit-putting-it--all-together">Ambit: Putting it  all together</a><ul><li><a href="#row-address-grouping">Row address grouping</a></li><li><a href="#executing-bitwise-ops-the-aap-primitive">Executing Bitwise Ops: The AAP Primitive</a></li><li><a href="#accelerating-aap-with-a-split-row-decoder">Accelerating AAP with a Split Row Decoder</a></li><li><a href="#integrating-ambit-with-the-system">Integrating Ambit with the System</a></li></ul></li></ul></li><li><a href="#evaluation">Evaluation</a></li><li><a href="#conclusion">Conclusion</a><ul><li><a href="#circuit-level-spice-simulation">Circuit-level SPICE Simulation</a></li><li><a href="#analysis-of-throughput--energy">Analysis of Throughput &amp; Energy</a></li><li><a href="#effect-on-real-world-application">Effect on Real-World Application</a></li></ul></li><li><a href="#notes">Notes</a><ul><li><a href="#bulk-bitwise-operations%E7%9A%84%E5%8A%A0%E9%80%9F%E5%9C%BA%E6%99%AF%E5%8F%8A%E6%84%8F%E4%B9%89">Bulk bitwise operations的加速场景及意义</a></li><li><a href="#interleaved-memory-system-%E4%BA%A4%E9%94%99%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F">Interleaved Memory System (交错存储系统)</a></li></ul></li></ul><!-- /TOC --><p>HPCA-2020</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><!-- 写完笔记之后最后填，概述文章的内容，以后查阅笔记的时候先看这一段。 --><p>这篇文章介绍了一种存内计算的方法Ambit，可以在DRAM中实现整行的AND/OR/NOT逻辑操作，将源数据复制到预留的操作数行，不破坏原始数据，同时降低操作数译码电路的复杂度。</p><h2 id="Research-Objective"><a href="#Research-Objective" class="headerlink" title="Research Objective"></a>Research Objective</h2><!-- 作者的研究目标 --><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><!-- 问题陈述，要解决什么问题？ --><p>In existing architectures, the throughput of bulk bitwise operations is limited by the memory bandwidth available to the processing unit (e.g., CPU, GPU, FPGA, processing-in-memory).</p><h2 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a>Method(s)</h2><!-- 解决问题的方法/算法是什么？ --><p>Ambit利用DRAM技术的模拟操作完全在DRAM内部执行按位运算，从而充分利用了内部DRAM的全部带宽。<br>With modest changes to the DRAM design, Ambit can exploit:</p><ul><li>the maximum internal bandwidth available inside each DRAM array;</li><li>the memory-level parallelism across multiple DRAM arrays.</li></ul><h3 id="Detailed-Design"><a href="#Detailed-Design" class="headerlink" title="Detailed Design"></a>Detailed Design</h3><h4 id="Ambit-AND-OR"><a href="#Ambit-AND-OR" class="headerlink" title="Ambit-AND-OR"></a>Ambit-AND-OR</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-11-44-34.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="TRA"></p><p>TRA (triple-row activation) 同时将一个读出放大器与同一位线上的三个DRAM单元相连，假设这三个单元的电容相同，都为$C_c$，bitline的寄生电容为$C_b$，基于电荷共享原则，在电荷共享结束之后，bitline上的电压偏差为：<br>$$\delta = \frac{k\cdot C_c \cdot V_{DD} + C_b \cdot \frac{1}{2} \cdot V_{DD}}{3C_c + C_b} - \frac{1}{2}V_{DD} = \frac{(2k-3)C_c}{6C_c + 2C_b}V_{DD}$$<br>从上面的公式可以看出，如果$k = 2, 3$，则bitline deviation为正，如果$k = 0, 1$，则bitline deviation为负。<br>分别使用A, B, C表示三个cell的逻辑值，则最终的输出可以表示为$C(A+B) + \overline{C}(AB)$，由此我们可以得到：通过控制C的逻辑值，我们可以使用TRA实现逻辑AND和OR。</p><h4 id="TRA能够工作需要解决的问题"><a href="#TRA能够工作需要解决的问题" class="headerlink" title="TRA能够工作需要解决的问题"></a>TRA能够工作需要解决的问题</h4><ol><li>当同时激活三个单元时，位线上的偏差可能小于仅激活一个单元时的偏差。 这可能会延长感测放大的时间或更糟，感测放大器可能会检测到错误的值。</li><li>由于工艺的变化，所有电容相等的假设在实际设计中是不正确的。这会影响TRA的可靠性，从而影响其结果的正确性。</li><li>TRA会改写三个cell的原始数据。</li><li>电容可能会没有充电到满电荷，或者由于漏电会导致电荷随时间减少，如果漏电明显会影响运算结果。</li><li>同时激活DRAM子阵列中的三个任意行需要内存控制器和行解码器同时通信和解码三个行地址。这将在地址总线和行解码器上引入大量成本。</li></ol><h4 id="解决3-5的Ambit-AND-OR-Flow"><a href="#解决3-5的Ambit-AND-OR-Flow" class="headerlink" title="解决3~5的Ambit-AND-OR Flow"></a>解决3~5的Ambit-AND-OR Flow</h4><p>Ambit reserves a set of designed rows in each subarray thar are used to perform TRAs. These designated rows are chosen statically at design time.</p><ol><li>Copy data of row A to designated row T0</li><li>Copy data of row B to designated row T1</li><li>Initialize designated row T2 to 0</li><li>Activate designated rows T0, T1, and T2 simultaneously</li><li>Copy data of row T0 to row R</li></ol><h4 id="Ambit-NOT"><a href="#Ambit-NOT" class="headerlink" title="Ambit-NOT"></a>Ambit-NOT</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-46-47.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Ambit-NOT"></p><p>$\overline{\text{bitline}}$上的电压表示cell逻辑值的NOT逻辑，因此Ambit-NOT的方法是将$\overline{\text{bitline}}$上的数值连接到$bitline$，从而实现NOT逻辑，如上图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-52-29.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Bitwise NOT using a dual-contact cell"></p><ol><li>Activate the source row A;</li><li>Activate n-wordline of DCC (address B5);</li><li>Precharge the bank;</li><li>Copy data from d-wordline of DCC to row R (RowClone).</li></ol><h3 id="Ambit-Putting-it-all-together"><a href="#Ambit-Putting-it-all-together" class="headerlink" title="Ambit: Putting it  all together"></a>Ambit: Putting it  all together</h3><h4 id="Row-address-grouping"><a href="#Row-address-grouping" class="headerlink" title="Row address grouping"></a>Row address grouping</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-15-58-18.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Row address grouping"></p><p>Ambit将每个subarray中的行地址分为三类：</p><ul><li><strong>B</strong>itwise group</li><li><strong>C</strong>ontrol group</li><li><strong>D</strong>ata group</li></ul><p>Bitwise group的地址译码如下表所示：</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-16-07-51.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Mappping of B-group address"></p><h4 id="Executing-Bitwise-Ops-The-AAP-Primitive"><a href="#Executing-Bitwise-Ops-The-AAP-Primitive" class="headerlink" title="Executing Bitwise Ops: The AAP Primitive"></a>Executing Bitwise Ops: The AAP Primitive</h4><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-01-31-16-29-14.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Command sequences for different bitwise operations"></p><p>从上图可以看出逻辑操作基本上可以使用AAP操作和AP操作来实现。</p><h4 id="Accelerating-AAP-with-a-Split-Row-Decoder"><a href="#Accelerating-AAP-with-a-Split-Row-Decoder" class="headerlink" title="Accelerating AAP with a Split Row Decoder"></a>Accelerating AAP with a Split Row Decoder</h4><h4 id="Integrating-Ambit-with-the-System"><a href="#Integrating-Ambit-with-the-System" class="headerlink" title="Integrating Ambit with the System"></a>Integrating Ambit with the System</h4><ol><li><p>ISA Support<br>$$bbop dst, src1, [src2], size$$</p></li><li><p>Ambit API/Driver Support</p><ul><li>an API that enables applications to specify bitvectors that are likely to be involved in bitwise operations;</li><li>a driver that is aware of the internal mapping of DRAM rows to subarrays and maps the bitvectors involved in bulk bitwise operations to the same DRAM array.</li></ul></li><li><p>Implementing the $bbop$ Instruction<br> 微架构需要检查：1)Ambit操作的源/目的地址是否行对齐；2)操作的长度是否是DRAM行长度的整数倍。如果检查通过，则CPU将操作发送到memory controller，否则CPU执行该操作。</p></li><li><p>Maintaining On-chip Cache Coherence</p><ul><li>flush any dirty cache lines from the source rows;</li><li>invalidate any cache lines from the source rows;<blockquote><p>Note: The above mechanism is already required by DMA. As Ambit operations are always row-wide, we can use structures like the Dirty-Block Index to speed up flushing dirty data.</p></blockquote></li></ul></li><li><p>Error Correction and Data Scrambling<br>暂时不深入这一块</p></li></ol><h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><!-- 作者如何评估自己的方法，有没有问题或者可以借鉴的地方 --><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-29-22.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><!-- 作者给了哪些strong conclusion, 又给了哪些weak conclusion? --><h3 id="Circuit-level-SPICE-Simulation"><a href="#Circuit-level-SPICE-Simulation" class="headerlink" title="Circuit-level SPICE Simulation"></a>Circuit-level SPICE Simulation</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-21-41.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Effect of process variation on TRA"></p><p><strong>Simulation tools:</strong><br>    HSPICE with the sense amplifier using 55nm DDR3 model parameters.<br><strong>Conclusion:</strong></p><ul><li>up to $\pm5%$ variation, there are zero errors in TRA.</li><li>even with $\pm10%$ and $\pm15%$ variation, the percentage of erroneous TRAs across 100,000 iterations each is just 0.29% and 6.01%.</li></ul><h3 id="Analysis-of-Throughput-amp-Energy"><a href="#Analysis-of-Throughput-amp-Energy" class="headerlink" title="Analysis of Throughput &amp; Energy"></a>Analysis of Throughput &amp; Energy</h3><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-32-10.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Through of bbop"></p><p> Ambit (with 8 DRAM banks) outperform Skylake by 44.9%, GTX745 by 32.0x, and HMC 2.0 by 2.4X.</p><p> <img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-39-42.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Energy of bbop"></p><p><strong>Conclusion:</strong> Ambit reduces energy consumption by 25.1X-59.5X compared to copying data with the memory controller using the DDR3 interface.</p><h3 id="Effect-on-Real-World-Application"><a href="#Effect-on-Real-World-Application" class="headerlink" title="Effect on Real-World Application"></a>Effect on Real-World Application</h3><p><strong>Tools:</strong> GEM5<br><strong>Benchmark:</strong><br>    - a database bitmap index<br>    - BitWeaving, a mechanism to accelerate database column scan operations<br>    - a bitvector-based implementation of the widely-used set data structure</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-53-03.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Bitmap index performance"></p><p><strong>Conclusion:</strong> Ambit significantly reduces the query execution time compared to the baseline by 6X on average.</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-54-54.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Speedup offered by Ambit for BitWeaving"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-10-58-20.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Performance of set operations"></p><p><font color="blue" size="5">现有基于忆阻器的PIM能够加速的一大原因在于神经网络计算的高并行度，但是一旦并行度不高，这些慢的访存速度将强烈限制PIM的性能，因此在比cache访存速度慢的memory中实现非规则计算加速是不现实的，物理特性和容量升高都会导致访存变慢。但是有可能实现低功耗PIM。</font></p><h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><!-- 在这些框架外额外需要记录的笔记。 --><h3 id="Bulk-bitwise-operations的加速场景及意义"><a href="#Bulk-bitwise-operations的加速场景及意义" class="headerlink" title="Bulk bitwise operations的加速场景及意义"></a>Bulk bitwise operations的加速场景及意义</h3><p>In fact, many real-world databases support bitmap indice. A recent work, WideTable, designs an entire database around a technique called BitWeaving, which accelerates scans completely using bulk bitwise operations. Microsoft recently open-sourced a technology called BitFunnel that accelerates the document filtering portion of web search. BitFunnel relies on fast bulk bitwise AND operations. Bulk bitwise operations are also prevalent in DNA sequence alignment, encrayption algorithms, graph processing, and networking. Thus, accelerating bulk bitwise operations can significantly boost the performance of various applications.</p><h3 id="Interleaved-Memory-System-交错存储系统"><a href="#Interleaved-Memory-System-交错存储系统" class="headerlink" title="Interleaved Memory System (交错存储系统)"></a>Interleaved Memory System (交错存储系统)</h3><blockquote><p>参考链接：<a href="https://blog.csdn.net/wbcuc/article/details/8183369">https://blog.csdn.net/wbcuc/article/details/8183369</a></p></blockquote><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-47-52.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Non-interleaved Memory Organization"></p><p>非交错存储系统如上图所示，单个bank内地址连续，因此访问连续内存需要串行访问，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-51-32.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Non-interleaved Burst Access Timing"></p><p>不难看出上面这种方式的访问延时比较高，为了降低访存的延时，交错存储系统将地址连续的分布在bank之间，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-53-18.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Interleaved Memory Organization"></p><p>因此bank0和bank1的可以并行访问，从而将地址0和1并行读出，降低了访存的延时，如下图所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/27/ambit-in-memory-accelerator-for-bulk-bitwise-operations-using-commodity-dram-technology/2021-02-01-00-55-01.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="Intereaved Burst Access Timing"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Compute Caches</title>
      <link href="/2021/08/26/compute-caches/"/>
      <url>/2021/08/26/compute-caches/</url>
      
        <content type="html"><![CDATA[<h1 id="Compute-Caches"><a href="#Compute-Caches" class="headerlink" title="Compute Caches"></a>Compute Caches</h1><p>这是密西根大学Reetuparna Das团队的基于SRAM的存内计算三部曲的第一篇，提出了基于Cache的简单逻辑操作接口。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>由于当今的计算由以数据为中心的应用程序主导，因此对这一重要领域的专业化有着强大的推动力。 传统处理器的窄向量单元无法利用这些应用程序中的高度数据并行性。 此外，与实际计算相比，它们在缓存层次结构上移动数据和指令处理上花费了不成比例的大部分时间和精力。</p><p>我们提出了计算缓存架构，通过缓存中的就地（原位）处理显着减少这些低效率。 现代处理器将大部分 (40-60%) 的硅片区域用于缓存，用于存储和检索数据。 我们的主要思想是重新利用缓存中使用的元素并将其转换为活动计算单元。 这可以在缓存子阵列内进行就地计算，而无需将数据传入或传出。 这种转换可以释放海量数据并行计算能力，显着减少数据在缓存层次结构上的移动所消耗的能量，从而直接满足以数据为中心的应用程序的需求。</p><p>我们提出的架构使用了一种新兴的 SRAM 电路技术，我们将其称为位线计算。通过同时激活多个字线，并感测共享位线上产生的电压，可以在不损坏数据的情况下完成对存储在激活位单元中的数据的几个重要操作。 最近制造的芯片证明了位线计算的可行性。 它们还显示了超过 6 sigma 的 Monte Carlo 模拟的稳定性，这被认为是针对工艺变化的稳健性的行业标准。</p><p>过去的内存处理 (PIM) 解决方案建议将处理逻辑移动到缓存或主存储器附近。 3D 堆叠可以使这成为可能。 计算缓存通过使用现有缓存元素启用就地处理，显着推动了极限。 对于以数据为中心的应用程序来说，这是一种有效的优化，其中计算中使用的至少一个操作数（例如 WordCount 中的字典）具有缓存局部性。</p><p>Compute Caches的效率来自两个主要来源：大规模并行和减少数据移动。缓存通常被组织为一组子数组；多达数百个子阵列，具体取决于缓存级别。这些子阵列可以潜在地对存储在其中的数据（KB 数据）进行并发计算，而对现有缓存结构几乎没有扩展（缓存区域开销的 8%）。因此，缓存可以有效地用作大型向量计算单元，其操作数大小比传统 SIMD 单元（KBs vs 字节）大几个数量级。为了实现类似的功能，传统 PIM 解决方案中接近存储器的逻辑需要提供一百多个额外的矢量功能单元。计算缓存的第二个好处是，它们不仅避免了在内核和不同级别的缓存层次结构之间传输数据（通过片上网络），而且甚至在缓存的子阵列与其控制器之间（通过缓存内互连）。</p><p>本文解决了实现计算缓存架构的几个问题，讨论了 ISA 和系统软件扩展，并重新设计了几个以数据为中心的应用程序以利用新的处理能力。</p><p>使用Compute Caches的一个重要问题是满足操作数局部性约束。 位线计算要求数据操作数存储在共享同一组位线的行中。 我们构建了一个缓存几何结构，其中一组中的路被明智地映射到一个子数组，以便软件可以轻松满足操作数局部性。 我们的设计允许编译器通过将操作数放置在页面对齐的地址（相同的页面偏移量）来确保操作数的局部性。 它避免将缓存的内部结构（例如其大小或几何形状）暴露给软件。</p><p>当由于缺乏操作数局部性而无法对操作进行就地处理时，我们建议使用近地计算缓存。 在近地设计中，源操作数从缓存子阵列中读出，操作在靠近缓存控制器的逻辑单元中执行，结果可以写回缓存。</p><p>除了操作数局部性，Compute Caches 还提出了几个有趣的问题。 如何协调跨多个缓存子阵列的操作数的并发计算？ 如何确保启用计算的缓存之间的一致性？ 当计算分布在核心和缓存之间时，如何确保一致性模型约束？ 软错误是现代处理器中的一个重要问题， ECC 可以用于Compute Caches吗？ 如果不可能，有哪些替代解决方案？ 我们讨论了解决这些问题的相对简单的解决方案。</p><p>Compute Caches支持多种就地向量操作：复制、搜索、比较和逻辑操作（和、或、异或和非），它们可以加速各种应用程序。 我们研究了两个文本处理应用程序（字数统计、字符串匹配）、使用位图索引的数据库查询处理、操作系统中的写时复制检查点和位矩阵乘法（BMM）； 用于密码学、生物信息学和图像处理的关键原语。 我们重新设计了这些应用程序，以根据计算缓存支持的向量操作有效地表示它们的计算。 第 V 部分确定了许多可以从计算缓存中受益的其他领域：数据分析、搜索、网络处理等。</p><p>我们评估了以英特尔 SandyBridge 处理器为模型的多核处理器的Compute Caches的优点，该处理器具有八个内核、三级缓存和一个环形互连。 对于我们研究的应用程序，与具有 32 字节宽向量单元的传统处理器相比，Compute Caches平均可将性能提高 1.9 倍，并将能耗降低 2.4 倍。 具有更高比例的Compute Caches操作的应用程序可以受益更多。 通过操作 4KB 操作数的微基准测试，我们表明Compute Caches在使用 32 字节 SIMD 单元的基线上提供 9 倍的动态节能，同时提供 54 倍的平均吞吐量。</p><p>总之，本文做出了以下贡献：</p><ul><li>我们为可以计算的缓存提供了一个案例。 使用位线计算，我们的Compute Caches自然支持对大型数据操作数（几个 KB）的矢量处理。 由于缓存和内核之间的数据移动，这大大减少了开销。 此外，就地计算甚至避免了缓存子阵列与其控制器之间的数据传输。</li><li>我们提出了解决各种架构问题的Compute Caches架构：操作数局部性、跨不同缓存级别和组管理并行性、一致性、一致性和可靠性。</li><li>为了支持没有操作数局部性的计算缓存操作，我们研究了缓存中的近地处理。</li><li>我们重新设计了几个重要的应用程序（文本处理、数据库、检查点）来利用计算缓存操作。 与具有传统 SIMD 单元的处理器相比，我们展示了显著的加速（1.9 倍）和节能（2.4 倍）。 虽然我们为应用程序节省的成本受到可以使用 Compute Caches（阿姆达尔定律）加速的计算部分的限制，但我们的微基准测试表明，具有较大部分 Compute Cache 操作的应用程序可以受益更多（54 倍吞吐量，9 倍 动态节能）。</li></ul><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>本节简要介绍了 SRAM 中的缓存层次结构、缓存几何结构和位线计算。</p><p>A. 缓存层次结构和几何形状</p><p><img "" class="lazyload placeholder" data-original="/2021/08/26/compute-caches/2021105-02653.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>图 1 (a) 展示了一个多核处理器，该处理器基于英特尔的 Sandybridge 建模。 它有一个三级缓存层次结构，包括私有 L1 和 L2，以及一个共享 L3。 共享的 L3 缓存分布在通过共享环互连连接到内核的切片中。 一个缓存由一个缓存控制器和几个bank组成（（图1（b））。每个bank有几个子阵列，通过H-Tree互连连接。例如，一个2MB的L3缓存片总共有64个子阵列。 阵列分布在 16 个存储体中。缓存存储体中的子阵列被组织成多行数据存储位单元。同一行中的位单元连接到一条字线。沿列的位单元 共享同一位线。通常，在任何周期中，一条字线被激活，通过列位线从中读取或写入数据块。</p><p>B. 位线计算</p><p><img "" class="lazyload placeholder" data-original=".//Compute-Caches/2021105-02714.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>计算高速缓存在 SRAM 中使用新兴的位线计算技术（图 2），该技术观察到，当多条字线同时被激活时，可以感测共享位线以产生存储在两个激活的行中的数据的and和nor结果。通过降低字线电压以偏置 SRAM 阵列的写入，可以防止由于多行访问而导致的数据损坏。杰洛卡等人对 20 个制造的测试芯片的测量表明，即使在这种就地计算过程中同时激活 64 条字线时，也不会发生数据损坏。它们对 Monte Carlo 模拟显示出超过 6 sigma 稳健性的稳定性，这被认为是针对工艺误差的稳健性的行业标准。另外，请注意，通过进一步降低字线电压，可以以延迟增加为代价来提高鲁棒性。即使有了它，鉴于其潜力（第 VI 部分，54 倍吞吐量，9 倍动态节能），计算缓存仍将提供显着的节省。</p><p>第 IV-B 节讨论了我们对启用位线计算的 SRAM 的扩展，以支持其他操作：复制、异或、相等比较、搜索和无进位乘法 (clmul)。</p><h2 id="计算缓存的案例"><a href="#计算缓存的案例" class="headerlink" title="计算缓存的案例"></a>计算缓存的案例</h2><p><img "" class="lazyload placeholder" data-original="/2021/08/26/compute-caches/2021105-02727.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>就地计算缓存具有提供大量数据并行性的潜力，同时也显著减少指令处理和片上数据移动开销。 图 3 通过比较标量内核、具有矢量处理支持的 SIMD 内核和计算缓存，以图形方式描述了这些优势。</p><p>图3的下半部分描绘了三种架构的面积比例和处理能力。 传统处理器中的很大一部分芯片面积用于高速缓存。 计算缓存将这个大区域中使用的元素重新用于计算单元，以实现小区域开销（缓存区域的 8%）。 典型的最后一级缓存由分布在不同组中的数百个子阵列组成，这些子阵列可以潜在地对存储在其中的缓存块进行并发计算。 这使我们能够利用大规模数据级并行性（例如，16MB L3 具有 512 个子阵列并且可以支持 8 KB 操作数），甚至使 SIMD 内核相形见绌。</p><p>图 3 的顶行显示了在几个 4KB 操作数块上进行比较操作的相对能耗（第 VI-D 部分）。 在标量内核中，不到 1% 的能量消耗在 ALU 操作上，而将近四分之三的能量花费在内核中处理指令上，四分之一花费在数据移动上。 虽然通用和数据并行加速器中的矢量处理 (SIMD) 支持（图 3 (b)）在一定程度上减少了指令处理开销，但它无助于解决数据移动开销。 Compute Cache 架构（图 3 (c)）通过支持对大型操作数（数十 KB）的 SIMD 操作，可以将指令处理开销减少一个数量级。 此外，它还避免了由于数据移动而导致的能源和性能成本。<font color="blue">从这边可以看出，在标量内核中能耗最高的部分还是内核处理指令，数据搬运约占1/4。而随着向量处理架构的出现，并行处理导致指令处理开销可以均摊，功耗下降，从而数据搬运能耗占主要部分。存内计算只是进一步提高计算并行度，并且数据搬运的能耗也同步降低，达到指令处理/ALU/数据搬运能耗三足鼎立。</font></p><p><img "" class="lazyload placeholder" data-original="/2021/08/26/compute-caches/2021105-02740.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>就地计算缓存减少了片上数据移动开销，它由两个组件组成。 首先，是数据传输所消耗的能量。 这不仅包括在处理器互连线路和路由器上花费的大量能源，还包括用于缓存内数据传输的 H 树互连。 就地计算缓存解决方案可以解决前者，但不能解决后者。 如表 I 所示，H-Tree 消耗了近 80% 的缓存能量，用于读取 2MB 的 L3 缓存切片。</p><p>其次，是在更高级别的缓存中读写时消耗的能量。 在传统处理器中，数据块在可以对其进行操作之前，从 L3 到 L1 高速缓存一直沿高速缓存层次结构向上传递，并进入内核的寄存器。 L3 Compute Cache 可以消除所有这些开销。 共享 L3 计算缓存还可以降低在两个内核之间共享数据的成本，因为它可以避免从源内核的 L1 写回共享 L3，然后传输回目标内核的 L1。</p><h2 id="计算缓存架构"><a href="#计算缓存架构" class="headerlink" title="计算缓存架构"></a>计算缓存架构</h2><p>图 1 说明了计算缓存 (CC) 架构。 我们通过就地计算能力增强了缓存层次结构中的所有级别。 计算是在应用程序表现出显着局部性的最高级别完成的。 就地计算基于我们在第 II 节中讨论的位线计算技术。 我们增强了这些基本的就地计算能力，以支持异或和多种就地操作（复制、搜索、比较和无进位乘法）。</p><p>只有当操作数被映射到子数组，以便它们共享相同的位线时，就地计算才是可能的。 我们将此要求称为操作数局部性。 我们讨论了一种缓存几何结构，它允许编译器通过确保操作数页面对齐来满足操作数局部性。</p><p>每个缓存控制器都被扩展为管理跨多个存储体的 CC 指令的并行执行。 它还决定执行计算的缓存级别并将操作数提取到该级别。 鉴于 Compute Cache 可以修改数据，我们将讨论其在确保一致性和一致性属性方面的含义。 最后，我们讨论了在计算缓存中支持 ECC 的设计替代方案。</p><p>在没有操作数局部性的情况下，我们建议在缓存中计算近位。 为此，我们在缓存控制器中添加了一个逻辑单元。 虽然近地缓存计算需要额外的功能单元，并且无法节省缓存内部的 HTree 互连能量，但它成功地帮助减少了在更高级别缓存中传输和存储数据所花费的能量。</p><p>A. 指令集架构 (ISA)</p><p><img "" class="lazyload placeholder" data-original="/2021/08/26/compute-caches/2021105-02758.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>计算缓存 (CC) ISA 扩展列在表 II 中。 它支持多种向量指令，其操作数是使用寄存器间接寻址指定的。 操作数大小通过立即数指定，可以大到 16K。 它支持向量复制、归零和逻辑运算。 它还支持单/双/四字粒度的向量少乘法指令 (cc clmul)。</p><p>它还支持相等比较和搜索。 我们将这些指令的操作数大小 (n) 限制为 64 个字（512 字节），以便结果可以作为 64 位值返回到处理器内核的寄存器。 对于搜索指令，密钥大小设置为 64 字节。 对于较小的键，程序员可以从键的地址开始多次复制键（如果其大小是一个字的倍数），或者将键和源数据操作数填充为 64 字节。</p><p>B. 使用就地计算缓存子阵列</p><p>我们的 SRAM 子阵列设计使计算缓存成为可能，该设计有助于就地计算。 我们从 Jeloka 等人提出的基本电路框架开始。它支持逻辑和和非操作。 对于传统缓存的子阵列，我们添加了一个额外的解码器，以允许激活两条字线，每个字线对应一个操作数。 分别感测连接到位单元的两条位线所需的两个单端感测放大器是通过重新配置原始差分感测放大器获得的。</p><p>除了和和非操作之外，我们还扩展了电路以通过对位线和位线补码进行 NOR 运算来支持异或运算。 我们利用按位异或的结果来实现比较和搜索等复合操作。 为了比较两个字，单独的按位异或结果使用有线 NOR 组合。 比较用于对存储在子阵列中的缓存块进行迭代搜索。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/26/compute-caches/2021105-02818.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>通过将读出放大器的结果反馈回位线，可以将一条字线复制到另一条字线，而无需锁存源操作数。 我们利用最后一个读取值与下一个周期要写入的数据相同的事实，并合并读写操作以启用更节能的复制操作，如图 4 所示。通过在 a 之前重置输入数据锁存器 写入我们可以启用缓存块的就地归零。</p><p>最后，无进位乘法 (clmul) 操作使用逻辑和在两个子阵列行上完成，然后对所有结果位进行异或归约。 这是通过向每个子数组添加异或归约树来支持的。</p><p>我们的扩展对基线读/写访问的影响可以忽略不计，因为它们使用与基线相同的电路，包括差分传感。 就地操作比单个读取或写入子阵列访问需要更长的时间，因为它需要更长的字线脉冲来激活和感测两行以补偿较低的字线电压。 与差分感测相反，由于使用单端感测放大器，感测时间也会增加。 但是，请注意，这仍然小于完成等效就地操作所需的延迟基线，因为它需要多次读取访问和/或写入访问。 第 VI-C 部分提供了具有计算能力的高速缓存子阵列的详细延迟、能量和面积参数。</p><p>C. 操作数位置</p><p>对于就地操作，操作数需要物理存储在子阵列中，以便它们共享同一组位线。 我们将此要求称为操作数局部性。 在本节中，我们将讨论可以共同满足此属性的缓存组织和软件约束。 幸运的是，我们发现只要操作数是页面对齐的，即具有相同的页面偏移量，软件就可以确保操作数的局部性。 除此之外，程序员或编译器不需要知道缓存几何的任何其他细节。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/26/compute-caches/2021105-02836.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><strong>操作数位置感知缓存组织：</strong> 图 5 说明了一个简单的缓存，其中一个存储体有四个子阵列。 子阵列中的行共享同一组位线。</p><p>我们定义了一个新术语，块分区（BP）。 子阵列的块分区是该子阵列中共享相同位线的高速缓存块组。 块分区内存储的任何两个缓存块之间都可以进行就地操作。 在我们的示例中，由于子阵列中的每一行都有两个缓存块，因此每个子阵列有两个块分区。 总共有八个块分区（BP0-BP7）。 可以在映射到同一块分区的任何块之间进行就地计算（例如集合 S0 和 S2 中的块）。</p><p>我们为缓存组织做出了两种设计选择，以简化操作数局部性约束。 首先，一组中的所有路都映射到同一个块分区，如图 5(a) 所示。 这确保操作数局部性不会因为缓存块选择的方式而受到影响。</p><p>其次，我们使用一部分 set-index 位来选择块的 bank 和块分区，如图 5(b) 所示。 只要两个操作数的这些相同，就可以保证将它们映射到同一个块分区。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/26/compute-caches/2021105-02859.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><strong>软件要求：</strong> 必须与操作数位置匹配的地址位数因缓存大小而异。 如表 III 所示，即使我们模型中最大的缓存 (L3) 要求两个操作数只有至少 12 位相同（我们假设页面被映射到最靠近主动访问它们的核心的 NUCA 切片）。 鉴于我们的页面大小为 4KB，我们观察到只要操作数是页面对齐的，即具有相同的页面偏移量，那么它们将被放置在地址空间中，使得最低有效位（4KB 页面为 12 ) 在它们的地址（虚拟和物理）中匹配。 这将很容易满足我们研究的所有缓存级别和大小的操作数位置要求。 注意，我们只需要将操作数放置在 4KB 内存区域的相同偏移量处，而不必将它们放置在单独的页面中。 对于大于 4KB 的超级页面，操作数可以放在一个页面内，同时确保 12 位地址对齐。</p><p>我们预计，对于操作大量数据的数据密集型常规应用程序，有可能满足此属性。 许多涉及从一页复制到另一页的操作系统操作都保证为我们的系统展示操作数局部性。 将来可以扩展编译器和动态内存分配器以优化此属性。</p><p>最后，根据给定的地址位对齐要求（我们的工作中为 12 位）编译的二进制文件可以在各种缓存架构中移植，只要要对齐的地址位数量等于或小于它们编译的数量 . 如果缓存几何结构发生变化以致需要更大的对齐，则必须重新编译程序以满足该更严格的约束。</p><p><strong>列多路复用：</strong> 通过列多路复用，多条相邻的位线被多路复用为一位数据输出，然后使用一个读出放大器进行观察。 这可以控制外围设备的区域开销并提高对粒子撞击的弹性。 幸运的是，在列多路复用子阵列中，高速缓存块中的相邻位在不同的子阵列中交错，这样它们的位线就不会被多路复用。 在这种情况下，我们定义的逻辑块分区将在子阵列中交错。 因此，可以并行访问整个缓存块。 鉴于此，即使使用列多路复用，也可以对缓存块中的所有位进行就地并发操作。</p><p>我们在块分区内放置集合的方式的设计选择不会影响列多路复用的程度，因为我们交错不同集合的缓存块。</p><p><strong>路映射与并行标记数据访问：</strong> ==我们选择将集合的所有路放置在块分区中，以便操作数局部性不依赖于在运行时为块选择的路径。 然而，这阻止了我们支持并行标签数据访问，其中一组中的所有缓存块都与标签匹配并行地被主动读取。==<font color="blue">这是为什么？</font> 这种优化通常用于 L1，因为它可以通过将标签匹配与读取重叠来减少读取延迟。 但是为了适度的性能提升（SPLASH-2为 2.5%），它会产生很高的读取能量开销（L1 缓存每次访问的能量高出 4.7 倍）。 鉴于 L1 Compute Cache 的显着优势，我们认为放弃这种针对 L1 的优化是值得的。</p><p>D. 管理并行性</p><p>缓存控制器被扩展为提供协调 CC 指令执行的 CC 控制器。 CC 控制器将 CC 指令分解为多个简单的向量操作，其操作数最多跨越一个缓存块，并将它们发布到子阵列。 由于典型的缓存层次结构可以有数百个子阵列（16MB L3 缓存有 512 个子阵列），我们可能会发出数百个并发操作。 这仅受两个因素的限制。 首先，用于传输地址/命令的共享互连的带宽。 请注意，我们没有在 H 树互连中复制地址总线。 其次，可以限制同时激活的子阵列数量以限制消耗的峰值功率。</p><p>L1 缓存中的控制器使用指令表来跟踪待处理的 CC 指令。 简单的向量操作在操作表中被跟踪。 指令表跟踪在指令级别关联的元数据（即结果、已完成的简单向量操作的计数、要生成的下一个简单向量操作）。 另一方面，操作表跟踪与操作关联的每个操作数的状态，并在缓存中不存在操作数时发出请求以获取操作数（第 IV-E 节）。 当所有操作数都在缓存中时，我们向缓存子数组发出操作。 当操作完成时，它们更新指令表，当指令完成时，L1 缓存控制器通知内核。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>转-四种基本的编程命名规范</title>
      <link href="/2021/08/13/zhuan-si-chong-ji-ben-de-bian-cheng-ming-ming-gui-fan/"/>
      <url>/2021/08/13/zhuan-si-chong-ji-ben-de-bian-cheng-ming-ming-gui-fan/</url>
      
        <content type="html"><![CDATA[<h1 id="转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）"><a href="#转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）" class="headerlink" title="转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）"></a>转-四种基本的编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法、下划线命名法）</h1><h2 id="匈牙利命名法"><a href="#匈牙利命名法" class="headerlink" title="匈牙利命名法"></a>匈牙利命名法</h2><p>匈牙利命名法是早期的规范，由微软的一个匈牙利人发明的，是IDE还十分智障的年代的产物。那个年代，当代码量很多的时候，想要确定一个变量的类型是很麻烦的，不像现在IDE都会给提示，所以才产生了这样一个命名规范，估计现在已经没啥人用了吧……一个十分系统却又琐碎的命名规范。</p><p>该命名规范，要求前缀字母用变量类型的缩写，其余部分用变量的英文或英文的缩写，单词第一个字母大写。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int iMyAge;        #  &quot;i&quot;: int</span><br><span class="line">char cMyName[10];  #  &quot;c&quot;: char</span><br><span class="line">float fManHeight;  #  &quot;f&quot;: float</span><br></pre></td></tr></table></figure><p>其他前缀类型还有：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">a      数组（Array）</span><br><span class="line">b      布尔值（Boolean）</span><br><span class="line">by     字节（Byte）</span><br><span class="line">c      有符号字符（Char）</span><br><span class="line">cb     无符号字符（Char Byte，并没有神马人用的）</span><br><span class="line">cr     颜色参考值（Color Ref）</span><br><span class="line">cx,cy  坐标差（长度 Short Int）</span><br><span class="line">dw     双字（Double Word）</span><br><span class="line">fn     函数（Function）</span><br><span class="line">h      Handle（句柄）</span><br><span class="line">i      整形（Int）</span><br><span class="line">l      长整型（Long Int）</span><br><span class="line">lp     长指针（Long Pointer）</span><br><span class="line">m_     类成员（Class Member）</span><br><span class="line">n      短整型（Short Int）</span><br><span class="line">np     近程指针（Near Pointer）</span><br><span class="line">p      指针（Pointer）</span><br><span class="line">s      字符串（String）</span><br><span class="line">sz     以 Null 做结尾的字符串型（String with Zero End）</span><br><span class="line">w      字（Word）</span><br></pre></td></tr></table></figure><p>还有其他更多的前缀是根据微软自己的MFC/句柄/控件/结构等东西定义的，就不过多描述了。</p><h2 id="驼峰式命名法"><a href="#驼峰式命名法" class="headerlink" title="驼峰式命名法"></a>驼峰式命名法</h2><p>驼峰式命名法，又叫小驼峰式命名法（所以自然就存在大驼峰命名法啦……)。</p><p>该命名规范，要求第一个单词首字母小写，后面其他单词首字母大写，简单粗暴易学易用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int myAge;</span><br><span class="line">char myName[10];</span><br><span class="line">float manHeight;</span><br></pre></td></tr></table></figure><h2 id="帕斯卡命名法"><a href="#帕斯卡命名法" class="headerlink" title="帕斯卡命名法"></a>帕斯卡命名法</h2><p>帕斯卡命名法，又叫大驼峰式命名法。</p><p>与小驼峰式命名法的最大区别在于，每个单词的第一个字母都要大写。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int MyAge;</span><br><span class="line">char MyName[10];</span><br><span class="line">float ManHeight;</span><br></pre></td></tr></table></figure><h2 id="下划线命名法"><a href="#下划线命名法" class="headerlink" title="下划线命名法"></a>下划线命名法</h2><p>下划线命名法并不如大小驼峰式命名法那么备受推崇，但是也是浓墨重彩的一笔。尤其在宏定义和常量中使用比较多，通过下划线来分割全部都是大写的单词。</p><p>该命名规范，也是很简单，要求单词与单词之间通过下划线连接即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int my_age;</span><br><span class="line">char my_name[10];</span><br><span class="line">float man_height;</span><br></pre></td></tr></table></figure><h2 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h2><p>随着技术的发展，命名规范也在不断的细化，一种命名规范早已无法系统的满足各方需求（匈牙利命名法除外，但是已经基本淘汰了），不同的语言不同 IDE 推崇的规范也有所不同，无法评判哪一种最好，但是可以肯定的是，集后三种命名规范大成者，一定是受众最广的。</p><p>例如，谷歌 C++ 编程规范，从项目的命名到文件的命名，再到类和变量以及宏定义的命名都做到了细致入微，充分的结合了下划线命名法与驼峰式命名法（早先推崇的小驼峰，不过今年好像改成大驼峰了），又加入了一些新的元素，十分的系统完善。</p><p>当然，命名规范并不代表着编程规范，仅仅是编程规范的一部分而已，除去命名规范，还有很多编程上的细节是必须关注的，例如，等号两边留空格还是等号对齐？空行神马时候神马地方留更加符合代码结构？空格神马时候神马地方留更加美观？花括号是否对齐？</p><p>诸如此类，还有很多，无法一下子全部掌握并应用，但是在编程经验增加的过程中，一定也要不断的留意，自己所在的公司部门使用的是神马样的规范，没错，并不提倡大家练就自己的规范，一定要去融入工作环境的需求。</p><p>每次去新的工作环境，第一个要看的文档不是别的，一定是编程规范，如果没有这个东西，那么就努力去推一个统一的规范，推不动的话，那可以换工作了，否则日后将会带来无尽的麻烦。</p><p>本文转载自：<a href="https://zhuanlan.zhihu.com/p/89909623">https://zhuanlan.zhihu.com/p/89909623</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2021/08/07/hello-world/"/>
      <url>/2021/08/07/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>A 28 nm Configurable Memory (TCAM/BCAM/SRAM) Using Push-Rule 6T Bit Cell Enabling Logic-in-Memory</title>
      <link href="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/"/>
      <url>/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/</url>
      
        <content type="html"><![CDATA[<p>今天在阅读“CAPE: A Content-Addressable Processing Engine”这篇论文时，论文中引用的一篇仅使用6T SRAM实现CAM的工作引起了我的兴趣。</p><p>由于可以对存储的所有entry进行并行数据搜索/匹配的优良特性，CAM是高关联性缓存、TLB和寄存器重命名电路中不可或缺的部分。LUT也是IP路由器表的主要功能，如Fig. 1所示，因此CAM是许多路由器芯片的主要组成部分。<br><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-222208.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><!-- ![](202184-222208.jpg) --><p>但是传统的CAM存在一个严重的问题就是资源开销很大，无法高密度集成，比如一个BCAM需要10个晶体管，一个TCAM需要16个晶体管，如Fig. 2所示。<br><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-222641.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>因此本文能够使用6T SRAM紧凑的单元实现CAM的方案就显得非常有意义。同时，该论文在保留SRAM存储功能的基础上还实现了TCAM以及一些基础的逻辑操作（AND和NOR）。该论文不仅提出了实现方案，还通过一些精巧的设计保证了该设计的高性能，而且分析的面面俱到，是一个相当优秀的工作。</p><p>在此也先简单总结一下该设计的最终性能：基于6T 28nm FDSOI SRAM工艺，实现了$64\times 64 (4kb)$ BCAM，在1V工作电压下，BCAM的工作频率为370 MHz，能效为$0.5\ fJ/search/bit$，两个64-bit words的逻辑操作的频率达到787 MHz。</p><p>接下来开始介绍该工作的细节，受限简单介绍一下传统CAM搜索的原理。如Fig. 3所示，存储单元中的比特与输入的比特进行XNOR操作，然后同一根match line上的所有同或结果进行线与逻辑，最终通过SA输出匹配结果。在很多查找应用中，可能需要匹配多个结果，如果只需要单个地址，也可以对结果进行优先编码。<font color="blue">这里对搜索的结果进行优先编码也可能对今后的研究有一些启示，很多时候想用到优先编码，但是还没有遇到合适的场合。</font></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-224025.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>接下来看这篇论文提出的6T BCAM设计，如Fig. 4所示。该设计使用标准SRAM中的位线 作为match lines，使用WL表示搜索序列按列进行搜索匹配。而传统的SRAM存储功能仍然保持，可以动态配置成BCAM/TCAM/Logic/SRAM storage。为此，需要对电路进行一些特殊设计，以兼容多种模式，这些在本文中也一一进行了详细的介绍，之后我也会对一些关键的考虑进行简单的介绍。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-224830.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>从Fig. 4中，我们可以看到为了兼容CAM的功能，作者在传统的6T SRAM基础上进行了些微的改动，那就是将WL变为两根，WLR和WLL，分别对与BL和BLB相连的晶体管进行门控（这在Fig. 5中可以看得更加清楚）。文中对这一设计的代价总结为:</p><blockquote><p>“This creates two indeppendent access transistors but incur no area penalty since the push-rule layers are kept intact (i.e., only DRC-compliant metallization changes are made).”</p></blockquote><p><font color="blue">在这里重点指出这一点的原因在于：之前我在和其他人讨论类似的设计的时候，我想通过一根WL改进设计，大家觉得增加这一根线会对面积开销产生很大的影响，这与这边作者的观点相左，暂时看不懂这里为什么面积不会有很大的影响，今后的研究中可能会借鉴这个观点。</font></p><p>废话说完，开始真正介绍三种工作模式：</p><p><strong>1. BCAM</strong></p><p>Fig. 5展示的是该设计实现BCAM搜索的过程，Search string从WLR/WLL输入，当输入为1时，WLR=1，WLL=0，表明BL对应的门控晶体管开启，BLB对应的门控晶体管截止。如果对应的SRAM cell存的值为1，则BL对应的门控晶体管D/S端都为高电平，结果是BL和BLB的最终电位都为高，而如果存储的值为0，则BL预充的高电平会通过SRAM cell放电，从而将BL上电位下拉到0，BLB上电位仍然保持高电平。当输入为0时，工作情况类似，只是BLB对应的门控晶体管开启。因此同一条BL对应的SRAM cell只要有任意一比特无法跟search string bit匹配，BL或BLB会被下拉到低电平，最终与门输出为0，否则输出为1，表示完全匹配。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202184-230549.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>Note:</p><ul><li>基于SRAM的CAM相对于忆阻器的CAM还有一个有点就是搜索的字长可以做到特别长，因为SRAM的off state可以做到几乎不漏电。</li><li>针对SRAM的读操作和BCAM的操作，SA的工作机制是不同的，该设计提出了一种SA，可以在不增加面积的基础上，实现可重构的两种功能的SA，如Fig. 6所示。<br><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-05002.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></li><li>SRAM是逐行写，CAM是对所有列进行匹配，数据需要逐列写。这要是在我看来就是不可能的，这个方案就放弃了，但是作者可能巧妙地解决了这一问题，不仅是磕盐的态度，对于行和列都要写的方案在今后的设计中也可以参考，毕竟有时候经常需要行/列都进行操作，比如矩阵的转置等等，比如从一个bank中逐行读出，逐列写入另一个bank。之前陈怡然也有一篇工作涉及到行列操作的CAM，也可以一起总结一下。这个按列去写刚好受益于有两根WL，这跟BL是等价的。逐行写数据从BL输入，逐列写数据从WL输入。</li><li>该工作还考虑了同时开启多行对SRAM cell中数据的破坏进行了分析，并提出了解决方案。</li></ul><p><strong>2. TCAM</strong></p><p>TCAM的工作原理如Fig. 13所示，由于TCAM中存在三种状态”1”, “0”, “X”，所以需要使用两比特来实现，相邻的两列表示一比特，其中存储”00”表示“0”，存储“11”表示“1”，存储“01”表示“X”，当存储的值为“01”是，左列的BLB对应的SRAM cell输出为“1”，右列的BL对应的SRAM输出也为“1”，因此无论输入是“0”还是“1”，都不会将BL或BLB下拉到低电平。<font color="blue">在其他文章中，认为该设计在实现TCAM时，只需要将WLR和WLL都设置为GND，这样使用BCAM同样的电路就可以实现TCAM的功能。而在本文中，作者自己竟然用了两倍的面积来实现TCAM的功能。不仔细看还会以为本文作者犯了一个错误，其实并不是这样子的。这是如何定义TCAM的一个问题。如果对于输入的某些bit进行mask的话，这样输入的这些bit与所有搜索项目的对应bit都不会去比较，个人感觉这种是比较常用的，但是对于优先编码等应用场合，这种就不适用了，需要将对应的某一搜索项的某些bit进行mask，这样就需要用到本文中所提出的方案，也没有去查TCAM的具体定义，可能这中才是真正的TCAM（杨老师Nature Electronics论文中也是实现的这种方式），以后研究过程中可以用这个电路。</font></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202193-12929.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><strong>3. Logic Operations</strong></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-15755.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该设计实现“AND”逻辑如Fig. 15所示，逻辑操作与存储相同，是以行为单位进行的。要对某两行进行逻辑操作，将对应的WL输入设置为“1”（即WLR=VDD, WLL=GND)，其他行WLL=WLR=GND进行MASK。开启的两行中对应的2个SRAM cell中只要有一个cell存储的值为0，就会将BL下拉到低电平，即实现了“AND”操作。“NOR”操作方式与“AND”类似，TABLE I总结了这两种操作的配置。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20434.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>该设计的整体架构如Fig. 16所示。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20452.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>最后，放置一些实验结果，以对该设计的性能有一个更加深入的了解。</p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20730.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20753.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20813.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20832.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p><img "" class="lazyload placeholder" data-original="/2021/08/04/a-28-nm-configurable-memory-tcam-bcam-sram-using-push-rule-6t-bit-cell-enabling-logic-in-memory/202185-20851.jpg" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 挖坑待填 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决gem5运行时缺少pydot的问题</title>
      <link href="/2021/08/03/jie-jue-gem5-yun-xing-shi-que-shao-pydot-de-wen-ti/"/>
      <url>/2021/08/03/jie-jue-gem5-yun-xing-shi-que-shao-pydot-de-wen-ti/</url>
      
        <content type="html"><![CDATA[<h1 id="解决gem5运行时缺少pydot的问题"><a href="#解决gem5运行时缺少pydot的问题" class="headerlink" title="解决gem5运行时缺少pydot的问题"></a>解决gem5运行时缺少pydot的问题</h1><p>在运行gem5时，会显示：</p><blockquote><p>warn: No dot file generated. Please install pydot to generate the dot file and pdf.</p></blockquote><p>作为一个高度强迫症患者，实在无法忍受每次运行出现这个刺眼的warning，而且在进行系统仿真的时候，产生的config.dot.svg和config.dot.pdf等文件还可以可视化整个系统的架构，为此记录一下我解决这个问题的方法。</p><p>在网上搜索博客，基本上都是如下的<a href="https://blog.csdn.net/mjl960108/article/details/79981794">解决方案</a>：</p><blockquote><p>sudo apt install python-pydot python-pydot-ng graphviz</p></blockquote><p>但是运行时会事与愿违：</p><blockquote><p>root@9187b8755600:~/gem5/m5out# apt install python-pydot python-pydot-ng graphviz<br>Reading package lists… Done<br>Building dependency tree<br>Reading state information… Done<br>E: Unable to locate package python-pydot<br>E: Unable to locate package python-pydot-ng</p></blockquote><p>找不到安装包，也有博客指出需要使用pip命令安装，但是ubuntu自带的python无法找到pip命令，而也最好不要使用conda的虚拟python环境，因为无法定位到虚拟环境中的scons命令，这个我至今也没有解决，而是直接安装docker环境，配置python2.7和python3.8，用于不同版本的gem5，非常方便。</p><p>为此解决系统python环境缺少pydot的方法如下：</p><ol><li>下载<a href="https://pypi.org/project/pydot/#files">pydot源</a><blockquote><p>wget <a href="https://files.pythonhosted.org/packages/13/6e/916cdf94f9b38ae0777b254c75c3bdddee49a54cc4014aac1460a7a172b3/pydot-1.4.2.tar.gz">https://files.pythonhosted.org/packages/13/6e/916cdf94f9b38ae0777b254c75c3bdddee49a54cc4014aac1460a7a172b3/pydot-1.4.2.tar.gz</a></p></blockquote></li><li>解压文件</li><li>安装pydot<blockquote><p>python setup.py install (for python2.7)<br>python3 setup.py install (for python3.8)</p></blockquote></li></ol><p>完美解决！！！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>(转)Types of Memory Interleaving</title>
      <link href="/2021/07/30/zhuan-types-of-memory-interleaving/"/>
      <url>/2021/07/30/zhuan-types-of-memory-interleaving/</url>
      
        <content type="html"><![CDATA[<h1 id="转-Types-of-Memory-Interleaving"><a href="#转-Types-of-Memory-Interleaving" class="headerlink" title="(转)Types of Memory Interleaving"></a>(转)Types of Memory Interleaving</h1><p><a href="https://www.geeksforgeeks.org/memory-interleaving/">Memory Interleaving</a> is an abstraction technique which divides memory into a number of modules such that successive words in the address space are placed in the different module.</p><p>Suppose a 64 MB memory made up of the 4 MB chips as shown in the below:</p><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/1406-4.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>We organize the memory into 4 MB banks, each having eight of the 4 MB chips. The memory thus has 16 banks, each of 4 MB.</p><p>64 MB memory = $2^{26}$, so 26 bits are used for addressing.<br>16 = $2^4$, so 4 bits of address select the bank, and 4 MB = $2^{22}$, so 22 bits of address to each chip.</p><p>In general, an N-bit address, with $N = L + M$, is broken into two parts:</p><ol><li>L-bit bank select, used to activate one of the $2^L$ banks of memory, and</li><li>M-bit address that is sent to each of the memory banks.</li></ol><p>When one of the memory banks is active, the other ($2^L – 1$) are inactive. All banks receive the M-bit address, but the inactive one do not respond to it.</p><p><strong>Classification of Memory Interleaving:</strong><br>Memory interleaving is classified into two types:</p><ol><li><strong>High Order Interleaving –</strong> In high-order interleaving, the most significant bits of the address select the memory chip. The least significant bits are sent as addresses to each chip. One problem is that consecutive addresses tend to be in the same chip. The maximum rate of data transfer is limited by the memory cycle time.</li></ol><p>It is also known as Memory Banking.</p><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/223-1.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><ol start="2"><li><strong>Low Order Interleaving –</strong> In low-order interleaving, the least significant bits select the memory bank (module). In this, consecutive memory addresses are in different memory modules. This allows memory access at much faster rates than allowed by the cycle time.</li></ol><p><img "" class="lazyload placeholder" data-original="/2021/07/30/zhuan-types-of-memory-interleaving/3164-1.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif"></p><p>注：转载于<a href="https://www.geeksforgeeks.org/types-of-memory-interleaving/">https://www.geeksforgeeks.org/types-of-memory-interleaving/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CACTI 7.0介绍</title>
      <link href="/2021/07/29/cacti-7-0-jie-shao/"/>
      <url>/2021/07/29/cacti-7-0-jie-shao/</url>
      
        <content type="html"><![CDATA[<h1 id="CACTI-7-0介绍"><a href="#CACTI-7-0介绍" class="headerlink" title="CACTI 7.0介绍"></a>CACTI 7.0介绍</h1><h2 id="1-CACTI发展"><a href="#1-CACTI发展" class="headerlink" title="1. CACTI发展"></a>1. CACTI发展</h2><p>CACTI是HP公司推出的一款开源开源工具，广泛应用于对cache/DRAM的延时，功耗，cycle time[^1]和面积的评估。</p><p>[^1]: <font color="gray">(暂时不知道如何翻译比较好，感觉前面的延时指的是各个部分的延时信息，这边的cycle time应该指的是访问周期)</font></p><p>CACTI最初由Dr. Jouppi和Dr. Wilton于1993年开发，此后经历了六次版本的迭代。</p><h2 id="2-CACTI支持的特性"><a href="#2-CACTI支持的特性" class="headerlink" title="2. CACTI支持的特性"></a>2. CACTI支持的特性</h2><ul><li>以下memory的功耗、延时、cycle time的建模<ul><li>direct mapped caches</li><li>set-associative caches</li><li>fully associative caches</li><li>Embedded DRAM memories</li><li>Commodity DRAM memories</li></ul></li><li>多端口UCA(uniform cache access)，多端口的NUCA(non-uniform cache access)的建模</li><li>工作温度对泄露功耗的影响</li><li>路由功耗模型</li><li>具有不同延迟、功耗和面积属性的互连模型，包括低摆幅线模型</li><li>用于执行功率、延迟、面积和带宽之间权衡分析的接口</li><li>该工具使用的所有工艺特定值均从 ITRS 获得，目前该工具支持 90nm、65nm、45nm 和 32nm 技术节点</li><li>用于计算DDR总线延迟和能量的芯片IO模型。用户可以模拟不同的负载（扇出）并评估对频率和能量的影响。该模型可用于研究LR-DIMM、R-DIMM等。</li><li>Version 7.0在6.5版本的基础之上还融合了CACTI 3D</li></ul><h2 id="3-CACTI的使用方法"><a href="#3-CACTI的使用方法" class="headerlink" title="3. CACTI的使用方法"></a>3. CACTI的使用方法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/HewlettPackard/cacti</span><br><span class="line"><span class="built_in">cd</span> cacti</span><br><span class="line"><span class="comment"># modify the xxx.cfg for self configuration</span></span><br><span class="line">make</span><br><span class="line">./cacti -infile xxx.cfg</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows使用sftp获取服务器运行记录</title>
      <link href="/2021/07/25/windows-shi-yong-sftp-huo-qu-fu-wu-qi-yun-xing-ji-lu/"/>
      <url>/2021/07/25/windows-shi-yong-sftp-huo-qu-fu-wu-qi-yun-xing-ji-lu/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>函数的副作用</title>
      <link href="/2021/07/25/han-shu-de-fu-zuo-yong/"/>
      <url>/2021/07/25/han-shu-de-fu-zuo-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="转-函数的副作用"><a href="#转-函数的副作用" class="headerlink" title="(转)函数的副作用"></a>(转)函数的副作用</h1><p><strong>函数的副作用</strong>指当调用函数时，除了返回函数值之外，还对主调用函数产生附加的影响。例如修改全局变量（函数外的变量）或修改参数。</p><p>函数副作用会给程序设计带来不必要的麻烦，给程序带来十分难以查找的错误，并且降低程序的可读性。严格的函数式语言要求函数必须无副作用。</p><p>函数的副作用相关的几个概念， Pure Function、 Impure Function、 Referential Transparent。</p><ul><li><p><strong>纯函数 (Pure Function)</strong><br>输入输出数据流全是显式（Explicit）的。 显式（Explicit）的意思是，函数与外界交换数据只有一个唯一渠道——参数和返回值。函数从函数外部接受的所有输入信息都通过参数传递到该函数内部。函数输出到函数外部的所有信息都通过返回值传递到该函数外部。</p></li><li><p><strong>非纯函数 (Impure Function)</strong></p><p>与之相反。 隐式（Implicit）的意思是，函数通过参数和返回值以外的渠道，和外界进行数据交换。比如读取/修改全局变量，都叫作以隐式的方式和外界进行数据交换。</p></li><li><p><strong>引用透明 (Referential Transparent)</strong></p><p>引用透明的概念与函数的副作用相关，且受其影响。 如果程序中两个相同值得表达式能在该程序的任何地方互相替换，而不影响程序的动作，那么该程序就具有引用透明性。它的优点是比非引用透明的语言的语义更容易理解，不那么晦涩。纯函数式语言没有变量，所以它们都具有引用透明性。</p></li></ul><p>以下示例说明了引用透明与函数副作用的结合</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result1 = (fun(a) + b) / (fun(a) - c);</span><br><span class="line">temp = func(a);</span><br><span class="line">result2 = (temp + b) / (temp - c);</span><br></pre></td></tr></table></figure><p>如果函数没有副作用，那么result1和result2将是等价的。然而如果fun有副作用，比如让b或c加1，那么result1和result2将不相等。因此，副作用违背了引用透明性。</p><p>在JavaScript中，引入了函数。但显然JS中的函数可以访问、修改全局变量（或定义在函数外的变量），如下</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">5</span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fun</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">a = <span class="number">10</span>;</span><br><span class="line">&#125;</span><br><span class="line">fun();<span class="comment">// a变成了10</span></span><br></pre></td></tr></table></figure><p>JS中要想保证函数无副作用这项特性，只能依靠编程人员的习惯，即</p><ol><li><p>函数入口使用参数运算，而不修改它</p></li><li><p>函数内不修改函数外的变量，如全局变量</p></li><li><p>运算结果通过函数返回给外部（出口）</p></li></ol><blockquote><p>转载自：<a href="https://www.cnblogs.com/snandy/archive/2011/08/14/2137898.html">https://www.cnblogs.com/snandy/archive/2011/08/14/2137898.html</a></p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>(转)多核处理器的九大关键技术</title>
      <link href="/2021/07/23/zhuan-duo-he-chu-li-qi-de-jiu-da-guan-jian-ji-zhu/"/>
      <url>/2021/07/23/zhuan-duo-he-chu-li-qi-de-jiu-da-guan-jian-ji-zhu/</url>
      
        <content type="html"><![CDATA[<h1 id="转-多核处理器的九大关键技术"><a href="#转-多核处理器的九大关键技术" class="headerlink" title="(转)多核处理器的九大关键技术"></a>(转)多核处理器的九大关键技术</h1><p>与单核处理器相比，多核处理器在体系结构、软件、功耗和安全性设计等方面面临着巨大的挑战，但也蕴含着巨大的潜能。</p><p>CMP和SMT一样，致力于发掘计算的粗粒度并行性。CMP可以看做是随着大规模集成电路技术的发展，在芯片容量足够大时，就可以将大规模并行处理机结构中的SMP（对称多处理机）或DSM（分布共享处理机）节点集成到同一芯片内，各个处理器并行执行不同的线程或进程。在基于SMP结构的单芯片多处理机中，处理器之间通过片外Cache或者是片外的共享存储器来进行通信。而基于DSM结构的单芯片多处理器中，处理器间通过连接分布式存储器的片内高速交叉开关网络进行通信。由于SMP和DSM已经是非常成熟的技术了，CMP结构设计比较容易，只是后端设计和芯片制造工艺的要求较高而已。正因为这样，CMP成为了最先被应用于商用CPU的“未来”高性能处理器结构。</p><p>虽然多核能利用集成度提高带来的诸多好处，让芯片的性能成倍地增加，但很明显的是原来系统级的一些问题便引入到了处理器内部。</p><ol><li><p>核结构研究: 同构还是异构</p><p>CMP的构成分成同构和异构两类，同构是指内部核的结构是相同的，而异构是指内部的核结构是不同的。为此，面对不同的应用研究核结构的实现对未来微处理器的性能至关重要。核本身的结构，关系到整个芯片的面积、功耗和性能。怎样继承和发展传统处理器的成果，直接影响多核的性能和实现周期。同时，根据Amdahl定理，程序的加速比决定于串行部分的性能，所以，从理论上来看似乎异构微处理器的结构具有更好的性能。</p><p>核所用的指令系统对系统的实现也是很重要的，采用多核之间采用相同的指令系统还是不同的指令系统，能否运行操作系统等，也将是研究的内容之一。</p></li><li><p>程序执行模型</p><p>多核处理器设计的首要问题是选择程序执行模型。程序执行模型的适用性决定多核处理器能否以最低的代价提供最高的性能。程序执行模型是编译器设计人员与系统实现人员之间的接口。编译器设计人员决定如何将一种高级语言程序按一种程序执行模型转换成一种目标机器语言程序; 系统实现人员则决定该程序执行模型在具体目标机器上的有效实现。当目标机器是多核体系结构时，产生的问题是: 多核体系结构如何支持重要的程序执行模型？是否有其他的程序执行模型更适于多核的体系结构？这些程序执行模型能多大程度上满足应用的需要并为用户所接受？</p></li><li><p>Cache设计: 多级Cache设计与一致性问题</p><p>处理器和主存间的速度差距对CMP来说是个突出的矛盾，因此必须使用多级Cache来缓解。目前有共享一级Cache的CMP、共享二级Cache的CMP以及共享主存的CMP。通常，CMP采用共享二级Cache的CMP结构，即每个处理器核心拥有私有的一级Cache，且所有处理器核心共享二级Cache。</p><p>Cache自身的体系结构设计也直接关系到系统整体性能。但是在CMP结构中，共享Cache或独有Cache孰优孰劣、需不需要在一块芯片上建立多级Cache，以及建立几级Cache等等，由于对整个芯片的尺寸、功耗、布局、性能以及运行效率等都有很大的影响，因而这些都是需要认真研究和探讨的问题。</p><p>另一方面，多级Cache又引发一致性问题。采用何种Cache一致性模型和机制都将对CMP整体性能产生重要影响。在传统多处理器系统结构中广泛采用的Cache一致性模型有: 顺序一致性模型、弱一致性模型、释放一致性模型等。与之相关的Cache一致性机制主要有总线的侦听协议和基于目录的目录协议。目前的CMP系统大多采用基于总线的侦听协议。</p></li><li><p>核间通信技术</p><p>CMP处理器的各CPU核心执行的程序之间有时需要进行数据共享与同步，因此其硬件结构必须支持核间通信。高效的通信机制是CMP处理器高性能的重要保障，目前比较主流的片上高效通信机制有两种，一种是基于总线共享的Cache结构，一种是基于片上的互连结构。</p><p>总线共享Cache结构是指每个CPU内核拥有共享的二级或三级Cache，用于保存比较常用的数据，并通过连接核心的总线进行通信。这种系统的优点是结构简单，通信速度高，缺点是基于总线的结构可扩展性较差。</p><p>基于片上互连的结构是指每个CPU核心具有独立的处理单元和Cache，各个CPU核心通过交叉开关或片上网络等方式连接在一起。各个CPU核心间通过消息通信。这种结构的优点是可扩展性好，数据带宽有保证; 缺点是硬件结构复杂，且软件改动较大。</p><p>也许这两者的竞争结果不是互相取代而是互相合作，例如在全局范围采用片上网络而局部采用总线方式，来达到性能与复杂性的平衡。</p></li><li><p>总线设计</p><p>传统微处理器中，Cache不命中或访存事件都会对CPU的执行效率产生负面影响，而总线接口单元（BIU）的工作效率会决定此影响的程度。当多个CPU核心同时要求访问内存或多个CPU核心内私有Cache同时出现Cache不命中事件时，BIU对这多个访问请求的仲裁机制以及对外存储访问的转换机制的效率决定了CMP系统的整体性能。因此寻找高效的多端口总线接口单元（BIU）结构，将多核心对主存的单字访问转为更为高效的猝发（burst）访问; 同时寻找对CMP处理器整体效率最佳的一次Burst访问字的数量模型以及高效多端口BIU访问的仲裁机制将是CMP处理器研究的重要内容。</p></li><li><p>操作系统设计: 任务调度、中断处理、同步互斥</p><p>对于多核CPU，优化操作系统任务调度算法是保证效率的关键。一般任务调度算法有全局队列调度和局部队列调度。前者是指操作系统维护一个全局的任务等待队列，当系统中有一个CPU核心空闲时，操作系统就从全局任务等待队列中选取就绪任务开始在此核心上执行。这种方法的优点是CPU核心利用率较高。后者是指操作系统为每个CPU内核维护一个局部的任务等待队列，当系统中有一个CPU内核空闲时，便从该核心的任务等待队列中选取恰当的任务执行，这种方法的优点是任务基本上无需在多个CPU核心间切换，有利于提高CPU核心局部Cache命中率。目前多数多核CPU操作系统采用的是基于全局队列的任务调度算法。</p><p>多核的中断处理和单核有很大不同。多核的各处理器之间需要通过中断方式进行通信，所以多个处理器之间的本地中断控制器和负责仲裁各核之间中断分配的全局中断控制器也需要封装在芯片内部。</p><p>另外,多核CPU是一个多任务系统。由于不同任务会竞争共享资源，因此需要系统提供同步与互斥机制。而传统的用于单核的解决机制并不能满足多核，需要利用硬件提供的“读－修改－写”的原子操作或其他同步互斥机制来保证。</p></li><li><p>低功耗设计</p><p>半导体工艺的迅速发展使微处理器的集成度越来越高，同时处理器表面温度也变得越来越高并呈指数级增长，每三年处理器的功耗密度就能翻一番。目前，低功耗和热优化设计已经成为微处理器研究中的核心问题。CMP的多核心结构决定了其相关的功耗研究是一个至关重要的课题。</p><p>低功耗设计是一个多层次问题，需要同时在操作系统级、算法级、结构级、电路级等多个层次上进行研究。每个层次的低功耗设计方法实现的效果不同——抽象层次越高，功耗和温度降低的效果越明显。</p></li><li><p>存储器墙</p><p>为了使芯片内核充分地工作，最起码的要求是芯片能提供与芯片性能相匹配的存储器带宽，虽然内部Cache的容量能解决一些问题，但随着性能的进一步提高，必须有其他一些手段来提高存储器接口的带宽，如增加单个管脚带宽的DDR、DDR2、QDR、XDR等。同样，系统也必须有能提供高带宽的存储器。所以，芯片对封装的要求也越来越高，虽然封装的管脚数每年以20%的数目提升，但还不能完全解决问题，而且还带来了成本提高的问题，为此，怎样提供一个高带宽，低延迟的接口带宽，是必须解决的一个重要问题。</p></li><li><p>可靠性及安全性设计</p><p> 随着技术革新的发展，处理器的应用渗透到现代社会的各个层面，但是在安全性方面却存在着很大的隐患。一方面，处理器结构自身的可靠性低下，由于超微细化与时钟设计的高速化、低电源电压化，设计上的安全系数越来越难以保证，故障的发生率逐渐走高。另一方面，来自第三方的恶意攻击越来越多，手段越来越先进，已成为具有普遍性的社会问题。现在，可靠性与安全性的提高在计算机体系结构研究领域备受注目。</p></li></ol><p>转载于:<a href="http://blog.itpub.net/312079/viewspace-245322/">http://blog.itpub.net/312079/viewspace-245322/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux Tools Mannual</title>
      <link href="/2021/07/22/linux-tools-mannual/"/>
      <url>/2021/07/22/linux-tools-mannual/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux-常用工具使用命令速查表"><a href="#Linux-常用工具使用命令速查表" class="headerlink" title="Linux 常用工具使用命令速查表"></a>Linux 常用工具使用命令速查表</h1><h2 id="tmux"><a href="#tmux" class="headerlink" title="tmux"></a>tmux</h2><h3 id="tmu常用操作指令及快捷键"><a href="#tmu常用操作指令及快捷键" class="headerlink" title="tmu常用操作指令及快捷键"></a>tmu常用操作指令及快捷键</h3><ol><li>查看有所有tmux会话<br>指令：tmux ls<br>快捷键：Ctrl+b s</li><li>新建tmux窗口<br>指令：tmux new -s <session-name></session-name></li><li>重命名会话<br>指令：tmux rename-session -t <old-name> <new-name><br>快捷键：Ctrl+b $</new-name></old-name></li><li>分离会话<br>指令：tmux detach/exit(关闭窗口，杀死会话)<br>快捷键：Ctrl+b d</li><li>平铺当前窗口<br>快捷键：Ctrl+b z(再次Ctrl+b d恢复)</li><li>杀死会话<br>指令：tmux kill-session -t <session-name></session-name></li><li>切换会话<br>指令：tmux switch -t <session-name></session-name></li><li>划分上下两个窗格<br>指令：tmux split<br>快捷键：Ctrl+b “</li><li>划分左右两个窗格<br>指令：tmux split -h<br>快捷键：Ctrl+b %</li><li>光标切换到上方窗格<br>指令：tmux select-pane -U<br>快捷键：Ctrl+b 方向键上</li><li>光标切换到下方窗格<br>指令：tmux select-pane -D<br>快捷键：Ctrl+b 方向键下</li><li>光标切换到左边窗格<br>指令：tmux select-pane -L<br>快捷键：Ctrl+b 方向键左</li><li>光标钱换到右边窗格<br>指令：tmux select-pane -R<br>快捷键：Ctrl+b 方向键右</li></ol><p><a href="https://zhuanlan.zhihu.com/p/90464490">https://zhuanlan.zhihu.com/p/90464490</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
